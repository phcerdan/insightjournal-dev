[
{"reviews": [], "publication_id": 9},
{"reviews": [], "publication_id": 10},
{"reviews": [], "publication_id": 11},
{"reviews": [], "publication_id": 12},
{"reviews": [{"date": "09-19-2005", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<b>Summary:</b>\r\nThe authors present MITK, a freely available and truly open-source (commercial and non-commercial use) software library that provides modules that integrate and extend ITK, VTK, GLUT, and FLTK/QT. Integration alone is noteworthy - the extensions are even more noteworthy.\r\n\r\nKey features include the coordination fo multiple 2D/3D visualizations of spatial objects, a general interaction concept including undo/redo, and a layered API that hides complexity at upper levels while also allowing specialization of functionality at lower levels.\r\n\r\nThe layered approach is particularly useful in this context. A user can quickly piece together some broad modules to form a \"standard\" application, and then time can be spent to refine the inner workings of one or two of the modules to provide tailored functionality.\r\n \r\n<b>Hypothesis:</b>\r\nA diversity of open-source projects can be integrated and wrapped to provide software modules that simplify medical image analysis application development.\r\n\r\n<b>Evidence:</b>\r\nThe paper is written in a casual tone and introduces the concepts behind MITK and provides a few specifcs regarding the options available in MITK.\r\n\r\nThe paper provides an excellent overview of which strengths were combined from the various open source packages that comprise MITK. That overview is written at an ideal level of detail. Specific programming constructs (e.g., smart pointers) are mentioned without going into overly detailed explanations. The details given are exactly what a reader would need to begin to investigate the integration of those packages into his/her own toolkit.\r\n\r\nThe paper, however, would benefit from a bit more details regarding what options are available to someone using MITK to develop an application. A list of available visualization models, for example. Otherwise, the authors could provide more details regarding the process of developing one or two demonstration applications using MITK. Either type of additional information would be welcome.\r\n\r\n<b>Open Science:</b>\r\nMITK is released under an open-BSD-style license. It is available for commercial or non-commercial use. Many aspects are GUI independent, and GUI components from different packages (e.g., QT or FLTK) can be used; however, most work appears to be done with QT components - the development of FLTK components seems to be more limited. This is unfortunate given QT's licensing restrictions.\r\n\r\n<b>Reproducibility:</b>\r\nThe website for MITK is very good. Publications, documentation, and the code are readily available. The installation details and requirements are well specificied.\r\n\r\n<b>Use of Open Source Software:</b>\r\nMakes heavy use of open-source.\r\n\r\n<b>Open Source Contributions:</b>\r\nIs released as open source: commercial and non-commercial.\r\n\r\n<b>Code Quality:</b>\r\nI did not look at the code, but the use of ITK, VTK, etc and the fact that the group has contributed back to those toolkits suggests that they use good coding style/practices.\r\n\r\n<b>Additional Comments:</b>\r\nUsers interesting in this package should be aware of related work in the form of Slicer and SOViewers. MITK, however, appears to fill a gap between those two toolkits. It allows more specialization than Slicer, and it is easier to develop a standard application using MITK than using SOViewers.\r\n", "review_id": 109}, {"date": "08-16-2005", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThis paper describes the development of a medical image software framework based on ITK, VTK, QT, and FLTK. The framework is, conceptionally, one level closer to the end-user than any of the components, because it creates high-level widgets and controls used for interacting with data and algorithms. End-user developers should be able to build interactive applications with MITK.\r\n \r\n\r\n<b>Hypothesis:</b>\r\nNot Applicable\r\n\r\n<b>Evidence:</b>\r\nNot Applicable other than the fact that the framework has been built. The paper doesn't provide studies or evidence that the framework is valid, end-user acceptable, fast, or other metrics of performace. However, this was not the intent of the paper and (my opinion only) I don't believe such a study would be prudent at this time. (my opinion only) I would suggest that the software probably requires some time to mature.\r\n\r\n<b>Open Science:</b>\r\nThe work is consistent with open science principles\r\n\r\n\r\n<b>Reproducibility:</b>\r\nThe software can be downloaded and run. Although the package hasn't been submitted with the paper, the paper explicitly describes where the code can be obtained from. I admit that I have not taken the time to download and run it. \r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nMost of the packages are open source except for QT which does have some licensing restrictions.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe whole package is available for user evaluation. In addition, the authors request community participation to test and develop the software.\r\n\r\n<b>Code Quality:</b>\r\nOnce again, in the intereste of full disclosure, I have not yet downloaded the package and worked with it.\r\n\r\n<b>Applicability to other problems:</b>\r\nBecause it is a framework, there are many specific applications which can utilize this code to develop targeted software.\r\n\r\n<b>Suggestions for future work :</b>\r\nPerformace evaluation in the context of specifica applications.\r\n\r\n<b>Requests for additional information from authors :</b>\r\nIt would be beneficial to have a little code example in the text to show the implementation approach. As is noted in figure 2, a small example in fltk exists. Some amount of this code might be included and described in the text as a specific example.\r\n\r\n<b>Additional Comments:</b>\r\nNone\r\n", "review_id": 28}], "publication_id": 13},
{"reviews": [], "publication_id": 14},
{"reviews": [], "publication_id": 15},
{"reviews": [], "publication_id": 16},
{"reviews": [{"date": "09-18-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis papers describes the application of algorithms available in ITK to the segmentation of brain-tumors infiltrating the skull. It also implements a methodology for evaluating their results compared to a human expert.\r\n \r\n<b>Hypothesis:</b>\r\nThis paper hypothesis that segmentation methods from the Insight Toolkit can be used for delineating skull infiltrated tumors. In order to test this hypothesis, the authors selected multiple segmentation methods from the toolkit, ran segmentation on test data and implemented an evaluation methodology for comparing the results from the software-based segmentation with the human expert segmentations.\r\n\r\n<b>Evidence:</b>\r\nThe authors present abundant evidence from the result of their segmentation experiments. The comparision of the segmentation methods reveals that the authors invested a significan amount of work in exploring the applicability of the many segmentation methods compared here. It is unfortunate that the full material of those experiments was not shared with the readers, who would have derived great benefits from being able to apply the same set of experiments to other medical segmentation problems.\r\n\r\n<b>Open Science:</b>\r\nThe paper describe the segmentation methods evaluated in this case, and the evaluation methodology used for comparing the results. This evaluation methodology seems to be the most valuable contribution of the paper, since it reveals that a wide set of segmentation tools were systematically tested. Unfortunately the authors did not share the source code used for their test and for their evaluation methodology. Despite the fact that their code is based on ITK filters, it would take a reader a significant amount of time to replicate the work of the authros, since the reader will have to reimplement the code for all the tests.\r\n\r\n<b>Reproducibility:</b>\r\nThe work can hardly be reproduced. Not enough coding details are provided by the authors, and in particular, no details regarding the many numerical parameters of the segmentation methods are mentioned. In the current form it is impossible to replicate the work performed by the authors. A reader could run an equivalent set of experiments, by using ITK filters, but the lack of the input images, and the lack of details regarding the parameters will make impossible to ensure that the reader\\'s set of test is equivalent to the one reported by the authors.\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors make extensive use of the Insight Toolkit, and took care of using ITK filters as building blocks. Their study of the applicability of ITK segmentation filters is certainly valuable for the readers, since it guides them towards the segmentation methods that displayed the best performance (compared to a human expert) for segmenting the skull-infiltrated tumors.\r\n\r\n\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors did not provide their source code.\r\n\r\n\r\n<b>Code Quality:</b>\r\nReviewer\\'s speculation: Judgging from the description in the paper it seems that the authors made a good use of the code available in the Insight Toolkit, by combining ITK filters as building blocks for their segmenation pipelines. \r\n\r\n<b>Applicability to other problems:</b>\r\nThe generic problem faced by the authors is indeed quite challenging since the intensity of the image alone is not enough for segmenting the objets. The ITK methods that the authors found to be more appropriate for this problem, will probably perform well for other segmentation situations where the intensity of the object to be extracted is similar to the intensity of adjacent structures.\r\n\r\n\r\n<b>Suggestions for future work:</b>\r\nMany of the methods used in VALMET (Gerig, G., Jomier, M., Chakos, M.) are now available in ITK in the form of filters. In particular the overlap measures, the Haussdorf distance and surface mean distance. It could be interesting to create a reusable framework for segmentation validation that any authors could use during the validation stages of their segmentation work.\r\n\r\n\r\n\r\n<b>Requests for additional information from authors:</b>\r\nIt will be very useful if the authors share their source code with the community. In particular all the parameters setting of the segmentation methods. The source code of their evaluation framework will also be extremely useful for anybody performing a segmentation evaluation study.\r\n\r\n\r\n<b>Additional Comments:</b>\r\nSince the authors found the Chi squared value to be a convenient measure for comparing the segmentation results to the human expert delineation, it seems to be interesting to create that measure as an ITK filter.\r\n\r\n\r\n", "review_id": 105}, {"date": "08-24-2005", "author": {"author_id": 87, "author_email": "sylvain@bwh.harvard.edu", "author_lastname": "Bouix", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThis paper describes a validation study of the segmentation of skull infiltrated tumors.\r\nTwo segmentation pipelines implemented in ITK are presented, one based on region growing, one based on level sets.\r\nThey are then validated agains one expert\\\\\\'s segmentations using five similarity measurement: sensitivity, specificity, Dice, X2 and Hausdorff\r\n\r\n<b>Hypothesis:</b>\r\nNon applicable\r\n\r\n<b>Evidence:</b>\r\nFour datasets were used, 3 patients with manual tracings by 1 human expert and 1 phantom with ground truth.\r\nThe experimetns are clearly explained and sufficient evidence is provided.\r\n\r\n<b>Open Science:</b>\r\nThere is enough information in the paper to reproduce the experiment, but no data or source code is provided. \r\n\r\n<b>Use of Open Source Software:</b>\r\nAuthors used ITK for the segmentation pipelines and Hausdorff measurements\r\n\r\n<b>Open Source Contributions:</b>\r\nNo code provided.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe main contribution of the paper is to question certain measurement when validating segmentation technique, which I think is important for the community in general. They partiucularly caution the reader in using specificity and sensitivity as the sole validation parameters as they are dependent on the image size vs. object size relationship. They later show that these measures actually rank region growing higher than level sets even though other measures disagree. \r\n\r\n<b>Suggestions for future work :</b>\r\nIn the context of open science, I suggest the author incorporate the validation measurements into ITK and share their data and source code so experiments can be reproduced elsewhere.\r\nI also suggest they investigate other similarity measures found in the statistic litterature. The article by Hripcsakk abd Heitjjan on \\\\\\\"Measuring Agreement in medical informatics reliability studies\\\\\\\" is a good starting point. \r\n\r\n", "review_id": 38}], "publication_id": 17},
{"reviews": [{"date": "09-08-2005", "author": {"author_id": 133, "author_email": "cates@sci.utah.edu", "author_lastname": "Cates", "author_firstname": "Josh"}, "content": "<b>Summary:</b> This paper describes a new, open-access collection of medical \r\nimage data assembled by the Mayo Clinic with support from the National Library \r\nof Medicine (NLM). The collection includes over 100 datasets of\r\nvarying modalities, anatomy and subject species and is intended to support\r\nmedical imaging research. The focus of the collection is on diversity, \r\nmulti-modalilty, and new imaging modalities. A web-based interface to the \r\ncollection has been developed and the data will be made available through\r\nthe NLM.\r\n \r\n<b>Hypothesis:</b>\r\nThe work was motivated by the idea that open access data collections facilitate \r\nmedical imaging research, and it follows in the footsteps of the original Visible \r\nHuman Project initiative. The authors anticipate that this data will be useful\r\nin the development and validation of new imaging algorithms.\r\n\r\n<b>Evidence:</b>\r\nThe authors clearly state their motivations behind the work and cite some evidence that \r\nsimilar efforts have been effective, but this paper is not intended to be a rigorous \r\ninvestigation into the usefulness of open access data collections.\r\n\r\n<b>Open Science:</b> This is a true open science initiative. The data is to be\r\nreleased to the research community through a web interface. The article indicates \r\nthat this is an ongoing effort.\r\n\r\nSome issues: None of the data seems to be currently available. When will it be\r\nreleased? It is also not clear from the article what restrictions will be placed \r\non the use of the data. Will they be similar to those governing use of Visible \r\nHuman Data?\r\n\r\n<b>Reproducibility:</b>\r\nNot applicable.\r\n\r\n<b>Use of Open Source Software:</b>\r\nNot applicable.\r\n\r\n<b>Open Source Contributions:</b>\r\n(Will the web interface be open source?)\r\n\r\n<b>Code Quality:</b>\r\nNot applicable.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe data will no doubt be of interest to researchers in domains outside\r\nmedical imaging (e.g. computer graphics, anatomists, education, ...).\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n\r\n<b>Requests for additional information from authors:</b> Will any of the\r\nvolumetric datasets include the raw (un-reconstructed) scanner data? This data\r\nwould obviously be of great interest to the reconstruction community. It would\r\nalso be helpful to include information about the reconstruction algorithms used\r\nto produce the volumes and the scanner geometries.\r\n\r\n<b>Additional Comments:</b> I would encourage the authors to include additional\r\ninformation as it becomes available, i.e. where and how to access, restrictions\r\non use, etc.\r\n\r\nSome minor points:\r\nThe article reads fairly well, but another editing pass might be useful. There are \r\nfor example, one or two typos to address (e.g. p. 3 comprhensive->comprehensive).\r\nAlso, I believe the acronym 'BIR' is never fully spelled out.\r\n\r\nI look forward to getting my hands on some of this data!\r\n\r\n", "review_id": 50}, {"date": "09-17-2005", "author": {"author_id": 96, "author_email": "tkapur@bwh.harvard.edu", "author_lastname": "Kapur", "author_firstname": "Tina"}, "content": "<b>Summary:</b>\r\n\r\nAs previous reviewers have stated, this paper describes a collection of 100 diverse data sets that has been compiled already and will be made available (shortly?) for open access by the NLM via the Visible Human Project. The data sets are across species (mouse, Canine, Dophin, Mouse, Rabbit), anatomy(Abdomen, Brain, Cells, Chest, Ear, Hand, Heart, Knee, Larynx, Liver, Prostate), modality (MR, CT, Confocal Microscopy, PET, SPECT, Ultrasound, microCT, microMR), and pathology. The highest level categories of the collection are human and animal, each further subdivided into anatomical regions, then into modality, and then pathology. Many of the data sets were retrieved from archives at Mayo and collaborators, while an interesting one acquired specifcally for the collection is a full mouse data set acquired as overlapping sections with microCT and microMR at voxel resolutions of 0.02mm^3 and 0.125mm^3, and realigned into a single volume.\r\n\r\nEach data set is available in three file formats: Analyze 7.5, Analyze Volumefile, and MetaIO. References for descriptions of these formats are provided.\r\n\r\nHuman data has been anonymized and complies with HIPPA standards. \r\n\r\nThe data has been organized into a website with a custom browser.\r\n\r\n<b>Hypothesis:</b>\r\nA hypotheis is that openly accessible data is useful for advancing science.\r\n\r\n<b>Evidence:</b>\r\nThis is a widely accepted truth in many fields, including biomedical research. The authors have also provided references on how exisiting collections of data such as the Visible Human and the Vanderbilt Registration data have been successfully used by many researchers in different applications.\r\n\r\n<b>Open Science:</b>\r\nData sets like this are key enablers of open science. \r\n\r\n<b>Reproducibility:</b>\r\n\r\n<b>Use of Open Source Software:</b>\r\nIt is not clear if the web browser and file format conversion tools are open source.\r\n\r\n<b>Additional Comments:</b>\r\n\r\n- This is very useful work and should enable research in the area as the authors have noted.\r\n\r\n- For those interested in additional image collections, the authors have provided an interesting list (from open to restricted to closed): the visible Koren and Chinese human projects, MNI Brainweb for brain anatomy, UCDavis Brain atlas project for human and animal brains, BIRN brain data collection.\r\n\r\n- Following a link in the bibliography explains BIR (http://www.mayo.edu/bir)- it stands for Biomedical Imaging Resource, the group computational group at Mayo where this work was conducted. \r\n\r\n-The categories noted in the paper include 5 species, 11 anatomical regions, and 8 modalities. One can see that even if one data set was available for each bin of this table, 5x11x8x2 (the last two is one normal and one pathological) or 880 data sets would be needed. Clearly, there is room to add to this collection. Question for authors: are there guidelines that would allow other researchers to supply data sets that could be added to the collection to help populate the table? Are there NLM plans to solicit entries for this collection the way that algorithm implementations were successfully added to ITK?\r\n\r\n- Having a web based browser for the data was a great choice. As useful as downloaded data viewing applications can be, it seems that browsing data in a collection is something that is very well suited for a web based browser. I am waiting to try it out to see if the data sizes will make network lag an issue while browsing.\r\n\r\n-File formats: Is there a reason that images in this collection are not provided in the industry standard DICOM format? Most of the data in this collection seem to be the direct output of imaging scanners, does keeping it in DICOM (assuming it was once in that format) rather than converting it to the Analyze/MetaIO formats lose anything?\r\n", "review_id": 96}, {"date": "09-16-2005", "author": {"author_id": 21, "author_email": "hans-johnson@uiowa.edu", "author_lastname": "Johnson", "author_firstname": "Hans"}, "content": "\r\n<b>Summary:</b>\r\nThis document describes a repository of publicly available images and the tools developed to allow access to the data.\r\n \r\n<b>Hypothesis:</b>\r\nAccess to diverse data sets is critical to testing software. These data sets are useful for verifying that an algorithm is robust across data sets that differ from the data \r\nused during the initial development of the agorithm.\r\n\r\n<b>Evidence:</b>\r\nExamples of the web based interface to the downloading the data, as well as a description of the organization of the data is described.\r\n\r\n<b>Open Science:</b>\r\nThe data in this document are public. The tools described for dissemination of the data do not seem to be publicly available (although that is not the focus of the \r\npaper).\r\n\r\n\r\n<b>Reproducibility:</b>\r\nNA\r\n\r\n<b>Use of Open Source Software:</b>\r\nUnclear, but the data itself is collected from multiple public repositories.\r\n\r\n<b>Open Source Contributions:</b>\r\nNo code, but the data is very important to have available.\r\n\r\n<b>Code Quality:</b>\r\nNA\r\n\r\n<b>Suggestions for future work:</b>\r\nContinue to add interesting data sets to this collection.\r\n", "review_id": 93}], "publication_id": 18},
{"reviews": [{"date": "09-15-2005", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThe authors have a large volume serial histology registration problem to address. Like many others, they preprocess the data and register it. The purpose of this paper is not to validate the technique (because there is not enough data or gold standards), but to describe the workflow\r\n \r\n<b>Hypothesis:</b>\r\nImplicit hypothesis that there is a workflow (which happens to use ITK) that can process and register these histologic sections\r\n\r\n<b>Evidence:</b>\r\nThe authors describe the method; however, there is no code and data so there is no real evidence.\r\n\r\n<b>Open Science:</b>\r\nThe authors state that they use ITK for their processing (they don't state what they use for visualization). There is no code for the two algorithms (processing and registration); however, the registration approach is the basic approach described in all of the ITK documentation. There is not much to contribute back to the open science community because it appears to be a straightforward application of the API. Possibly if the tissue detection algorithm was new, it could be plugged back into the API.\r\n\r\n<b>Reproducibility:</b>\r\nSorry, there is no code. Equally important, there is no data. You would need both for reproducibility. Also, specific parameters for processing would have to be included as well.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThey used ITK\r\n\r\n<b>Open Source Contributions:</b>\r\nNope\r\n\r\n<b>Code Quality:</b>\r\nN/A\r\n\r\n<b>Applicability to other problems:</b>\r\nWell, the area of research is important because histologic registration is really needed.\r\n\r\n<b>Suggestions for future work:</b>\r\nMore validation\r\n\r\n<b>Requests for additional information from authors:</b>\r\nI am pleased to see ITK being used for this type of application. It is an important area which the authors are contributing.\r\n\r\nI have several comments for the authors' consideration:\r\n\r\n(1) Your use of figure is not particularly good. Figure 1 combines two completely different thoughts into one image. Several of the figures (including the left side of Figure 3) are not specificaly referenced in the paper. They should be so a reader can go back and forth.\r\n\r\n(2) It appears that some of the pre-processing algorithm has been previously published. I appreciate the fact that your reference that while still giving some of the details. The rest probably needs validation or comparision to other methods. Also, I notice that Figure 2 suggests that you downsample the data. That is not mentioned in the text, but is really important because it has implications for the results.\r\n\r\n(3) I like the MI approach that ITK uses. I think that multiple start points is also a good ideal; however, I wouldn't call this a novel idea. It is common to have more than one registration performed with different initial conditions or perturbations.\r\n\r\n(4) For this journal (although not all journals), it is really important to have the code and data for independant validation and testing.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 75}, {"date": "09-18-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper describes a methodology for registering the successive microscopy slices of a mouse placenta using the author\\\\\\'s modified version of the ITK registration framework.\r\n \r\n<b>Hypothesis:</b>\r\nThe authors suggest that the characterization of placenta morphology can be used for correlating genetic changes with phenotypic variation. The characterization of morphology is intended to be done after reconstructing a 3D model of the placenta via registration of a full microscopy sectioning of a mouse placenta.\r\n\r\n<b>Evidence:</b>\r\nThe authors provide multiple examples of the images at the various stages of the registration process, and describe many of the details of their registration approach. Unfortunately, the authors do not provide the source code used for their study, nor the images that could be used for replicating their work. \r\n\r\n<b>Open Science:</b>\r\nThe paper do not satisfy the requirements of Open Science, since it doesnt enable the reader to repeat and replicate the work reported by the authors. The lack of source code and images makes impossible for a reader to replicate the work of the authors. However the paper provide useful advice regarding that image registration methodology that was used by the authors for performing the alignment of the microscopy images.\r\n\r\n<b>Reproducibility:</b>\r\nThe work cannot be reproduced due to the lack of source code and images.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors made extensive use of the Insight Toolkit, and modified some of the components in the Registration Framework, in order to suite the particular characteristics of their image registration problem. Unfortunately the source code of such modification is not being shared, so authors that are interested in using a similar approach will have to re-implement the source code for that methodology.\r\n\r\n<b>Open Source Contributions:</b>\r\nSource code was not provided\r\n\r\n<b>Code Quality:</b>\r\nSource code was not provided\r\n\r\n<b>Applicability to other problems:</b>\r\nThe authors introduced the interesting concept of a two level optimization scheme where the parameters of the optimizer are set differently at the beggining and at the end of the registration process. This concept seems to be applicable to many if not all of the typical image regsitration problems. It would be interesting to implement this concept into auxiliary classes and to make them available to the community as part of the Insight Toolkit.\r\n\r\n<b>Suggestions for future work:</b>\r\nSince the final goal of the authors is to characterize the morphology of the surface of the placenta, it may be interesting to use registration methods that will focus on aligning the boundaries of the placenta. Among the possible options, the authors may want to consider the use of Image metrics that operate on the gradient magnitude of the images, or on the result of edge-detection algorithms such as Canny. The use of PointSet to image registration may also be appropriate for focusing the registration process on aliging the surface of the placenta.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nIt will be quite useful for readers if the authors share their source code and their image data.\r\n\r\n<b>Additional Comments:</b>\r\nThe description of the authors reveals that they have dedicated a significant amount of time to this problem. It is unfortunate that readers involved in similar fields would have to reimplement the work reported by the authors due to the lack of source code sharing.\r\n\r\n", "review_id": 103}], "publication_id": 19},
{"reviews": [{"date": "08-25-2005", "author": {"author_id": 51, "author_email": "pauly@despammed.com", "author_lastname": "Yushkevich", "author_firstname": "Paul"}, "content": "<b>Summary:</b>\r\nThis paper describes a MATLAB program to visualize and analyze metabolic phenotypes\r\n \r\n\r\n<b>Hypothesis:</b>\r\nNA\r\n\r\n<b>Evidence:</b>\r\nNo evidence is provided. The paper only has an introduction, a brief info about the GUI and a few lines describing functionality. No examples are presented\r\n\r\n<b>Open Science:</b>\r\nSource code is probably open, but no links are given. No output images are shown in the paper. There are no details\r\n\r\n<b>Reproducibility:</b>\r\nNo details -> No reproducibility\r\n\r\n<b>Use of Open Source Software:</b>\r\nNone\r\n\r\n<b>Open Source Contributions:</b>\r\nNot stated in the paper\r\n\r\n<b>Code Quality:</b>\r\nN/A\r\n\r\n<b>Applicability to other problems:</b>\r\nThis is not really an image analysis paper. Applicability is not discussed\r\n\r\n<b>Requests for additional information from authors :</b>\r\nProvide details of the application, some illustrations, impact.\r\n\r\n<b>Additional Comments:</b>\r\nThis paper seems incomplete and its quality is not comparable to typical MICCAI material\r\n\r\n", "review_id": 39}, {"date": "09-18-2005", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<b>Summary:</b>\r\nDiscusses the on-going development of a Matlab-based tool for studying the multivariate space that describes the metabolic environment of a cell. The tool allows for the menu-based selection of different types of clustering methods (termination criterion, etc.) to explore that multivariate space.\r\n\r\nNo specific mention of open-source (use or delivery) is mentioned.\r\n\r\n<b>Evidence:</b>\r\nA prototype system is mentioned and a screenshot (without data loaded) is presented. The paper speaks mainly of work that will be accomplished in the future. The paper is extremely sparse on details. The data analysis methods mentioned are straightforward and readily developed using Matlab.\r\n\r\n<b>Open Science:</b>\r\nI did some investigation on the web based on one sentence in the abstract...This work is intended to replicate and extend functionality currently available in a toolkit that was developed by the same people and that has been released as a \"pre-compiled\" IDL application. See http://prometheus.med.utah.edu/~marclab/protocols_cellkit.html It is not re-assuring that no mention of open-source is made and that previous work from this group appears to not be open-source. \r\n\r\nThe difficult balance faced by many and reflected in this work is that making freely-available software is very useful and should be applauded - however, Matlab is not freely available. Additionally, for data exploration it is often important to know the implementation details of the algorithms being applied and to be able to extend/modify those implementations.\r\n\r\n<b>Applicability to other problems:</b>\r\nThis work may be applicable to other multivariate data/cluster exploration problems - which are quite common. More details, however, are needed to determine how generic the methods and implementation will truly be.\r\n\r\n<b>Suggestions for future work:</b>\r\nI look forward to future revisions of this submission to include more details in the paper, demonstration data, and the matlab source code. The scope of the problem and the solution being pursued seem like idea areas for open-source efforts to florish.\r\n", "review_id": 102}, {"date": "09-18-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper describes the very early stages of a software system for performing Molecular Phenotyping through the use of image analysis.\r\n \r\n<b>Hypothesis:</b>\r\nThe paper suggests that the combination of image analysis and computational molecular phenotyping can be used successfully for identifiying cell classes in tissue samples.\r\n\r\n<b>Evidence:</b>\r\nThe paper does not provide any evidence of the claims. The system seems to be in the stages of design and prototyping.\r\n\r\n<b>Open Science:</b>\r\nAlthough the field of application of this paper is extremly interesting, the actual state of the software seems to be in a very early stage. \r\nThe paper does not satisfy the requirements of open science since there are no actual experiments reported, and there is no sharing of source code of data that could be used by others in order to verify the work of the authors.\r\n\r\n<b>Reproducibility:</b>\r\nThe content of the paper describe a project in the early stages of developement. It does not seem to be ready for being tested by others.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors don\\\\\\\\\\\\\\'t mention the use of Open Source code. The system is designed with Matlab, and it is not indicated whether the author\\\\\\\\\\\\\\'s software will be made available once it is ready to be used.\r\n\r\n<b>Open Source Contributions:</b>\r\nThere are no Open Source Contributions in this paper.\r\n\r\n<b>Code Quality:</b>\r\nNo code was available. The project is in early stages of design and prototyping.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe methodology suggested by the authors is based on the use of K-Means for classifying the images. The novelty of their work is the application of these well stablished image classification algorithms to a leading edge field, by combining it with molecular marking of the cellular tissues.\r\n\r\n<b>Suggestions for future work:</b>\r\nIt seems to be too early for this work to have been published. However, it is certainly an exciting application field for image analysis techniques, and it will be interesting to see the results of their work once the code reaches higher levels of maturity.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe authors should indicate if they made use of open source tools, or if they are planning to release their own tools as open source resources.\r\n\r\n\r\n\r\n", "review_id": 101}], "publication_id": 20},
{"reviews": [{"date": "09-17-2005", "author": {"author_id": 96, "author_email": "tkapur@bwh.harvard.edu", "author_lastname": "Kapur", "author_firstname": "Tina"}, "content": "<b>Summary:</b>\r\nThis paper describes the software development process for IGSTK, an open source image guided surgery toolkit whose architecture is described in a separate paper in this issue of the journal. It points out that in contrast to most open source projects, IGSTK needs to closely document the traceability of each requirement specification to its software implementation and testing in order to be compliant with the FDA (Food and Drug Administration) standards for medical devices. In particular, it details a collaborative method used in the project for capturing its evolving requirements.\r\n\r\n<b> Hypothesis </b>\r\nA hypothesis is that it is faster/cheaper/better to capture requirements with the proposed method than it is to manually update the requirements documentation.\r\n\r\n<b> Evidence </b>\r\nIt is still early in the project to determine this.\r\n\r\n<b> Comments </b>\r\n-\tSome of the IGSTK team members have carried over best practices from their participation in other open source projects to IGSTK, which is a good way to propagate these through the medical image analysis research community.\r\n-\tNote on the term âbest practiceâ: it is usually used to describe a practice that is deemed âbestâ because it helped make an aspect of a project successful. Since IGSTK is still in its infancy, and its practice of capturing requirements collaboratively for traceability purposes has not yet been proven one way or another, it might be too early to knight it. \r\n-\tAs another reviewer pointed out, a trace matrix would be useful since it is a commonly used format to demonstrate traceability for FDA review. Such a three column matrix contains one row for each requirement of the project and lists (1) the requirement text (2) the sections of the code that implement it, and (3) the sections of the code that test it.\r\n-\tI think that the automatic generation of updates to requirements documents (and potentially trace matrices) is appealing for commercial medical device development, and could be a useful tool in its own right.\r\n\r\n\r\n", "review_id": 94}, {"date": "09-09-2005", "author": {"author_id": 63, "author_email": "pkaz@cs.jhu.edu", "author_lastname": "Kazanzides", "author_firstname": "Peter"}, "content": "<b>Summary:</b>\r\nThis paper presents some best practices and a method for requirements capture during agile software development of the IGSTK toolkit.\r\n \r\n<b>Hypothesis:</b>\r\nOne hypothesis is that requirements for a medical software toolkit can be captured during development (as they emerge).\r\n\r\n<b>Evidence:</b>\r\nNot applicable\r\n\r\n<b>Open Science:</b>\r\nThe paper adheres to the concept of open science quite well. IGSTK source code is freely available. Some of the developer documentation requires a login and password. The nightly generated requirements are also freely available on the web site. I would have liked to see the guidelines for defining requirements (for example, why is a requirement numbered REQ 06.02.13?) as well as the scripts that are used for extracting the requirements from the bug tracker. If done well, this could be as useful to the community as the IGSTK software itself (for example, CMake was developed to support ITK development and is a useful tool on its own).\r\n\r\n<b>Reproducibility:</b>\r\nNot really applicable. It should be possible to reproduce the requirements generation if the scripts were publically available.\r\n\r\n<b>Use of Open Source Software:</b>\r\nYes, the authors use quite a bit of open source software packages (ITK, VTK, FLTK) and development tools (CMake, Dart, CVS, PHPBugTracker) and extoll their virtues appropriately.\r\n\r\n<b>Open Source Contributions:</b>\r\nIGSTK is a work in process, so I have not yet tried it though I plan to use it in the future. I am not sure if I will use the requirements capture method -- that depends on how much it evolves.\r\n\r\n<b>Code Quality:</b>\r\nNot applicable. This paper was not about the code, but about the best practices and requirements definition.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe development process identified in this paper is applicable to nearly every medical software development effort, especially if clinical use is anticipated.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe problem of capturing requirements and maintaining traceability (and consistency) between requirements, software implementation and testing is of critical importance. The current solution of using the bug tracker is a good start, but much more could be done. The nightly-generated requirements document is just a sorted list (based on the requirement number, which is somehow assigned by the programmer) and is not as easy to read as a typical manually-created requirements document. In my opinion, it would be nice to have a hyperlinked traceability matrix in which you can easily navigate between requirement, source code implementation, test procedure and test result.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nI would like more information about the way in which the requirements are numbered.\r\n\r\n<b>Additional Comments:</b>\r\nI am an advisor to this project and am listed in the Acknowledgments.\r\n\r\n", "review_id": 56}], "publication_id": 21},
{"reviews": [], "publication_id": 22},
{"reviews": [{"date": "09-18-2005", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<b>Summary:</b>\r\nAn open-source, view-based (i.e., 2D) image processing system. Ultimate focus is medical image analysis, but also includes routines useful to computer vision (camera geometry, stereo matching).\r\n\r\nWritten in C with some platform specific code for UNIX/Linux/Cygwin. \r\n\r\nThe system was largely developed within one group and is perhaps limited in functionality. It is not appropriate for 3D medical image analysis application development and contains a limited number of methods for 2D image analysis.\r\n\r\nMost of the information below was gathered from the TINA website, not from the paper. The TINA website is excellent, but it revealed the limitations of the system that weren't specifically mentioned in the paper. The TINA website is http://tina-vision.net The website appears very up-to-date - with many papers from 2005. Perhaps, however, the paper is discussing a verision of TINA that supports 3D image analysis and more functions. If so, I apologize for my mistake, and I look forward to clarification from the authors.\r\n\r\n<b>Hypothesis:</b>\r\nThe authors propose that TINA is an effective tool for medical image analysis. In particular, it is useful for cortical thickness estimation.\r\n\r\n\r\n<b>Evidence:</b>\r\nExploring the TINA website suggests that TINA has limited capabilities for representing images and for providing methods that work on multiple types of images. Most notable, (1) a TINA image is a C record that uses a (void *) variable to support different pixel types, (2) it only supports 2D images, and (3) special functions must be written to access vector pixel types.\r\n\r\nRegarding, image processing, TINA appears to only provide a small set of methods. Consider, for example, that the following \"Noise Filters\" are currently available (the following is the documentation from their website):\r\n\r\n<code>\r\nThe following routines can be used for the removal of various forms of noise and unwanted data variation from images.\r\n\r\nImrect *im_bthresh(double k,Imrect *im)\r\n\r\nReturns an image which is a binary thresholded version of the input image around the value defined by 6#6.\r\n\r\nImrect *im_thresh(double k,Imrect *im)\r\n\r\nReturns an image which has been thresholded to set all pixel values below 6#6 to zero. This is useful, for example, in the elimination of unwanted terms in the 2D Fourier domain of an image.\r\n\r\nImrect *im_corrupt(Imrect * im, int dx, int dy, double a, double b)\r\n\r\nGenerate an image by adding uniform random noise (generated by imf_unif_noise(im->width, im->height, dx, dy, a, b)) to the input image. Useful in the generation of simulated test data for the evaluation of algorithm stability.\r\n\r\nImrect *im_rank(Imrect *im, int range, double noise)\r\n\r\nReturns an image with each pixel (of measurement accuracy 11#11 ) given by the rank of its value in the surrounding 12#12 x 12#12 patch. Useful for enhancing the spatial information content of an image before the process of cross correlation or template matching.\r\n\r\nImrect *im_median(Imrect *im)\r\n\r\nReturns a median filtered (discontinuity preserving) version of the input image (each pixel replaced by the median value of the 3x3 neighbourhood). Useful for the removal of sensor or aliasing derived pixel dropout. This technique should only be used when there is no alternative, generally it is better to eliminate the problem at source).\r\n\r\nImrect *im_tsmooth(Imrect * im1)\r\n\r\nReturns an image which has been smoothed by averaging in a direction tangential to the image gradient at each point (discontinuity preserving).\r\n</code>\r\n\r\nRegarding the specific application for cortical thickness estimation, it is interesting that their volume estimation analysis must have been conducted by processing the slices individually and not as a 3D segmentation task. It would be interesting to compare those estimates with estimates made when 3D smoothing and other 3D neighborhood information is considered.\r\n\r\nIn summary, their work is extremely well presented in this paper and in the many other papers presented on their website. Their work is also extremely important and beneficial - clinically and to the image analysis community. This software package, however, is perhaps a bit limited in scope.\r\n\r\n\r\n<b>Open Science:</b>\r\nThe authors and the TINA project have made use of and contributed to open-source. Their system integrates with R and promotes other open-source packages (gnuplot, etc.). They are also making many of their datasets available online.\r\n\r\nHowever, their software product, TINA, is not the most up-to-date image analysis software package available. Users should consider VXL, ITK, MITK, MeVisLab or other pacakges that are more easily extended to other medical image analysis tasks.\r\n\r\n", "review_id": 104}, {"date": "09-08-2005", "author": {"author_id": 87, "author_email": "sylvain@bwh.harvard.edu", "author_lastname": "Bouix", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThis article presents a very interesting toolkit used for cortical grey thickness measurement. The paper gives a very thorough description of the the open source software, TINA, but gives almost no information on the thickness measurement itself. After reading the referenced technical report, thickness is measured by shooting rays normal to the GM/WM boundary and carefully measuring their lengths.\r\n\r\n<b>Hypothesis:</b>\r\nThickness is measured as the length of a straight line connecting the GM/WM surface to the GM/CSF surface.\r\n\r\n<b>Evidence:</b>\r\nThe method is validated as follows. The authors made thickness measurement in 13 young adults and compared their results to the ones of Kabanis et al. made on 20 young adults on a different data set. This form of validation is questionable, but due to the lack of a true gold standard for cortical thickenss measurements it is already quite an achievement that the method is validated.\r\n\r\n<b>Open Science and Reproducibility:</b>\r\nSource code is provided as well as user's and developper's guides. The data is not shared.\r\nI have not tried to reproduce the results and even if I tried and I had the data, I would probably need some training to be able to run the software. Also I did not see any description of the parameters used.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe entire TINA toolkit is open source and it offers a nice alternative to other toolkits.\r\n\r\n<b>Code Quality:</b>\r\nFrom what I browsed on the doxygen pages, the code is nicely written. The main point of discussion is the programing language used for the toolkit (C). Even though I am theoretically inclined to believe C++ offers much greater flexibility for software development, my experience with ITK and its highly templated code is not painless. It would be interesting to see how fast developemnt can be made by both novice and expert programmers in these two very different coding philosophies.\r\n \r\n\r\n", "review_id": 44}, {"date": "09-19-2005", "author": {"author_id": 96, "author_email": "tkapur@bwh.harvard.edu", "author_lastname": "Kapur", "author_firstname": "Tina"}, "content": "<b> Summary </b>\r\nThis paper introduces an open source medical image processing environment, TINA (GNU style, TINA Is No Acronym), and discusses an application that has been developed with it for measurement of cortical thickness from MR images. The goal of the project is to make both source and data available. Currently sources are available but data (for the discussed application at least) is not.\r\n\r\n<b> Open Source/Reproducibility </b>\r\n\r\nThe package is open source -- sources and documentation are available on www.tina-vision.net. It is written in C (GUI in GDK/GTK, Motif) and primarily targets GNU/Linux platforms. It reportedly also compiles on MacOSX and Solaris and instructions are provided on the website for how to run it on a Windows machine using a version of linux that can run off a flash/CD drive without installing any files on the hard drive. I was able to build it under Cygwin in Windows XP (see notes below) and launched a couple of the programs mentioned in the documentation (mri_analysis and example2). \r\n\r\n<b> Open Science/Reproducibility </b>\r\nI did not find either the data used by the authors in the cortical thickness measurement experiment, or documentation on which program I should invoke to compute the measures if I wanted to try it out on my own data. \r\n\r\n<b> Other Comments </b>\r\n-\tI would recommend the README file that is distributed with the source to anyone who wants to learn more about this software. It is a very well written document both for history of the project as well as structure/compilation of the sources. Had I not been compiling in a non-certified environment, I expect the build would have been quite straightforward with the use of this file.\r\n-\tBased on the description of the toolkit, the user interfaces of the provided examples, as well as the documentation on the website, this package seems to be more targeted towards computer vision researchers who might be interested in duplicating/building upon the results created using TINA, rather than for clinical user who would like to, for example, meaure the cortical thickness in their own MR data.\r\n-\tNotes for compiling in Cygwin/Windows XP: 1)commented out AC_MINGW32 in tina-libs/configure.ac and tina-tools/configure.ac, 2) created links from cygwin libtool binary in tina-libs and tina-tools (and renamed the libtool created there),3) reinstalled x11-bin and gtk packages in cygwin. Notes for running the examples: 1)I needed to copy various cygwin dlls from their usual locations (/bin and /usr/X11R6/bin) to the directory from which I launched the examples, even though the PATH environment variable contained these locations 2)run startxwin.bat to start an x server and then ran the examples in tina-tools/toolkits/mri_analysis(example, example2)/tinaTool.exe.\r\n", "review_id": 106}], "publication_id": 23},
{"reviews": [{"date": "09-08-2005", "author": {"author_id": 45, "author_email": "ibitter@nih.gov", "author_lastname": "Bitter", "author_firstname": "Ingmar"}, "content": "\r\n<b>Summary:</b>\r\nThe paper presents a method to classify voxels in MRI brain images into brain tissue classes. It uses probabilistic brain atlases and non-parametric density estimation and entropy minimization to determine convergence of the classification.\r\n \r\n<b>Hypothesis:</b>\r\nThat the method can classify brain tissues better than other state of the art classification methods.\r\n\r\n<b>Evidence:</b>\r\nThere is no evidence for any of the claims. The reader is referred to a currently unpublished paper for the details on mathematics and experiments and comparisons.\r\n\r\n<b>Open Science:</b>\r\nThe paper states that the code is based on and extents ITK. All new components are (or will be) contributed to ITK. However, the implementation is described as work in progress.\r\nNo input data or result images are available. \r\n\r\n<b>Reproducibility:</b>\r\nReproducing the work is impossible without information on what to reproduce.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe described software is open source, based on ITK, and the important classes are well described. However, there are no pointers to the complete application discussed in the paper. It seems that I am supposed to build such an application myself from the existing and new ITK classes.\r\n\r\n<b>Open Source Contributions:</b>\r\nI did not evaluate their contribution, nor double checked that the new classes are in the ITK CVS repository.\r\n\r\n<b>Code Quality:</b>\r\nI did not evaluate the code.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe methods appears to be quite general and can easily go beyond brain tissue classification. With few changes it does not even have to be restricted to MRI data.\r\n\r\n<b>Suggestions for future work:</b>\r\nAdd evidence for the capabilities of your method.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\nThe references have many capitalization errors in the paper titles.\r\n\r\n<b>Conclusion:</b>\r\nThe described additions to ITK are most likely very valuable, but the paper does not provide any evidence for its performance claims and it therefore not an example of open science. It does address a need in the community (if it really works) and there is some background material and probably other applications that can benefit from this work. \r\n\r\nI'll be happy to change my review if the paper adds the missing evidence and makes it easy to reproduce the results.\r\n", "review_id": 48}, {"date": "09-09-2005", "author": {"author_id": 199, "author_email": "gregory-harris@uiowa.edu", "author_lastname": "Harris", "author_firstname": "Greg"}, "content": "<b>Summary:</b>\r\nThe authors propose a (uniform?) map-distortion approach to getting crisp anatomy diagrams for MRI images of an organ whose positional variability with respect to tissue class information is aparently unknown to them. The basal ganglia and perhaps the cerebellum could well be solved this way, but not the cerebral cortex.\r\n \r\n<b>Hypothesis:</b>\r\nThe authors propose the (novel?) hypothesis that tissue segmentation should be contingent on the deformability of a tissue-type probability vector atlas onto the acquisition structural image set; that bias field correction should be iterative and anatomy-based; that a stochastic approach to what sampling of features to use will lead to a convergent labeling of the image set with stable posterior class likelihood images; and that the MRI signal from adjacent voxels constitutes the right pool from which to draw feature samples. In this, the authors' interest in texture-driven \"surface reconstruction\" reported elsewhere appears to be what they have in mind (conjecture).\r\n\r\n<b>Evidence:</b>\r\nThey claim to be evaluating tissue classifications with a \"synthetic data ground truth\" phantom image generation process, but didn't validate the appropriateness of their phantom, either. We didn't even find out if the phantom was based on an MRI scan that classified well.\r\n\r\n<b>Open Science:</b>\r\nThere were no Open Science software submissions with this work-in-progress report.\r\n\r\n<b>Reproducibility:</b>\r\nThe only way to reproduce the work corresponding to this report is to steal their idea and crank out code of our own. However, I already know that prior probability field deformation and bias field estimation are inadequate to solve the problem of classifying the human cerebral cortex volume as to gyri and sulci and as to gray matter wrapped around positionally variable white matter spines.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors dutifully cited their use of ITK, but seemed to miss the point of what someone with experience in brain imaging and already using ITK would want in the way of significant details: knowing that pixel features are stored in an Image class instantiated with a PixelType of [type] Vector is hardly news; instead (in addition?) there should be a discussion of how the kernel size varies from early iterations to late ones: does it go from gross to fine on a schedule? What kind of signal processing filter does this in effect establish, and how does it compare to, say, an edge-preserving filter like itkGradientAnisotropicDiffusionImageFilter?\r\n\r\n<b>Open Source Contributions:</b>\r\nThey provided a flow chart, and said such a scheme is open to user experimentation, but their code has not been released into ITK yet.\r\n\r\n<b>Code Quality:</b>\r\nWe are left to expect they are planning to meet the ITK consortium standards for things added to ITK.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe Parzen method, sorting out worthwhile signal from characterizable error, is general, and suggests considerations of interest to anyone coping with numerically founded map or diagram fitting.\r\n\r\n<b>Suggestions for future work:</b>\r\nStatistical texture is a part of choosing the training classes in the stereotaxic cluster Mahalanobis metric classifier I contributed[1] to brains2, but we found that it was important to have the same prior probabilities for classes everywhere throughout the image. We currently have split bias field correction out as a pre-processing stage (that uses ITK) for our T1-T2 tissue classification workup.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe authors propose an implausible kind of measurement feedback based on stability of its outcome. Someone needs to make the case somewhere that MRI tissue classification is a discrete-outcome maximum likelihood kind of probability estimate, rather than a voxel composition fractions kind of probability estimate as histology would suggest.\r\n\r\n<b>Additional Comments:</b>\r\nBrain tissue classification is an important problem, but one that must be distinguished from the more anatomically positional problem of parcellation into the functioning units of the cerebral cortex and its supporting nuclei. An atlas has no business decreeing whether you may see gray matter at each of the anatomical coordinates you have imaged. \r\n\r\n[1] Harris, G., Andreasen, N.C.,Cizadlo, T., Bailey, J.M., Bockholt, H.J., Magnotta, V.A., and Arndt, S. 1999. Improving Tissue Classification in MRI: A Three-Dimensional Multi-Spectral Discriminant Analysis Method With Automated Training Class Selection. Journal of Computer-Assisted Tomography, 23(1), 144-154.\r\n", "review_id": 54}], "publication_id": 24},
{"reviews": [{"date": "09-19-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper presents a tool for sharing DICOM images by using the Open Source systems DSpace and DCMTK.\r\n\r\n \r\n<b>Hypothesis:</b>\r\nThis paper parts from the hypothesis that a DICOM query retrieve system based on Open Source tools, can be develop for empowering users to share DICOM images.\r\n\r\n<b>Evidence:</b>\r\nA System was developed using DSpace (an open source system for maintaining institutional repositories) and DCMTK a DICOM library. The system is used for managing the images of this current conference, which provides clear evidence for its usability. \r\n\r\n<b>Open Science:</b>\r\nThe paper fully adheres to the principles of Open Science. The full material used and developed by the authors is made available. The source code of the DICOM tools is made available as part of Insight Applications, a DICOM image example is provided in order to test the system, and even the Latex source file of the paper has been uplodaded and shared with the readers.\r\n\r\n<b>Reproducibility:</b>\r\nThe reviewer attempted to rebuild the software but got entangled in a number of issues.\r\n1) This applicationrequires the dcmtk library to be built into the same system\r\n2) A number of modifications were needed in order to configure the system with CMake 2.2\r\n3) The library \"libwrap\" should be installed in the system. This seems to be needed for SSH access.\r\n\r\nAfter this modification, the reviewer still end up in a link error problem that didn't seem to be trivial to solve since it was a missing symbol from the dcmtk library.\r\n\r\nThe reviewer did this with a Debian Linux system, so it seems that some work is required for enhancing the portability of the application.\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors made extensive use of open source tools. In particular\r\n\r\n* dcmtk : DICOM library\r\n* ITK : Image processing\r\n* FLTK : Graphical user interface\r\n\r\n\r\n<b>Open Source Contributions:</b>\r\nThe author have contributed their code already to the Insight Toolkit and it is distributed as part of InsightApplications. Unfortunately the code is not build at this point in all the platforms that are tested in the Dashboard, because it requires dcmtk to be build in the same system. It is worth to make an effort to ensure that this applications gets built nightly in at least the most popular platforms.\r\n\r\n<b>Code Quality:</b>\r\nThe code is well structured and follows the coding style of the Insight Toolkit.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe tool can be reused by converting it into a module of larger applications. It is worth to add an extra GUI designed to be embedded into a main FLTK window, so the entire current application could be the PACS communication module of a larger application.\r\n\r\n<b>Suggestions for future work:</b>\r\nDetaching the application from the GUI may be an interesting thing to pursue. Probably something that should be done by a third party to ensure that the central piece of the query / retrieve functionalities can be used from different GUI fronts.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nAdditional instructions on how to build the application will be appreciated. In particular on how to build dcmtk so that it is compatible with the configuration of the application.\r\n\r\n<b>Additional Comments:</b>\r\nFuture authors submitting papers to the Insight Journal may want to use this appliation as a portal for reusing data that has already been contributed to the image database of the journal.\r\n\r\n", "review_id": 110}, {"date": "08-22-2005", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThis paper describes the combination of the DICOM tools available within ITK (or more specifically, the DCMTK tools) with the DSpace package. The purpose of this work is to create an open, accessible framework for archiving medical image data. \r\n\r\n<b>Hypothesis:</b>\r\nThis work is not specifically hypothesis driven; however, the underlying supposition of this work is that there is a need for a well-defined architecture that for medical image archiving outside the scope of clinical RIS, HIS, and PACS systems\r\n\r\n<b>Evidence:</b>\r\nThe evidence will be generated as the package is used. Given that the submission system for this journal appears to be based on DSpace and the CADDLab MIDAS, I think that this evidence is already being generated. \r\n\r\n<b>Open Science:</b>\r\nThis work is consistent with open science principles.\r\n\r\n<b>Reproducibility:</b>\r\nUnfortunately, I have to say this is the only area where the paper is missing information. I would not be able to reproduce this very easily because the necessary information is not available. It would be beneficial to have an additional documented with this submission which lays out the steps required to link DSpace and DCMTK into a working system.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis project takes full advantage of open-source software to achieve the goals. \r\n\r\n<b>Open Source Contributions:</b>\r\nThe extensions proposed and effort in linking the different packages should add to the open source movement.\r\n\r\n<b>Code Quality:</b>\r\nNot Applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nThis described tool/framework has broad applicability to many different image database collections.\r\n\r\n<b>Suggestions for future work :</b>\r\nCollaborate with everybody.\r\n\r\n<b>Requests for additional information from authors :</b>\r\n\r\nHere are a few suggestions/thoughts â\r\n\r\nIn paragraph 1, you could have better referenced your references. I noted that the DSpace reference was missing right away. Also, in paragraph 1, you refer to the NIH data sharing policy. I suggest that you look for a specific reference about that or suggest that this is your interpretation of what NIH might be interested in.\r\n\r\nIn the same manner, in paragraph 3, it would be appropriate to include a reference for the Library of Congeressâ web-based handle system.\r\n\r\nIn section 2.1 you should consider a reference for proper anonymization or a description of what you information you anonymize. \r\n\r\nI would suggest a simple readme.txt that outlines the necessary steps to create a DADL.\r\n\r\n\r\n<b>Additional Comments:</b>\r\n\r\nThere is no reason that this work shouldn't receive a higher score except there is little information on the creation of a DADL using the work that the authors have done. While most of my suggestions aren't particularly important, I would stress the addition of a readme file for setup. This would not require much effort by the authors, but would dramatically increase the rating.", "review_id": 27}], "publication_id": 25},
{"reviews": [{"date": "09-13-2005", "author": {"author_id": 7, "author_email": "baghdadi@phenogenomics.ca", "author_lastname": "Baghdadi", "author_firstname": "Leila"}, "content": "<b>Summary:</b>\r\n[This paper describes tracking systems for surgical procedures. I think the effort for a proper design before development is the most impressive as I have not rpesonally used the code.]\r\n \r\n<b>Hypothesis:</b>\r\n[Not Applicable]\r\n\r\n<b>Evidence:</b>\r\n[Although the authors have provided urls to support their claim, no example was given in the actual paper. ]\r\n\r\n<b>Open Science:</b>\r\n[Once again, there was no specific example in the paper but judging by list of authors I am sure there is proof for all claims made in the paper.]\r\n\r\n<b>Reproducibility:</b>\r\n[Not applicable]\r\n\r\n<b>Use of Open Source Software:</b>\r\n[The use of ITK , VTK and FLTK guarantees the use of open source software.]\r\n\r\n<b>Open Source Contributions:</b>\r\n[URLs for software and instructions for use was provided.]\r\n\r\n<b>Code Quality:</b>\r\n[Not applicable]\r\n\r\n<b>Applicability to other problems:</b>\r\n[This paper describes a specific tool for surgey so I do not believe it is applicable to everyone's research. However, the design methods and the use of state machines for determining the state of each class can possibly be applied to alot of research probelms.]\r\n\r\n<b>Suggestions for future work:</b>\r\n[Not Applicable]\r\n\r\n<b>Requests for additional information from authors:</b>\r\n[Not Applicable]\r\n\r\n<b>Additional Comments:</b>\r\n[Not Applicable]\r\n\r\n", "review_id": 65}, {"date": "09-15-2005", "author": {"author_id": 6, "author_email": "i.wolf@dkfz.de", "author_lastname": "Wolf", "author_firstname": "Ivo"}, "content": "<b>Summary:</b>\r\nThe architecture of a new toolkit (beta version available) for image-guided surgery and rationale of its design concepts are described. The key goal of the toolkit is to provide âsafety-by-designâ, thus to ensure (or support) robustness of image-guided surgery applications by means of adhering to the toolkits design specifications. A key concept (also mentioned in the paperâs title) to achieve this goal is the use of state machines.\r\n \r\n<b>Hypothesis:</b>\r\nOnly partially applicable: An implicit hypothesis of the paper is that safety-by-design is possible and state machines are suitable to achieve safety-by-design.\r\n\r\n<b>Evidence:</b>\r\nOnly partially applicable: Evidence for the hypothesis can not be expected until the toolkit has been used for real-life image-guided surgery scenarios.\r\n\r\n<b>Open Science:</b>\r\nA real open science project, everything is publicly available via the web-addresses mentioned in the article.\r\n\r\n<b>Reproducibility:</b>\r\nI did download, compile and run the code, but not recently (several months ago). It worked nicely that time.\r\n\r\n<b>Use of Open Source Software:</b>\r\nSeveral open source software are used: ITK, VTK, FLTK.\r\nAdvantages or disadvantages or advice for future users of these toolkits are not described.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe toolkit is open source and in beta stage. If the goal is achieved, it probably will be very useful.\r\n\r\n<b>Code Quality:</b>\r\nThe well proven software process of Kitware is used, even with the goal of 100% testing.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe focus of the toolkit is clearly image-guided surgery. It is explicitly stated that only a very restrictive API is being provided to ensure as high a safety level as possible.\r\n\r\n<b>Suggestions for future work:</b>\r\nPersonal opinion: I like the idea of using explicit state machines (not surprisingly, as we use them also in MITK, although with a different focus). I would be interested in how much they support the âsafety-by-designâ goal, thus would be looking forward to a paper addressing this issue. Be evil, try to do as bad a thing as you can and demonstrate how the state machines stop you from doing this. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nnone\r\n\r\n<b>Additional Comments:</b>\r\nPersonally I do not expect that all bad things can be avoided by the state machine mechanism, but that it will be very useful for testing â not only of the toolkit, but also of the application written using the toolkit, as required by the FDA.", "review_id": 77}, {"date": "09-15-2005", "author": {"author_id": 96, "author_email": "tkapur@bwh.harvard.edu", "author_lastname": "Kapur", "author_firstname": "Tina"}, "content": "<b>Summary:</b>\r\nThis submission is a software toolkit for building Image-Guided Surgery (IGS) applications, and the companion paper describes the state machine abstraction used in the design of the toolkit. The toolkit is written in C++ and builds upon other three other open source toolkits, ITK (for image representation and processing), VTK (for visualization), and FLTK (for user interface). \r\n\r\nThis review consisted of using the instructions in the paper to download the sources and compile the toolkit (under Cygwin on a Windows XP on a Sony Viao S260 laptop with Intel 1.7Gz/512 MB Ram), running the examples, reading technical discussions that have been captured on the IGSTK wiki, joining the mailing list and participating in discussions there, and examining the source code. \r\n\r\n<b> Significance </b>\r\nI think that the creation of IGSTK is very timely. Unlike the scenario of 5-10years ago, when the technology involved in building IGS platforms was novel enough that various research labs created in-house prototypes and used those to perform scientific research, the IGS landscape today is much more mature with several companies building systems and over a thousand hospitals using these commercial systems on a routine basis. This migration of IGS systems into the commercial domain has created somewhat of a logistical void between the research and commercial worlds; Building the software and hardware for such systems from scratch no longer belongs in the research domain but at the same time companies in the area have not yet published interfaces that would allow researchers to easily test their applications/algorithms in a clinical context. I expect IGSTK to be most relevant for researchers who are seeking a software platform on which to add their contributions (such as improvements to the accuracy of a registration algorithm, a novel segmentation algorithm, a novel clinical workflow etc.) without first having to build the platform. \r\n\r\n<b> Hypothesis </b>\r\nI would say that there are three underlying hypotheses in this work: (1) a toolkit is needed for IGS (b) open source is a good way to do it and (c) state machines are a good abstraction for the components of such a toolkit.\r\n\r\n<b> Evidence </b>\r\nOn need and open source: I think that there is general agreement in the field that such a toolkit would be useful and that it's existence could allow researchers to focus on creating novel algorithms and clinical applications. The benefits of open source are well known and hence the argument for an open source version of the toolkit, but I can also see another scenario (with its own overhead, no doubt) that would achieve similar impact in which established IGS companies would provide APIs that would allow researchers to add applications to their existing hardware and software platforms. In fact, IGS companies have considered this options for a while and perhaps the existence of IGSTK will accelerate that process and allow researchers to have multiple options. The benefit of the API would be the availability of both the hardware and the software, while the benefit of the open source software toolkit is that one doesn't need to deal with any commercial entities.\r\n\r\nOn State Machines: The major components of the toolkit (viewers, spatial objects, tracker, logger) are modeled explicitly as state machines with well defined states and transitions. I think that the tracker component is particularly well suited to this abstraction because it models a device with a few clearly defined states and transitions. The use of the abstraction made the code of the tracker classes very simple to follow. I couldn't see the immediate benefit (or hazard) of using the same abstraction for the other components, for which I have seen non state-machine based implementations that do the job just fine. In any case, the motivation for using state machines is to potentially facilitate comprehensive testing, which is a good thing. For the interested reader, an active discussion is ongoing in the group via the mailing list and the wiki pages about how best to utilize hierarchical state machines in the toolkit.\r\n\r\n<b> Misc Points on Open Source/Useability/Code/Practices for Potential Users </b>\r\n- http://www.igstk.org is the best place to get the latest information about the toolkit. and is actively updated.\r\n- Good engineering practices (revision control, nightly builds, error monitoring via dashboards, active mailing lists, reasonable coding style,code reviews, documentation, wiki discussions) are all followed in the project which means that if you start using this toolkit, you will inherit a community that will answer your questions at the very least, and probably also help you move forward in your work.\r\n-Even if you are not interested in using the entire toolkit, some of the components such as the Tracker and the SpatialObjects can be used independently. The tracker component allows easy intergration of different trackers (NDI trackers are currently supported) and also has a very useful simulation mode to allow testing/demo without a physical tracker.\r\n-The learning curve for users who are not familiar with the VTK and ITK worlds will be steep. For example, I don't use cmake in my daily life, so I always spend the bulk of my installation cycles reminding myself on how to use it.\r\n-Some installation notes: I started with the iteration-2 tag, but quickly moved to the cvs head to take advantage of the additional bug fixes and features. If you are using Tortoise on Windows to interface to cvs (like I do), ensure that the tags are set correctly when you decide to move from the iteration-# tag to the head. I also had to comment out a line in the file igstkImageSpatialObjectRepresentation.cxx (line 170 in v1.1. of the file) to be able to compile. I figured I'd revisit it if I was missing any functionality in the examples, but didn't seem to.\r\n-The developer mailing list is quite active and the IGSTK team is very responsive to outside questions/input. If you are considering using this toolkit down the road, you might find it beneficial to get involved with the group now and share your use-cases with them. \r\n- The tool is a work in progress, as are the example programs available with it. The team plans to release a clinically realistic application example this year, which should showcase more of its functionality.\r\n\r\n<b> Overall </b>\r\nI am giving this paper a 4 rating because it satisfies all the criteria of good open source in terms of mechanics, and I also think that the end result will be useful to the field and the current state of the work shows every indication that it will get there within the year. For folks who are interested in checking it out right now, my suggestion is that the time you will spend getting a working copy of the toolkit on your machine will be worthile if you are a developer and would like to be an informed participant in the discussions that are shaping the toolkit. If your interest is to use the toolkit to build your own application, I would recommend waiting until the first clinical tracking application is released later this year.\r\n\r\n", "review_id": 70}], "publication_id": 26},
{"reviews": [], "publication_id": 27},
{"reviews": [], "publication_id": 28},
{"reviews": [{"date": "09-19-2005", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<b>Summary:</b>\r\nDescribes an toolkit for generating meshes for MR volumes. Summarizes the software architecture, illustrates results, and provides experimental results from comparison with a commercial package.\r\n\r\nThe documentation provided with the code states that the software is for non-commecial-use only. I wish the authors had stated that in their paper. I also wish they would clarify if this includes its use in grant funded research which has been ruled to be a commecial use by the courts. This limited licensing dampens my enthusiam for the software.\r\n\r\nMy main focus during this review has been the installation of the software. My initial experiences are given next.\r\n\r\n<b>Installation Notes:</b>\r\nI attempted to download and install this package.\r\n\r\n<ol>\r\n<li> It requires the installation of subversion to access the package </li>\r\n<li> The package requires three other software packages. The authors did not provide links to those packages in the documentation distributed with the code.\r\n<ol> \r\n <li> http://www.lam-mpi.org/ A message passing interface for parallel computation - does not use cmake </li>\r\n <li> http://www-unix.mcs.anl.gov/petsc/petsc-as/download/index.html This software also requires the installation of Python and the rebase modules for Cygwin. </li>\r\n <li> VTK is also required - but this is not mentioned in the paper or in the documentation provided with the code - uses cmake </li>\r\n</ol>\r\n<li> The MPI license is open source - YEAH!\r\n<li> The PETsc license requires special compilation options to turn off GNU licensed code that otherwise restricts the binary redistribution and use of the code. See: http://www-unix.mcs.anl.gov/petsc/petsc-as/documentation/copyright.html\r\n<li> My laptop ran out of disk space when installing python and rebase on cygwin </li>\r\n</ol>\r\n\r\nOverall, the software seems to be simple to install, but the process is more complex and time consuming than the authors imply in their paper. The use of other open source packages is applauded, but in this case, the mix of technologies used by those packages confounds the installation process. \r\n\r\nThe reality is, however, that there are few, if any, alternative solutions to the problems being addressed by this package. It is an important contribution to the field. Its burden is light relative to the potential benefits.\r\n\r\n<b>Evidence:</b>\r\nThe paper provides illustrative and experimental results.\r\n\r\nThe illustrative results are clearly presented.\r\n\r\nThe experiment results are convincing. The authors compared their method with a commercial system. The commercial system was deemed the gold standard. Their system produced a mean Hausdorff distances of ~2mm and a max distance of ~7mm compared to the commercial system. These measures were calculated using MR data from three neurosurgical patients. The time required for mesh generation is 5 minutes for pre-processing and 10-25 seconds for mesh generation.\r\n\r\n<b>Open Science:</b>\r\nThe code is a mix of open and limited-open source. The main code is limited to non-commercial use. The secondary packages require the specification of compilation options to eliminate code with GNU licensing restrictions. It is unclear what impact the use of the alternative code will have on the performance of the system.\r\n\r\nThe data used in the experiments are not publicly available, but some testing data is provided with the code.\r\n\r\n\r\n<b>Reproducibility:</b>\r\nI am fairly confident that I could reproduce the results stated.\r\n\r\n<b>Open Source Software:</b>\r\nThe system is not completely open-source - it is not available for commecial use - it is unclear if it can be used for grant funded research.\r\n\r\nThe packages used are open-source, but they have very different installation needs. This complicates the installation process.\r\n\r\nThe intended application is intra-operative processing for surgical guidance. Therefore a parallel implementation is being pursued. However, for more general use, it would be nice if requirement for an MPI library could be turned-off as a cmake option.\r\n\r\n<b>Code Quality:</b>\r\nThe installation code has holes as noted above.\r\n\r\nMost of the source code is very well documented. Doxygen comments are very good in most files. The ITK coding style is followed in most files.\r\n\r\nCertain files (e.g., tetra_mesh.h) appear to be converted C code. They do not use doxygen comment style or ITK coding style.\r\n\r\nThe authors' intent is to integrate this code with ITK. The non-conforming files would need to be updated prior to such integration.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe algorithms is much needed by the field and broadly applicable. I look forward to the refinement of the code and the installation process.\r\n\r\n", "review_id": 107}, {"date": "08-22-2005", "author": {"author_id": 165, "author_email": "duboisda@tele.ucl.ac.be", "author_lastname": "Du bois d'aische", "author_firstname": "Aloys"}, "content": "\r\nThe authors present what looks to be a very nice implementation of Molino's paper. This paper does not describe the details of the method which may be found in the original paper but brings forward the efficiency of their implementation in terms of speed and quality of the elements generated.\r\nThis opensource implementation may be an important contribution for all the algorithms using ITK and which need meshes composed of well-shaped elements.\r\n\r\n\r\n", "review_id": 37}, {"date": "02-01-2006", "author": {"author_id": 102, "author_email": "sylvainjaume@gmail.com", "author_lastname": "Jaume", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThe authors provide some code to address a generic issue in Medical Imaging and beyond: the creation of 3D meshes from binary images.\r\nThey implement the method of Molino et al. using ITK, VTK, PETSc and some code written by Jonathan Shewchuk.\r\n\r\n<b>Hypothesis:</b>\r\nThe authors make the reasonable assumption that the mesh quality can be assessed by tetrahedron aspect ratio and minimum dihedral angle.\r\n\r\n<b>Evidence:</b>\r\nThe authors provide a convincing comparison with the commercial mesher GHS3D. The paper is clearly presented and illustrated with renderings and statistics.\r\nWhat is the justification of the resampling? Does this impact the quality of the results?\r\n\r\n<b>Open Science:</b>\r\nCould the authors provide the data they used (case #1, case #2, and case #3)?\r\nOther data are provided, but having the exact same data would make possible the reproduction of the results and the comparison with future methods.\r\n\r\n<b>Reproducibility:</b>\r\nI did not reproduce the authors results since I did not install all the required packages (for example PETSc).\r\nI believe that it is possible to reproduce the results shown in the paper when all the packages are installed and the same data is available.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors use other Open Source packages. Dependence on MPI, PETSc and Shewchuk\\'s code could be painful for installation and maintenance.\r\nDo the authors plan to remove those dependencies? or provide a CMakeLists.txt that would simplify the build?\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors provide all their source code in a clean directory structure. Thanks! :-)\r\n\r\n<b>Code Quality:</b>\r\nThe code looks very good and is easy to read. I did not check if the code compiles on different platforms.\r\nCould the authors comment on that?\r\n\r\n<b>Applicability to other problems:</b>\r\nI believe that this implementation could be very useful to many applications in Medical Imaging and other disciplines.\r\n\r\n<b>Suggestions for future work:</b>\r\nI would be interested to see the application of this very valuable implementation to more sophisticated geometries and to the surgery of highly deformable anatomical structures.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe results section is very clear. Additionally I would suggest the comparison of this method with the method of Alliez et al., Variational Tetrahedral Meshing, 2005.\r\n\r\n<b>Additional Comments:</b>\r\nThe URL might have changed since the first publication of this paper. I found the source code at\r\nhttp://www.na-mic.org:8000/svn/NAMICSandBox/trunk/TetrahedralMeshGeneration/\r\n(the URL on page 4 does not have the /trunk)", "review_id": 167}], "publication_id": 29},
{"reviews": [{"date": "09-08-2005", "author": {"author_id": 45, "author_email": "ibitter@nih.gov", "author_lastname": "Bitter", "author_firstname": "Ingmar"}, "content": "<b>Summary:</b>\r\nThe paper presents a suite of bio-medical applications for visualization and analysis of neuro, cardiac, abdominal and other MRI and CT images. The applications use VTK, ITK and Tcl and all have a similar look and feel, but are very targeted to particular clinical needs.\r\n \r\n<b>Hypothesis:</b>\r\nThat the application suite can efficiently address various clinical image analysis needs.\r\n\r\n<b>Evidence:</b>\r\nThere are several screen shots of the various applications in action, but no measurable results, no comparison to other applications and no details of the underlying math.\r\n\r\n<b>Open Science:</b>\r\nThe paper states that the code is based on and extents ITK and VTK. However, none of the code is presently available and none of the datasets used to make the images are posted.\r\n\r\n<b>Reproducibility:</b>\r\nReproducing the work is impossible without the data and the code or applications.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe described software is planned to be open source in the future. None of the implementation specifics are described in the paper.\r\n\r\n<b>Open Source Contributions:</b>\r\nI could not evaluate their contribution.\r\n\r\n<b>Code Quality:</b>\r\nI could not evaluate the code.\r\n\r\n<b>Applicability to other problems:</b>\r\nWhile the the applications are very task specific, the set of modules and classes should allow many new applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nMake the code and applications available. Make example data available, post measurable results and make it easy for others to reproduce those results.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\n\r\n<b>Conclusion:</b>\r\nThe described applications are most likely very valuable, but it is hard to evaluate without access to the applications and data. But at least the screenshots look promising. The application suite does address a need in the community and probably other applications that can be build based on this work. \r\nI'll be happy to change my review if a revision of the paper adds the missing evidence and makes it easy to reproduce the results.", "review_id": 49}, {"date": "09-19-2005", "author": {"author_id": 96, "author_email": "tkapur@bwh.harvard.edu", "author_lastname": "Kapur", "author_firstname": "Tina"}, "content": "<b>Summary:</b>\r\nThis paper describes BioImage Suite, a collection of GUI driven medical image analysis applications as well as command line tools and support for batch processing. The applications are all created from a common set of underlying modules and have similar look and feel. This suite of applications is in use in various labs at Yale, and the authors expect that it will be publicly available by the end of 2005. The paper provides a listing of the algorithms and applications in the package (on pages 2 and 3) and the takeaway is that most major areas of medical image analysis research is covered in some form in this suite (bias correction for segmentation, deformable registration, fmri activation detection/roi analysis, diffusion image analysis, shape based cardiac deformation are some examples). An interesting feature that is unique to BioImage Suite is that it has an interface to a commercial Image-Guided Surgery System (Brainlab).\r\n\r\n<b>Open Science/Reproducibility/Open Source Contributions/Code Quality</b>\r\nThis work does not currently contribute much to open science/source since the programs (either executables or source) are not available at this time. However, the authors intend to make the software publicly accessisble by the end of the year. If I understand the intended licensing plan correct, it is to (a) make all algorithm implementations available under GPL and (b) to make all GUI-based applications available under a dual license (like mySQL) in which a GPL license is available to those who intend to keep the modified source code open, and a commercial license to those who intend to restrict access to the source.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors report using VTK/ITK/TCL/TK.\r\n\r\n<b>Suggestions for future work:</b>\r\n- My recommendation to the authors would be to try to pick the brains of a research group that has recently converted their in-house tools (and licenses) to an open source model.\r\n- A few typos in the paper: search for \"BuiImage suite includes a clean\" and remove the \"is included in BioImage Suite\" from the end of the sentence. Search for \"The later also\" and replace with \"The latter also\". In the Graphical Applications section: the numbering of tools starts with (v) at the fmriTool - add numbers to the ones listed earlier in the section. Search for \"the SPECT processing toll written by\" and add \"(b)\" in front of it. Search for \" the PET processing package developed\" and add \"(c)\" in front of it. Search for \"will be release using the\" and replace with \"will be released using the\".\r\n\r\n<b> Other Comments </b>\r\n\r\n- The interface to the Brainlab Image-Guided Surgery system is a unique attribute of this package. I believe that such interfaces will allow easier transition of cutting edge algorithms/applications from research labs to widely used IGS systems. This work, combined with the IGSTK toolkit for image-guided surgery (also an entry in this journal issue), are all steps in the right direction for the field of image-guided surgery.", "review_id": 97}], "publication_id": 30},
{"reviews": [], "publication_id": 31},
{"reviews": [], "publication_id": 32},
{"reviews": [], "publication_id": 33},
{"reviews": [{"date": "09-14-2005", "author": {"author_id": 131, "author_email": "gk@bwh.harvard.edu", "author_lastname": "Kindlmann", "author_firstname": "Gordon"}, "content": "<b>Summary:</b>\r\nThe paper lays out software and framework considerations for a multi-site approach to medical simulation, including issues such as collision detection. The approach described as based on mapping and multi-representation, so that different computational and physical aspects of interacting objects can be communicated. The details of how the system actually works are very sparse, however.\r\n\r\n<b>Hypothesis:</b>\r\nNon Applicable\r\n\r\n<b>Evidence:</b>\r\nThe substantial lack of references/citations hinders the evaluation of this work, because it makes it difficult to asses the novelty of the framework presented. The Introduction, in particular, lacked references to any other work in medical simulation or its computational components. The discussion of collision detection did not reference any of the large computer graphics literature on the subject (for example, a variety of datastructures have evolved to support efficient evaluation of collision detection). The actual evidence in the paper, such as it was, was in the form of Section 3 (\\\"Proof of concept\\\"), which is more in outline form than a textual exposition. The details are sufficiently sparse that it is hard to know how rudimentary a system created Figures 2 and 3.\r\n\r\n<b>Open Science:</b>\r\nUnfortunately there are few if any specific contributions to Open Science in this paper, although it may well be that when released the \\\"Open Framework\\\" described will be a significant contribution. As this paper is essentially a report about an proof-of-concept (and unreleased) implemenetation.\r\n\r\n<b>Reproducibility:</b>\r\nUnfortunately there is no means of Reproducibility here because there was no code release and no instructions on how to regenerate results. \r\n\r\n<b>Use of Open Source Software:</b>\r\nThere is a distinct lack of detail in this respect. It is not clear from the paper what software generated Figures 2 and 3, for example, and whether it is Open Source. In general, the paper describes an \\\"Open Framework\\\", but the text of the paper does not describe if the software developed the framework will all be open source. Reference 4 mentions \\\"open source\\\", but it is not clear what role that software plays in the work described. \r\n\r\n<b>Open Source Contributions:</b>\r\nNo code was made availble. There is mention of something being done for Medicine Meets Virtual Reality 2006, but there is no code release associated with whatever generated Figures 2 and 3.\r\n\r\n<b>Code Quality:</b>\r\nNo code was made available for this paper, or was any described in sufficient detail to answer this point. Issues of language choice, platform specificity, performance, and testing, are not addressed.\r\n\r\n<b>Applicability to other problems:</b>\r\nGeneral computational frameworks for this sort of problem would be a useful back-end for any number of medical imaging efforts. At the current level of detail, it hard to suggest specific connections to other problems or efforts.\r\n\r\n<b>Suggestions for future work:</b>\r\nI look forward to seeing a more fleshed-out version of the work described in Section 3!\r\n\r\n<b>Requests for additional information from authors:</b>\r\nNo specific information is needed from the authors. As noted above, the paper is lacking references and implementation specifics.\r\n\r\n", "review_id": 73}, {"date": "09-19-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis papers describes an open framework for performing medical simulation. This simulation is done at the organ level by generating geometrical models and providing support for collision detection functionalities, as well as simulating physical properties of biological tissues. The framework supports haptic interfaces. Physiology is not currently part of the simulation. The work seems to be currently at the design and prototyping stages.\r\n \r\n<b>Hypothesis:</b>\r\nThe paper advances the hypothesis that anatomical some physical aspects of anatomical organs can be simulated in software with enough accuracy for being used in medical applications such as training.\r\n\r\n<b>Evidence:</b>\r\nThe paper does not provide evidence to support the hypothesis. Instead it describes the design rationale of the framework, and provides an overview of the functionalities that will be implemented.\r\n\r\n<b>Open Science:</b>\r\nThe paper does not adhere to the practice of open science, since readers are not given the elements that will allow them to verify the claims made on the paper.\r\n\r\n<b>Reproducibility:</b>\r\nThe paper do not enable reproducibility since it is centered in describing a set of design criteria and a set of software requirements.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors do not explicity specify whether the final simulation framework will be made open source.\r\nThe reviewer speculates that this is the case, but still remains to be seen what licensing mechanism is selected by the developers of the framework.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors do not provide source code, and it is not clear if they will do it in the future, once the framework is implemented.\r\n\r\n<b>Code Quality:</b>\r\nCode quality could not be assesed due to the lack of source code availability.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe reviewer considers that a medical simulation tool will have a large set of application, but given that there are similar ongoing efforts it is unclear why users will prefer this framework to other medical simulation software.\r\n\r\n<b>Suggestions for future work:</b>\r\nIf the authors are interested in making their software available, the reviewer suggest that they consider the approach of \\\"release early, release often\\\".\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe reviewer will appreciate if the authors can clarify their use of open source tools, and their intention on the final distribution of their software.\r\n\r\n<b>Additional Comments:</b>\r\n\r\n\r\n", "review_id": 112}], "publication_id": 34},
{"reviews": [{"date": "08-08-2005", "author": {"author_id": 54, "author_email": "vincent-magnotta@uiowa.edu", "author_lastname": "Magnotta", "author_firstname": "Vincent"}, "content": "<b>Summary:</b>\r\n[Short description of the paper. In two or three phrases describe the problem that was addressed by the authors and the approach they took to solve it.]\r\nThis paper describes a Bayes based segmentation of cortical regions using MR images and expert based definitions for training the Bayes based classification. This was used to define DLPFC. \r\n\r\n<b>Hypothesis:</b>\r\n[If Applicable: Describe the assumptions that the authors have made and they hypothesis of their work, note that not all papers will fit the model of hypothesis driven work, for example, the description of an image database, or the description of a toolkit will not be driven by an hypothesis, in which case, please simply write : âNon Applicableâ in this field or delete the subtitle.]\r\nAnatomical variavbility is not sufficiently large in DLPFC to allow a Bayes based classification to be applied to this region without additional image registration.\r\n\r\n<b>Evidence:</b>\r\n[Describe the evidence that the authors provide in order to support their claims in the paper. This is a key component on Open Science, opinions that are not supported by evidence should be labeled as âspeculationsâ or âauthorâs opinionâ while. The same rule applies to the text of the reviews: claims should be supported by evidence]\r\nThe authors present DICE measures of region agreement. It is unclear why only single slice DICE metrics are provided instead of a 3D measure.\r\n\r\n<b>Open Science:</b>\r\n[Describe how much the paper and its addendums adhere to the concept of Open Science. Do the authors provide the source code of the programs used in their experiments? Do the authors provide the input images that they used? Or are those images publicly available? Do the authors provide the output images that they show in the paper? Do the authors provide enough details for you to be able to replicate their work?\r\nThe authors provide source code. No manual defined ROIs or image data is provided.\r\n\r\n<b>Reproducibility:</b>\r\n[Did you reproduce the authorsâ work?\r\nDid you download their code? Did you compile it? Did you run it?\r\nDid you managed to get the same results that they reported?\r\nWere there information missing from the paper, that was necessary for you to reproduce the work? Suggest improvements that will make easier for future readers to reproduce this work.]\r\n\r\n<b>Use of Open Source Software:</b>\r\n[Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]\r\n\r\n\r\n<b>Open Source Contributions:</b>\r\n[Do the authorâs provide their source code? Is it in a form that is usable? Do they describe clearly how to use of the code? How long did it take you to use that code?]\r\n\r\n\r\n<b>Code Quality:</b>\r\n[If the authors provided their source code: Was the code easy to read? Did they use a modern coding style? Did they rely on non-portable mechanism? Was it suitable for multiple-platforms?]\r\n\r\n<b>Applicability to other problems:</b>\r\n[Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]\r\nThis approach has great potential for a variety of applications. \r\n\r\n<b>Suggestions for future work :</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\n\r\n\r\n<b>Requests for additional information from authors :</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\nThe authors may want to specifiy how this algorithm relates to the work of Fischl et al.\r\n\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 26}, {"date": "09-16-2005", "author": {"author_id": 8, "author_email": "gavinb@cs.mu.oz.au", "author_lastname": "Baker", "author_firstname": "Gavin"}, "content": "<b>Summary:</b>\r\n\r\nThis paper presents a statistical approach to segmenting MRI brain scans. It extends a method described by Teo et al. It is an implementation of a K-means classifier.\r\n\r\n<b>Hypothesis:</b>\r\n\r\nThe first stated assumption is that \"the value of each voxel intensity in a given class can be considered as a random variable, independent across pixels\". The second assumption is that the voxel intensities are normally distributed. The hypothesis of the paper is that <i>a priori</i> intensity statistics can be derived from an image which can then be used to segment the tissue types.\r\n\r\n<b>Evidence:</b>\r\n\r\nThe authors present segmentation results on two different MRI data sets. These results could not be reproduced, as the data and parameters were not provided.\r\n\r\nThe data used for validation was first from coronal MRI scans. The data was hand-segmented and compared with the classified output of the program. The correspondence in all 10 cases was very good (>0.7). The second test involved a single ROI from an MRI of the prefrontal cortex. The correspondence with manual segmentation was similarly high.\r\n\r\n<b>Open Science:</b>\r\n\r\nThe paper includes full source, but no data or parameters.\r\n\r\nThe full details of the algorithm are not included in this paper, apparently due to space constraints. This makes it difficult to evaluate the algorithm, verify the claims and implementation.\r\n\r\n<b>Reproducibility:</b>\r\n\r\nNo data was provided to reproduce the findings in the paper. At least one data set and accompanying parameters should be supplied, in order to enable people to reproduce the results.\r\n\r\nI downloaded, compiled and ran the program. It was built on a Debian GNU/Linux Pentium 4 system with GCC 3.3 and ITK CVS.\r\n\r\nIn the absence of any test data, I obtained a data set from BrainWeb (http://www.bic.mni.mcgill.ca/brainweb/). The dataset selected was Modality=T1, Protocol=ICBM, Phantom_name=normal, Slice_thickness=1mm, Noise=3%, INU=20%. Since the implementation works in 2D, I selected slice 87 for testing (being close to those shown in the paper, with bone, white matter, grey matter, and CSF - bone was note removed as mentioned in the paper). The histogram of this slice reveals 4 peaks (at approx 3.5, 42.1, 99.0, 133.2) representing the four classes mentioned above.\r\n\r\nThe program was run, specifying 2 filter passes and 4 classes. The output is shown below:\r\n\r\n<pre>\r\ncluster[0]-- \r\n estimated mean : 4.70918\r\n estimated covariance : 27.4318\r\ncluster[1]-- \r\n estimated mean : 46.2727\r\n estimated covariance : 136.147\r\ncluster[2]-- \r\n estimated mean : 97.0753\r\n estimated covariance : 98.3453\r\ncluster[3]-- \r\n estimated mean : 133.666\r\n estimated covariance : 103.385\r\nPrior image in initial section [0.25, 0.25, 0.25, 0.25]\r\nRawData image in initial section 0\r\nData image in initial section [1.79769e+308, 1.79769e+308, 1.79769e+308, 1.79769e+308]\r\nInitial Posteriors [4.49423e+307, 4.49423e+307, 4.49423e+307, 4.49423e+307]\r\nAfter renormalizing in initial section [0, 0, 0, 0]\r\nPosteriors after smoothing in initial section [nan, nan, nan, nan]\r\nLabel image in initial section 0\r\nPosteriors after decision rule in initial section [nan, nan, nan, nan]\r\n</pre>\r\n\r\nThe K-means clustering correctly identified the peaks in the histogram corresponding to the 4 classes to within a small degree. The labelled output was blank, presumably due to the zeros and nans in the results above. It appears the program failed to calculate the initial posteriors correctly. Further results were not persued.\r\n\r\n<b>Use of Open Source Software:</b>\r\n\r\nThe implementation is an extension of ITK, and adds a utility class. The algorithm described is intended to ultimately be contributed also, once it has been rewritten as a proper ITK filter.\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\nSource is provided to test the algorithm in the form of a command-line program, which appears to be portable. The paper describes how to use the code. However as it stands the algorithm is implemented as one monolithic function as main(), and is not reusable in its current form.\r\n\r\n<b>Code Quality:</b>\r\n\r\nThe code did not build as published. The CMakeLists file needed to be changed to refer to the main driver program, and some corrections needed to be applied to KnowledgeBasedSegmentation.cxx in order to compile and run correctly:\r\n\r\n<pre>\r\n--- orig/KnowledgeBasedSegmentation.cxx 2005-09-16 18:03:11.898713993 +1000\r\n+++ ./KnowledgeBasedSegmentation.cxx 2005-09-16 19:27:30.498662560 +1000\r\n@@ -37,7 +37,7 @@\r\n int main( int argc, char * argv [] )\r\n {\r\n \r\n- if( argc < 8 )\r\n+ if( argc < 5 )\r\n {\r\n std::cerr << \"Missing command line arguments\" << std::endl;\r\n std::cerr << \"Parameters: inputFileName outputFileName nSmoothingIterations nClasses\" << std::endl;\r\n@@ -46,8 +46,8 @@\r\n \r\n char * rawDataFileName = argv[1];\r\n char * labelMapFileName = argv[2];\r\n- int nSmoothingIterations = argv[3]; // USER VARIABLE (DEFAULT = 10)\r\n- unsigned int nClasses = argv[4];\r\n+ int nSmoothingIterations = atoi(argv[3]); // USER VARIABLE (DEFAULT = 10)\r\n+ unsigned int nClasses = atoi(argv[4]);\r\n float timeStep = 0.1; // USER VARIABLE (DEFAULT = 0.1)\r\n float conductance = 3.0; // USER VARIABLE (DEFAULT = 3.0)\r\n</pre>\r\n\r\nThe implementation is provided largely in one very large main() function. This does not follow the principles of modular design, and prevents the algorithm being reused in other projects. The coding style is fairly consistent but sparsely commented.\r\n\r\nAs shown above, the program did not appear to run correctly to completion, so no real results were obtained.\r\n\r\nThe code uses only standard ITK and C library functions, and should be easily portable to common platforms.\r\n\r\n<b>Applicability to other problems:</b>\r\n\r\nThis technique could be developed further and extended to apply to other k-class segmentation problems.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\nThe explanation of the algorithm design could benefit from expansion.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\nWhy is the algorithm only working in 2D with individual slices?\r\n\r\nWhy does \"removing\" the bone improve the results? Surely it is simply another tissue class?\r\n\r\nWhy did you choose DICE to compare the segmentation results?\r\n\r\nIt would be very helpful to provide at least one test data set and the parameters required to reproduce the data you describe in the paper.\r\n\r\nSteps 2-4 need further explanation and discussion.\r\n\r\n<b>Additional Comments:</b>\r\n\r\nMany people view the term \"knowledge-based\" as a fairly significant claim, often overused, in that \"knowledge\" is a very high-level concept implying experience, ideas and inferences. In other words, much more than just facts, data or statistics. In this case, the segmentation is ostensibly based on <i>a priori</i> statistics, which is arguably not the same as \"knowledge\".\r\n\r\nIn this instance, <i>a priori</i> information is not gathered from other training data sets. The statistics are gathered from the one image, and the cluster means are used to classify each voxel using a MAP approach. It is probably a stretch to call this \"knowledge-based\".\r\n\r\nThe paper does not discuss other statistical approaches, nor contextualise this research.\r\n\r\nAs the paper suggests this is part of ongoing work, the newer more developed versions could serve as a useful addition to the ITK codebase.\r\n", "review_id": 85}], "publication_id": 35},
{"reviews": [{"date": "08-10-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper describes the use of the Open Source software, the Insight Toolkit (ITK), for supporting a real-time system for processing ultrasound images at real-time, about 10 to 20 frames per second.\r\n \r\n\r\n<b>Hypothesis:</b>\r\nThe point of the paper is to demonstrate that Open Source software is efficient enough for processing images at real-time rates, in this particular case at 10 frames per second.\r\n\r\n<b>Evidence:</b>\r\nThe authors developed a system that interfaces with an ultrasound probe (Terason), grabs images by using a clever trick through a copy of an OpenGL texture into memory, and then save the input images into files. The authors experimented by writing to a hard drive and to an external drive connected through a USB 2.0 port. Their observations indicate that 20 frames per second was to high of a rate for the system to sustain, while a rate of 10 frames per second was suitable for saving the images into disk and simultaneously displaying them using OpenGL.\r\n\r\n<b>Open Science:</b>\r\nThe paper does not fully adhere to the practice of Open Science, because the content of the paper cannot be fully reproduced due to two reasons\r\n\r\n<ul> \r\n<li>The work relies on the use of a particular hardware and software, the Terason Ultra-Sound probe.\r\n<li>The source code was not provided\r\n</ul>\r\n\r\nThe paper is still a valuable contribution, since it let other developers know that Open Source is efficient enough for being used in real-time systems.\r\n\r\n\r\n<b>Reproducibility:</b>\r\nThe exact work reported in the paper can not be reproduced by this reviewer due to lack of access to an Ultrasound probe and to the author's source code. However the reviewer could verify the performance claims made in this paper, by running similar processing and checking the time required to write images on disk.\r\n\r\nThis verication was done by using as source code a modification of the example:\r\n\r\n Insight/Examples/IO/ImageReadWrite.cxx\r\n\r\nThe pixel type in this code was changed from \"unsigned short\" to \"unsigned char\".\r\n\r\nIn this file, the try/catch block that invokes the writer->Update() method was put inside a for() loop from 0 to <100, and an itk::TimeProbe was added to Start() before the loop and to Stop() just after the loop. This test was set to write the image in a directory located in an external drive Maxtor \"OneTouch\", 120Gb, connected using a USB 2.0, through a USB hub of four ports. The code was run from a laptop DELL Latitude D810, with a Pentium M 750 at 1.86 GHz, running Windows XP. The code was compiled with Visual Studio .NET 2003, in Release mode.\r\n\r\nThe test used as input image the classical Lena at 512 x 512 from\r\n\r\n http://web.onetel.net.uk/~simonnihal/texcom/lena.html\r\n\r\n\r\nWriting this image 100 times in <b>PNG format</b>, in the USB 2.0 external drive took the following times (in seconds)\r\n\r\nTest 1 = 18.672\r\nTest 2 = 17.718\r\nTest 3 = 17.609\r\nTest 4 = 18.453\r\nTest 5 = 18.015\r\n\r\nThat is an average of 5.52 image per second.\r\n\r\nWhen a <b>JPEG format</b> was used for writing, with the default compression of the JPEG ImageIO writer in ITK , \r\nthe times (in seconds) became:\r\n\r\nTest 1 = 8.734\r\nTest 2 = 8.906\r\nTest 3 = 8.735\r\nTest 4 = 8.531\r\nTest 5 = 9.062\r\n\r\nThat is an average of 11.37 images per second.\r\n\r\nWhen using a <b>MetaImage</b> format, which is composed of a header file and an uncompressed raw binary file,\r\nthe times became:\r\n\r\nTest 1 = 4.406\r\nTest 2 = 5.062\r\nTest 3 = 5.312\r\nTest 4 = 4.859\r\nTest 5 = 5.453\r\n\r\nThat is an average of 19.92 images per second.\r\n\r\n\r\nThe authors do not mention the fileformat used for writing, but the values above indicate that the fileformat used for writing is a critical decision when performace is relevant to the writing process.\r\n\r\nIn any case, the reviewer verified that it is possible to write images of 8bits/pixel and 512 x 512 pixels into an external drive through a \r\nUSB 2.0 connection at rates of 10 to 20 images per second.\r\n\r\n\r\n\r\nWriting in an internal hard hardrive of 60 Gb at 7200 RPM produced the following results, again for writing 100 images:\r\n\r\n<b>PNG format </b> in seconds\r\n\r\nTime 1 = 9.234\r\nTime 2 = 9.718\r\nTime 3 = 9.235\r\nTime 4 = 9.156\r\nTime 5 = 9.125\r\n\r\nThat is an average of 10.76 images per second.\r\n\r\n\r\n<b>JPEG file format</b> in seconds\r\n\r\nTime 1 = 3.750\r\nTime 2 = 3.812\r\nTime 3 = 3.641\r\nTime 4 = 3.625\r\nTime 5 = 3.531\r\n\r\nThat is an average of 27.23 images per second\r\n\r\n\r\n<b>MetaImage Format</b> in seconds\r\n\r\nTime 1 = 1.437\r\nTime 2 = 1.015\r\nTime 3 = 2.734\r\nTime 4 = 1.312\r\nTime 5 = 2.171\r\n\r\nThat is an average of 57.67 images per second, however, note the larger variability on the times.\r\n\r\n\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\n\r\nThe authors used the Insight Toolkit (ITK) which is an Open Source package for segmentation and registration of medical images.\r\n\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\nThe authors do not provided their source code along with the paper.\r\nOnly code snippets are included in the text of the paper.\r\n\r\n\r\n<b>Code Quality:</b>\r\n\r\nNot applicable.\r\n\r\n\r\n\r\n<b>Applicability to other problems:</b>\r\n\r\nThe experiment perfomed by the authors is relevant in other image modalities. In particular for image guided surgery suported by fluoroscopic images, where having real time feedback is crucial for guiding the actions of the clinician.\r\n\r\n\r\n<b>Suggestions for future work :</b>\r\n\r\nThe main question that comes to mind is how much actual image processing can be performed at the rates of 10 to 20 frames per second. For example, tracking of objects. It is worth to continue profiling different image analysis methods in the context of real-time systems. Such an effort will foster the improvement of the Open Source software available to the community.\r\n\r\n\r\n<b>Requests for additional information from authors :</b>\r\n\r\nPlease let us know what image file format did you use in your experiments.\r\n\r\n\r\n\r\n<b>Additional Comments:</b>\r\n\r\n\r\n", "review_id": 24}, {"date": "08-16-2005", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThe authors describe the initial effort in capturing ultrasound images from a commercially available US system (Terason, Inc). The effort includes the combination of ITK and a proprietary Windows COM object to extract the image data. \r\n\r\n<b>Hypothesis:</b>\r\nNot Applicable.\r\n\r\n<b>Evidence:</b>\r\nUnclear -- this work appears to just be getting off of the ground.\r\n\r\n<b>Open Science:</b>\r\nDifficult to comment on given that the project appears to just be getting off of the ground.\r\n\r\n<b>Reproducibility:</b>\r\nThe entire code is not available. However, given that the application requires access to specific hardware and proprietary software, the inclusion of code would be for demonstration purposes (which would be valuable).\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nIt seems that the authors used OSS as much as possible.\r\n\r\n<b>Open Source Contributions:</b>\r\nRefer to the Reproducibility comments.\r\n\r\n<b>Code Quality:</b>\r\nNot Applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nThis is difficult to asses, so I can only speculate. This may be applicable in a general sense if it provides a framework for other researchers to capture data into ITK processes using standard windows programming methods. It is unclear if there is enough generality. Second, if the hardware is widely used, different researchers may be able to use this to development independant processing methods. \r\n\r\n<b>Suggestions for future work :</b>\r\nThe work must be extended to meet the expectations of the title.\r\n\r\n<b>Requests for additional information from authors :</b>\r\nSee comments below\r\n\r\n<b>Additional Comments:</b>\r\nWhile I can appreciate the need for real-time ultrasound image analysis, I don't think that this paper meets the expectations. There is no image analysis in the paper and the real-time aspects are only touched upon. Instead, the authors describe image data capture and storage. Data capture and storage is challenging. The particular type of storage and file format can dramatically affect the speed of storage. Moreoever, the use of ITK for storage may also entail overhead which would affect performace (although I have not tested this). Also, the need for an intermediate step of OpenGL viewing seems peripheral if the main goal is only storage for offline analysis.\r\n", "review_id": 29}, {"date": "09-15-2005", "author": {"author_id": 3, "author_email": "julien@jomier.com", "author_lastname": "Jomier", "author_firstname": "Julien"}, "content": "<b>Summary:</b>\r\nThis paper presents a combination of ITK and an Ultrasound device to perform real-time ultrasound acquisition.\r\n \r\n<b>Hypothesis:</b>\r\nNA\r\n\r\n<b>Evidence:</b>\r\nIt is not clear to me why the authors are testing writing on USB drive for real-time application.\r\nWriting into memory might be more useful.\r\nHowever, the paper is well written and well presented.\r\n\r\n<b>Open Science:</b>\r\nThe authors make use of ITK and provide the source code in the paper.\r\n\r\n<b>Reproducibility:</b>\r\nI did not reproduce the results in the paper: an ultrasound system is needed.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors used the Insight Toolkit (ITK). The other third-party libraries are private.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code was provided only as written in the paper.\r\n\r\n<b>Code Quality:</b>\r\nThe code looks good and is using ITK. However this opinion is based only on the code presented on the paper.\r\nMoreover, the code shouldn't be portable since it is using COM object only defined on specific platforms.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe code might be applied to other real-time imaging devices.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors should detail the paper more and state the needs in the clinic. What is the lowest refresh rate a clinician wants to see? \r\nTesting ITK speed to read/write onto memory and apply filters for real-time Utrasound would be nice.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe paper should state the refresh rate of the US.\r\nThe type of disk (rpms) should be also stated.\r\nThe list of references is short. Some links to the Ultrasound device and related info would be a plus.\r\n\r\n<b>Additional Comments:</b>\r\nThe list of areas in medicine is very long...\r\nSpecifying that COM = Component Object Model would be a plus for those non familiar with Windows design.\r\nThe type of file to be written should be stated in the paper\r\n\r\n", "review_id": 45}], "publication_id": 36},
{"reviews": [{"date": "09-16-2005", "author": {"author_id": 8, "author_email": "gavinb@cs.mu.oz.au", "author_lastname": "Baker", "author_firstname": "Gavin"}, "content": "<b>Summary:</b>\r\n\r\nThe stated aim is to determine the location of the boundary between two different tissue types in a medical image at a \r\nsub-pixel resolution. The authors present an optimisation technique that fits a cumulative Gaussian curve to a set of \r\nsample points (intended to represent such a curve). The parameters calculated should then match the data, such that \r\nthe mean (mu) of the Gaussian can be used to determine the boundary point. This is demonstrated by generating a \r\ncurve (possibly adding noise) and sampling it, then passing this to the optimiser to fit.\r\n\r\n<b>Hypothesis:</b>\r\n\r\nThe hyopthesis is that a cumulative Gaussian can be fitted to an intensity profile to determine the location of a \r\nboundary between two tissue types. It assumes that the intensity profile of this boundary can be modelled by a \r\ncumulative Gaussian function, and furthermore that there exists a unique boundary that can be found by the profile.\r\n\r\n<b>Evidence:</b>\r\n\r\nThe authors present results from testing on several generated curves. It shows how the RMS error (between the fitted \r\nand known parameters) for the curves tested goes rapidly to almost zero within a small number of iterations. This \r\nsupports the claim that their optimiser can fit a CG curve to a set of points derived from a 1D profile.\r\n\r\nNo evidence is presented (citation or data) to support the claim of the intensity profile being modelled by a Gaussian, \r\nor that this can be applied to images.\r\n\r\n<b>Open Science:</b>\r\n\r\nThe paper follows the tenets of Open Science; the source is provided, and the paper describes the algorithm as \r\nimplemented. The technique has not yet been applied to images, so there is no data to accompany it. All the \r\nparameters were provided to enable the reader to replicate the results presented in the paper.\r\n\r\n<b>Reproducibility:</b>\r\n\r\nI downloaded the code as supplied, and built it under Debian GNU/Linux on a Pentium 4 machine, using g++ 3.3.5, ITK \r\nCVS, VTK 4.2, FLTK 1.1. Apart from a few warnings, it built and ran fine.\r\n\r\nI ran the application with the default parameters, and it worked fine. Testing with a range of values seemed to \r\nproduce the expected results, and a good fit. One combination managed to cause a segfault (didn't manage to record \r\nthe settings).\r\n\r\n<b>Test Results</b>\r\n\r\nRunning with mu=5, sigma=2, I1=0, I2=100, samples=10, noise=[-1,1]: output information not displayed in GUI, but \r\nplot is displayed and fit looks very close. Mean fit error=0.0718168. Over 10 repeated runs, this would usually \r\nimprove to RMS fit error of 0.6, but occasionally the RMS error would increase and stabilise higher than the initial \r\nvalue.\r\n\r\nRunning with mu=10, sigma=5, I1=120, I2=900, samples=10, noise=[-10,10]: Fit error converges to about 6 after \r\naround 40 iterations. Mean error 2.78059. However Fitted mean=7.21941, fitted sigma=3.68412, fitted I1=121.483, \r\nfitted I2=589.68. The Upper asymptote is significantly out, despite fairly low overall fit error. These values of intensity \r\nare common for tissue-bone boundary, and are thus representative of real images.\r\n\r\n<b>Use of Open Source Software:</b>\r\n\r\nThe authors use the well-known combination of FLTK for the GUI and VTK for the charts. They do not discuss the \r\nimplementation or use of these libraries.\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\nThe source was provided for the algorithm itself, in the style of an ITK algorithm. The primary class has already been \r\nsubmitted to ITK. This was accompanied by an FLTK/VTK application front-end to exercise the filter and plot the \r\nresults. It was immediately usable for testing once built.\r\n\r\n<b>Code Quality:</b>\r\n\r\nThe code was generally readable and well-laid out. It tends to follow the conventions used in ITK and in the \r\nITKApplications suite, and was easily built on a Linux box with appropriate libraries installed. It seems to be fully \r\nportable.\r\n\r\n<b>Applicability to other problems:</b>\r\n\r\nThe solution is in a sense a very general one, in that it provides a particular type of curve-fitting algorithm for a \r\ncumulative Gaussian. It could potentially be used in many statistical analysis problems. It may need to be developed \r\nfurther to see just where else it could be applied in image analysis.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\nThe conclusion mentions future work in segmentation based on boundary profiles. In terms of ITK, clearly the most \r\nimportant step is demonstrating this approach on real image data. Also, perhaps some of the work of Pizer et al with \r\ncores could be relevant here.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\nGiven the results of this fitting (sigma, mu, etc) how do you calculate the actual boundary location?\r\n\r\nHow do you <b>know</b> the result is sub-pixel? What about scale issues and partial volume effect?\r\n\r\nHow are p1 and p2 (the sampling region) determined? How does this effect the optimization process?\r\n\r\nError function? How is the erf table generated? It would be useful to include at least the formula showing how they \r\nwere calculated.\r\n\r\n<b>Additional Comments:</b>\r\n\r\nOnly a single paper is cited as related work (written by one of the coauthors). It would help to have the work placed in \r\nthe context of other related boundary finding techniques, showing how this approach differs.\r\n\r\nThis technique as described seems to only be applicable to a 1-Dimensional image intensity profile. The issue of first \r\ndetermining the orientation of the profile is not addressed, and thus cannot be directly applied to boundary analysis in \r\n2D or 3D images. As it stands it is assuming that there is a unique boundary point to be found, which may be in 1D but \r\nis only possible <i>for a given orientation at a given point</i> in 2D or 3D.\r\n\r\nThe Cumulative Gaussian appears to well describe the blurred intensity profile at the implicit boundary of two tissue \r\ntypes. However no mention is made of the Partial Volume Effect. It is not clear that this approach can afford to ignore \r\nthe PVE. Implicit in the selection of I_1 and I_2 is the fact that it must be chosen at sufficient distance from the \r\nboundary itself as to prove representative of the plateau intensity.\r\n\r\nIt would be interesting to explore the issue of scale also; say the ratio of the intensity delta (between I1 and I2) to the \r\nvoxel size. Perhaps skewness and kurtosis play a part here. You mention skew in the abstract but don't address it \r\ndirectly in the body. Is the boundary <i>always</i> symmetric? Given there will always be a finite sampling \r\nfrequency for any acquisition device, the tyranny of Nyquist's theorem places a limit on the smallest feature we can \r\nresolve. Size of point-spread function?\r\n\r\nThere is minimal analysis of the results and their implications. Section 5 talks about mu in terms of \"skew\", which one \r\nwould ordinarily associate with asymmetry of the curve tails. This is also confusing since mu is supposed to represent \r\nthe tissue boundary position.\r\n\r\nThe technique is not tested on either synthetic or real images. It would be great to see this applied to some real image \r\ndata. Or even a synthesised boundary (say between tissue and bone for CT) with noise and blurring added for good \r\nmeasure.\r\n\r\nOne of the stated assumptions is that the implicit boundary is essentially a step-function; that the actual tissue \r\nobserved transitions at one point from I1 to I2 (or asymptotically close). Sigma is equated with the boundary \"width\", \r\nbut really 1 standard deviation is only going to be 37% (or whatever the figure is) of the way to 1 (either plateau).\r\n\r\nThe algorithm attempts to estimate I1 and I2, the intensities of the two regions. But this is a given, surely? It is in the \r\nimage data, only determined by sigma, or the \"width\" of the boundary.\r\n\r\nNot sure about about discrete sampling - check Insight into Images.\r\n\r\nI think it would be a much stronger demonstration of the technique if it were applied to a simulated edge profile for \r\nvalidation. Since the only experiment is fitting a G curve to a G curve, it doesn't directly address the hypothesis that \r\nthis can find the boundary edge. Beginning with a 1D profile, two intensity levels could be chosen, and a random point \r\nchosen for the boundary. Then to simulate the mixture of the two intensities about the boundary, apply a smoothing \r\nfilter of an appropriate kernel size/scale. Finally the boundary position could be calculated from mu and compared with \r\nthe original known position.\r\n", "review_id": 82}], "publication_id": 37},
{"reviews": [{"date": "09-09-2005", "author": {"author_id": 45, "author_email": "ibitter@nih.gov", "author_lastname": "Bitter", "author_firstname": "Ingmar"}, "content": "<b>Summary:</b>\r\nThe paper presents a novel N-dimensional path optimization algorithm called NDS.\r\n \r\n<b>Hypothesis:</b>\r\nThat the new NDS algorithm can find optimal path given reasonably close initial paths.\r\n\r\n<b>Evidence:</b>\r\nA description of the algorithm, a description of itâs implementation, complexity analysis and a single 2D example. No higher dimensional examples were provided.\r\n\r\n<b>Open Science:</b>\r\nNo source code, nor executables, nor input/output data are available.\r\n\r\n<b>Reproducibility:</b>\r\nThe paper does not facilitate reproducing the work described within. Adding the described work as extensions to ITK as was done with the underlying path classes would make reproduction easy.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe work is based on and extends ITK. \r\n\r\n<b>Open Source Contributions:</b>\r\nNo code was provided.\r\n\r\n<b>Code Quality:</b>\r\nNo code was provided.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe method would apply to may problems.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe method seems to be very similar to the Dijkstra method for optimal shortest paths. Please add a comparison to that algorithm to the paper. Especially for open paths from source to sink you may find equivalence in the optimal path. I used Dijkstra and a special merit function to find optimal chain-code path centerlines and skeletons in a 2001 TVCG paper called âPenalized-Distance Volumetric Skeleton Algorithmâ.\r\nIt is not clear what you mean when you talk about âscale spaceâ. Please add a reference.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nPlease provide more examples, including higher dimensional ones, as you claim the method does work in N dimensions.\r\n\r\n<b>Additional Comments:</b>\r\nI assume that by design this only works for chain-code paths, not for parametric paths. In case it can work for both, please clarify in the paper.\r\n\r\n<b> Conclusions:</b>\r\nThis paper does not adhere to open science standards, and is lacking some evidence that it will work on a variety of inputs of different dimensionality. It also could improve its background analysis. Once those things are ironed out it will be applicable to a wide range of problems. \r\n\r\n\r\n", "review_id": 62}, {"date": "09-19-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper presents an algorithm for optimizing a path through pixels in an image. The algorithm is based on dynamic programing and accepts a user-provided optimization criterion. The paper provides a nice description of the mathematical principles behind the optimization approach, and a brief description of how those principles are implemented in an open source software.\r\n \r\n<b>Hypothesis:</b>\r\nThe paper presents the hypothesis that dynamic programming methods are suitable for optimizing paths on digital images.\r\n\r\n<b>Evidence:</b>\r\nThe paper does not provide evidence for the hypothesis. \r\n\r\n<b>Open Science:</b>\r\nThe paper does not satisfy the criteria of open science since no material is provided that will allow the readers to verify the claims in the paper.\r\n\r\n<b>Reproducibility:</b>\r\nThe paper did not provided enough elements for enabling reproducibility. The paper is too focused on the mathematical description of the algorithm and not enough on its implementation and usability.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors used the Insight Toolkit as development platform.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors mention that their code was implemented in the form of ITK classes, but do not indicate where the reader can find these classes, or whether they are available.\r\n\r\n<b>Code Quality:</b>\r\nThere was no code available that would have allowed the reviewer to verify the quality.\r\n\r\n<b>Applicability to other problems:</b>\r\nAn algorithm for path optimization will have a wide range of applications. In particular on segmentation of anatomical structures.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe reviewer encourage the authors to provide more examples of the use of their code.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe reviewer will appreciate if the authors address more details on how their classes where implemented and how they can be used by others in order to foster their research.\r\n\r\n<b>Additional Comments:</b>\r\nIt is remarkable that the authors adopted the N-Dimensional philosophy of the Insight Toolkit. Implementing N-D algorithms require a significant amount of effort, but also provides a significant amount of return, since the algorithm can be applied to a larger set of problems.\r\n", "review_id": 113}], "publication_id": 38},
{"reviews": [{"date": "09-19-2005", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<b>Summary:</b>\r\nThe authors seek to apply Thirlon's Demons deformable registration method to align MR scans taken as contrast perfuses through an organ. Contrast perfusion curves at anatomic points are analyzed to detect and localize tumors. The concept is that inter-scan deformations occur (one demonstration application is breast MR) and such deformations will confound the computation of perfusion corresponding anatomic points.\r\n\r\nThe research area is well motivated in the paper. Excellent experiments are conducted. This is a very good research paper.\r\n\r\nThe paper will ideally motivate others to apply open-source software to their clinical research.\r\n\r\nThis paper has limited benefit to the open source community. The Demons method and the use of histogram matching is already detailed in the Insight Software Guide.\r\n \r\n<b>Hypothesis:</b>\r\nOpen-source software (ITK) can be applied to register MR image sequences that contain deformations.\r\n\r\n<b>Evidence:</b>\r\nThe evaluations are excellent. Some clinical issues should perhaps be considered, but such issues are not the focus of this conference/journal.\r\n\r\n<b>Open Science:</b>\r\nThe paper makes good used of open source, and it details many of the parameters involved in the algorithms used.\r\n\r\nThe data used in the paper are not made publicly available.\r\n\r\nThe software developed for the paper is not make publicly available. The application is summarized by a pipeline / flow chart, but the code to implement that pipeline is needed to fully understand the parameters of the application. How does it differ from the work presented in the Insight Software Guide?\r\n\r\n<b>Reproducibility:</b>\r\nThere are parameters to histogram matching that are not given.\r\n\r\nThere are parameters to the demons method that are not given.\r\n\r\nExperimentation would probably be required to duplicate these results.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThis work has great potential, but its impact on the open-source community is limited without source code or implementation details. This paper would be an excellent demonstration of the clinical potential of open-source, if it provided the details/code needed for others to replicate the work. Perhaps, at a minimum, a simple text document that details the various parameter settings could also be uploaded? Ideally, source code would be made available.\r\n\r\n", "review_id": 115}, {"date": "08-07-2005", "author": {"author_id": 54, "author_email": "vincent-magnotta@uiowa.edu", "author_lastname": "Magnotta", "author_firstname": "Vincent"}, "content": "It is clear that dynamic contrast MR imaging would benefit from image co-registration. Based on the image acquisition utilized in this paper, it is unclear if a nonlinear image registration is better than a rigid registration. While not described in sufficient detail in the paper, it appears that the dynamic contrast imaging has an image acquisition period of approximately 30 seconds. This is sufficient time to average several cardiac and respiratory cycles into the data causing blurring in the data as compared to non rigid motion as would be the case when using snapshot based imaging approaches. It is also unclear in the paper why histogram matching was used in comparison to a mutual information metric. The contrast changes in the area of the lesion are large (enhancement of 3 times) as shown in Figure 1. It is unclear if simple histogram matching is sufficient to allow the Thirion demon registration to work well in areas where there is a large change in contrast between the images.\r\n", "review_id": 17}], "publication_id": 39},
{"reviews": [], "publication_id": 40},
{"reviews": [{"date": "10-24-2006", "author": {"author_id": 3, "author_email": "julien@jomier.com", "author_lastname": "Jomier", "author_firstname": "Julien"}, "content": "<p><strong>Summary:</strong> This paper presents an open-source develoment software for computer-assisted intervention. The paper focuses on the real-time issue that is inherent in a clinical environment. </p><p><strong>Hypothesis:</strong> NA </p><p><strong>Evidence:</strong> NA </p><p><strong>Open Science:</strong> The software package really fits in the Open Science spirit by using a lot of Open Source packages and will be open-source in the future. It will be a great package to have when developing surgical guidance software. </p><p><strong>Reproducibility:</strong> Did you download their code? Yes Did you compile it? No source code provided Did you run it? Yes Did you managed to get the same results that they reported? Most of the examples need a tracker to run, so no test were performed. </p><p><strong>Use of Open Source Software:</strong> The authors use a lot of open source packages: CMake, Swig, Dart, CppUnit, PyUnit, CVSTrac. This is definitively one strength of the paper and the software. </p><p><strong>Open Source Contributions:</strong> The authors provides only the pre-compiled libraries. They ensure that the code will be open-source, but the type of license is not specified. </p><p><strong>Code Quality:</strong> Only the header files are provided at this point. The coding style looks really good. The portability looks good. </p><p><strong>Applicability to other problems:</strong> I don&#39;t see any other applications for the moment. </p><p><strong>Suggestions for future work:</strong> No suggestion. </p><p><strong>Requests for additional information from authors:</strong> - The type of license should be stated in the paper. - It would be nice to have some timing comparison with other real-time software. - Is the warping Python only? How about TCL and other wrappers? - References to SWIG, cmake (the URLs) will be good to have. </p><p><strong>Additional Comments:</strong> This sounds like a very good package.&nbsp;</p>", "review_id": 42}, {"date": "09-20-2005", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper describes an open source library for computer-assisted interventions. The software is distributed under an open source license.\r\n\r\nThe library provides very valuable resources for groups that develop software for computer-assisted intervention.\r\nIn particular\r\n\r\n* Support for Tracking devices\r\n* Robot control\r\n* Support for real time\r\n* Logging\r\n* Mathematical classes\r\n\r\n \r\n<b>Hypothesis:</b>\r\nThis paper advances the hypotesis that the development of computer-assited intervention systems can be simplified by using an open source library that offers support for the basic functionalities that are commonly required in these systems.\r\n\r\n<b>Evidence:</b>\r\nThe paper focuses on describing the architecture of the software. A set of examples is included with the source code that is downloadable from www.cisst.org\r\nA detailed description of the architecture is presented, as well as an overview of the classes that will be available in the toolkit.\r\n\r\n<b>Open Science:</b>\r\nThe paper does fully adhere to the principles of Open Science, since the software is distributed and the readers can check with the software the claims in the paper.\r\n\r\n<b>Reproducibility:</b>\r\nThe reviewer downloaded the source code and built it under Cygwin, with gcc 3.4 and CMake 2.0.6.\r\n\r\nThe configuration of the software when smoothly without a single warning,\r\nThe compilation didn't generate errors or warnings, which indicates that the authors really put in place an effective system of quality control.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors used \r\n\r\n* the netlib library (www.netlib.org) \r\n* the SWIG wrapper tool. \r\n* Cmake configuration tool\r\n* CVS for revision control\r\n* Dart for testing\r\n* Doxygen for code documentation\r\n* CVSTrac for bug tracking\r\n* CPPUnit and PyUnit for testing\r\n\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors distribute the source code at www.cisst.org\r\nDoxygen documentation is also available online and in a downloadable zip file.\r\n\r\n<b>Code Quality:</b>\r\nThe source code has a very standard of quality.\r\nIt is very structured, and follows a formal object oriented methodology. The authors used state of the art software engineering methodologies in the design, implementation and testing of the software. All of which is critical for software that is intended to be used in surgical applications.\r\n\r\nThe documentation of the classes is available online, \r\nhttp://www.cisst.org/resources/software/cisst-0.1.0/doc/doxygen/main.html\r\n\r\n\r\n<b>Applicability to other problems:</b>\r\nThe software described in the paper seems to be suitable for robotics applicaitons outside of the medical field, and the tracker functionalities can probably be used too in virtual reality applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors are strongly encouraged to follow the methodology of releasing early and releasing often. This maximize the feedback from the community and encourage the use of the software by a larger number of people.\r\n\r\n<b>Additional Comments</b>\r\nThe authors really need to make the download option more visible in their web site. This reviewer missed the option even after multiple passes through the page. \r\nReaders may easily get the impression that the software is not yet available.\r\n\r\nWhen visiting the web page of an open source software package the reviewer would expect the \"Download\" option to be close to the top, and quite highlighted.\r\n\r\n\r\n\r\n\r\n", "review_id": 116}], "publication_id": 41},
{"reviews": [{"date": "08-19-2005", "author": {"author_id": 145, "author_email": "dauguet@bwh.harvard.edu", "author_lastname": "Dauguet", "author_firstname": "Julien"}, "content": "<b>Summary:</b>\r\n[Short description of the paper. In two or three phrases describe the problem that was addressed by the authors and the approach they took to solve it.]\r\nSalient points are used in image analysis to extract informative and reliable regions. This paper describes two different methods to extract salient points and compares them on thirteen MR images. \r\n\r\n<b>Hypothesis:</b>\r\n[If Applicable: Describe the assumptions that the authors have made and they hypothesis of their work, note that not all papers will fit the model of hypothesis driven work, for example, the description of an image database, or the description of a toolkit will not be driven by an hypothesis, in which case, please simply write : âNon Applicableâ in this field or delete the subtitle.]\r\nThe authors chose two methods based on derivatives of intensity to extract salient points: one using the Gaussian curvature and the other using the correlation matrix.. \r\n\r\n<b>Evidence:</b>\r\n[Describe the evidence that the authors provide in order to support their claims in the paper. This is a key component on Open Science, opinions that are not supported by evidence should be labeled as âspeculationsâ or âauthorâs opinionâ while. The same rule applies to the text of the reviews: claims should be supported by evidence]\r\nThese methods are more adapted to low signal images than those using edge detection process.\r\n\r\n\r\n<b>Open Science:</b>\r\n[Describe how much the paper and its addendums adhere to the concept of Open Science. Do the authors provide the source code of the programs used in their experiments? Do the authors provide the input images that they used? Or are those images publicly available? Do the authors provide the output images that they show in the paper? Do the authors provide enough details for you to be able to replicate their work?\r\nThe methods proposed in this paper were implemented as open source using and extending Insight ToolKit.\r\n\r\n\r\n<b>Reproducibility:</b>\r\n[Did you reproduce the authorsâ work? No\r\nDid you download their code? Did you compile it? Did you run it? No\r\nDid you managed to get the same results that they reported?\r\nWere there information missing from the paper, that was necessary for you to reproduce the work? Suggest improvements that will make easier for future readers to reproduce this work.]\r\n\r\n<b>Use of Open Source Software:</b>\r\n[Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]\r\nThey used open source ITK.\r\n\r\n<b>Open Source Contributions:</b>\r\n[Do the authorâs provide their source code? Is it in a form that is usable? Do they describe clearly how to use of the code? How long did it take you to use that code?]\r\nYes, they provide their source code on the Web.\r\n\r\n<b>Code Quality:</b>\r\n[If the authors provided their source code: Was the code easy to read? Did they use a modern coding style? Did they rely on non-portable mechanism? Was it suitable for multiple-platforms?]\r\nNot read.\r\n\r\n<b>Applicability to other problems:</b>\r\n[Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]\r\nYes, as said in their introduction, salient points can be used in all sort of image registrations but also in tracking, stereoscopic matching.\r\n\r\n<b>Suggestions for future work :</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\nComparison with other types of salient points extraction. Tests of such methods for image registration.\r\n\r\n<b>Requests for additional information from authors :</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\nA diagram for statistics could have been interesting.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\nGood study on two methods for the extraction of salient points: it is a very interesting tool to obtain reliable displacement fields.\r\n", "review_id": 36}, {"date": "09-17-2005", "author": {"author_id": 227, "author_email": "fletcher@sci.utah.edu", "author_lastname": "Fletcher", "author_firstname": "Tom"}, "content": "<b>Summary:</b>\r\nThis paper reviews and compares two methods for computing salient points in 3D medical images. A set of validation metrics are devised and used to compare the performance of the two methods on 13 MR images of the brain.\r\n \r\n<b>Hypothesis:</b>\r\nNot applicable, as this paper is a comparison of existing methods.\r\n\r\n<b>Evidence:</b>\r\nThe results of the comparison of the two corner detection methods are given on 13 MR images of the brain.\r\n\r\n<b>Open Science:</b>\r\nThe source code is available as an extension of ITK in the NA-MIC SandBox. As far as I can tell, the MR images used in the paper are not made available.\r\n\r\n<b>Reproducibility:</b>\r\nI was able to download, compile and run the author\\\\\\'s source code with relative ease. The test programs ran without errors, and I ran the corner detectors on a provided synthetic binary image of a 3D box. It would be nice if the MR images from the paper were also provided, which would make the results of the paper fully reproducable.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe software to compute the salient points is provided as an open source addition to ITK in the NA-MIC SandBox. There is little documentation on the usage of the programs, but they are simple command-line programs that are easy to figure out how to use. It might be useful to add in the top-level readme file a description of the two command line tools.\r\n\r\nThe validation metrics and the framework used to compile the statistics comparing the methods is not provided (at least I didn\\\\\\'t find them). This would be nice to have, as others might be interested in comparing yet other salient point detectors.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe salient point detectors are provided, and they are a very nice addition to ITK. Using the code in new software should be rather straightforward as the methods are implemented as ITK image filters.\r\n\r\n<b>Code Quality:</b>\r\nThe code looked clean and easy to read. There was sufficient comments I think to understand what the code does, especially when combined with the detailed description of the methods in the paper. One nit-picky suggestion is to make the top-level CMakeLists.txt file also compile the two example command-line programs.\r\n\r\n<b>Applicability to other problems:</b>\r\nThis code will be very helpful to researchers that want to find salient points in images, most likely for image registration.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<b>Requests for additional information from authors:</b>\r\nAgain, it would be nice to have the MR images used and the framework for the validation.\r\n\r\n<b>Additional Comments:</b>\r\nI would like to see just a little discussion/analysis of why the comparisons turned out the way they did. For instance, why is it that the correlation measurement showed better reproducability than the curvature measurement? My feeling is that this is because the correlation measurement is an expectation value in a small neighborhood, which might make it more robust to scale changes and registrations. Also, why is the curvature method more correlated to the entropy?\r\n\r\nOne point of the paper that I am confused with is whether the images used in the results are of the same subject or different subjects. You mention in the description of repeatability that salient points should be robust to images \\\\\\\"scanned at different times\\\\\\\", which makes it sound like the same subject scanned multiple times. And since the registration used is rigid, it appears that it is a single subject. Rigid registration of multiple subjects would not do a good job of aligning salient points, and thus it would be a poor measurement of repeatability.", "review_id": 95}], "publication_id": 42},
{"reviews": [{"date": "02-01-2006", "author": {"author_id": 2746, "author_email": "bill.lorensen@gmail.com", "author_lastname": "Lorensen", "author_firstname": "Bill"}, "content": "<b>Summary:</b>\r\nA suite of approximately 20 programs to manipulate isosurfaces.\r\n\r\n<b>Open Science:</b>\r\nMost of the source code is available. Although some code is missing. There is no sample data provided. The algorithm is not suffieicently described in the paper.\r\n\r\n<b>Reproducibility:</b>\r\nI downloaded the file, but it would not compile. The file macros.h was missing.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors used the open source vtk toolkit. It seems that about 5 new vtk classes are provided.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe software cannot be built as distributed because of missing source code. Also, the CMakeLists.tst files contain user-specific paths. ALl of the CMakeLists.txt files need editing. A high level CMakeLists.txt file is not provided. This wouold ease the constrcution of all of the programs.\r\n\r\n<b>Code Quality:</b>\r\nCoding style is reasonable.\r\n\r\n<b>Suggestions for future work:</b>\r\n<UL>\r\n<LI>This looks like a useful set of tools to manipulate and improve isosurfaces.\r\n<LI>Some work is needed with the distriubtion and the cmake files.\r\n<LI>There is not a good description of the topology repair algorithm.\r\n</UL>\r\n", "review_id": 163}, {"date": "08-07-2005", "author": {"author_id": 54, "author_email": "vincent-magnotta@uiowa.edu", "author_lastname": "Magnotta", "author_firstname": "Vincent"}, "content": "This is a very interesting paper. The application is timely and the open source nature of the developed toolkit would facilitate cortical surface generation by a large number of groups allowing spherical or flat map representations to readily be generated from the resulting cortical manifold. The speed of the developed algorithms is a nice feature of the library. The only real drawback in the current paper is a lack of specific details describing the algorithms. This information would significantly enhance the paper.\r\n", "review_id": 16}, {"date": "08-08-2005", "author": {"author_id": 127, "author_email": "donna@brainvis.wustl.edu", "author_lastname": "Dierker", "author_firstname": "Donna"}, "content": "We have read the other paper these authors cite and have been interested in implementing one of these methods. But none of them makes the code so readily available. At the very least, we will test this method. If we like the results, we will integrate the code into Caret, giving appropriate credit and following the licensing guidelines.\r\n\r\nDonna Hanlon\r\nVan Essen Lab\r\nhttp://brainvis.wustl.edu", "review_id": 22}, {"date": "11-14-2005", "author": {"author_id": 322, "author_email": "agouaillard@gmail.com", "author_lastname": "Gouaillard", "author_firstname": "Alexandre"}, "content": "<b>Summary:</b>\r\nThis paper deals with topological correction of brain isosurface. The main idea is to mix surface approach (for handle detection) and image approach (for the correction part, faster and robust).\r\n \r\n<b>Open Science:</b>\r\nThis paper is most definitly within the scope of open science. The code is based on VTK and everything (data, code and documentation) is given. Moreover, there is no publicly available toolkit for topology management so far. (note: guskov2001 papers goes with a binary). It should be noted that we are still lacking (in the open community) a suitable Data Structurefor rigorous topological work on surface meshes. The authors implemented an HE data structure that manage orientability and other components. Unfortunatly it seems to be bundled with application specific code. See below for a discussion on how this could be best profitable to open source community. \r\n\r\n<b>Reproducibility:</b>\r\nI did not download the code and test it yet as the code is reported as not working.\r\nThis approach look pretty much alike the one from Wood04 where the authors used the isosurface (well, reeb-graph of iso surfaces and isocontours of the original image) to find the handles and \\\"repaired\\\" the mesh using the image. There too, MC was an intermediate step to recompute the corrected surface. This approach seems to be much simpler (which is a good thing) but the reader is left with no clue whatsoever about the underlying \\\"handle detection\\\" algorithm which unfortunatly is the core of the method. They seems to use a front propagation method on the isosurface to define a distance map (to what?), followed by a second pass where they detect the handles. The thing is, for each handle you have two specific \\\"class\\\" of loops (generators) that can be used to remove the handle. the first question is, how do you decide if you \\\"pintch\\\" the handle or \\\"fill\\\" the handle (dual operation, depending on the orientation of your surface)? Both operation lead to a genus - 1 surface, but very different ones. The second issue is that topology and geometry are disconnected. There is an infinity of loops that would be suitable to remove an handle in a topological sense. Here the authors seems to try to find the shortest one. Is that correct ? and if it is, why this one ? Are the authors sure they are getting the shortest one? I\\'m pretty much sure that the authors managed to removed all the handles in a topological sense (genus down to zero), I\\'m still wondering about if it\\'s done properly (and the definition of properly in this case is also an issue to be discussed with the biologists... Whatever \\\"properly\\\" is, it should be stated from the start as it impacts significantly the algorithm).\r\n\r\n<b>Use of Open Source Software:</b>\r\nThey do use open source (VTK). \r\n\r\n<b>Open Source Contributions:</b>\r\nFew details are given in the MICCAI paper, but the ppt contents more details. Most interestingly they somehow show that VTK does not contains the good structure for mesh processing. Even if the proposed structure contains some algorithm specific features, they implemented an Half-edge data-structure over the vtkPolyData. It would be interesting to see if the HE datastructure could be detached from the algorithm specific part (vtkPolyData -> vtkHalfEdgeMesh -> author code) and added to VTK toolkit. It would be also interesting to wonder if mesh processing features should be added to a VIZUALIZATION toolkit or to ITK which is dedicated to processing. The answer is most probably it should be integrated in ITK, but right now itk is lacking all the basic mesh processing filters vtk is providing..... A C-GAL - like mesh structure is definitly needed for mesh processing. By the way, how do the author insure closedness, 2-manifoldness (HE provides the orientation layer that vtkPolyData was not providing). Without those issues addressed, it seems difficult to treat topology rigorously (homology vs homotopy when the surface is not closed - we are working with surface of solid objects thus we should have 2-manifold, shall we let the end user handle that, or shall we enforce the 2-manfoldness in the DataStructure - ...).\r\n\r\n<b>Code Quality:</b>\r\nDid not check that. Compilation reported broken. I believe the author to have several years experience with VTK from belgium to caltech, INRIA, MIT and now kitware, so the code should be well written.\r\n\r\n<b>Applicability to other problems:</b>\r\nthat topological could be of interest if control over the topology was given. The subject is verey active in graphical, mechanical and computational field. In medical field most people focus on brain, as the genus is known. It would be interesting to open the problem to a larger scale.\r\n\r\n<b>Suggestions for future work:</b>\r\nHere are somef works on a possible solution for the all-surface approach (which does not address some of the \\\"mesh modification\\\" problems). I\\'m still somehow working on it, if the author want to have some discussions on the problem, I\\'m open.\r\nA. GOUAILLARD, C. ODET, X. GU, âComputing Shortest Cycles on Discrete Surfaces for Acurate Topological Modifications of Medical Image Isosurfacesâ, In Proceedings of IEEE EMBCâ05, Shanghai, September 11th-14th 2005. To appear.\r\nA. GOUAILLARD, T. KANAI, C. ODET, X. GU, âOptimal Localization of Topological Artefacts on 3D Meshesâ, The 11th Int. Conf. on Geometry and Graphics, 1-5 Aug., 2004, Guangzhou, China.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nI would definitly need some information on the handle detection part. There is nothing about it in the paper althought it\\'s the core of the method IMHO.\r\n\r\n<b>Additional Comments:</b>\r\nOpen to discussion on the subject.\r\n\r\n", "review_id": 131}], "publication_id": 43},
{"reviews": [{"date": "09-15-2005", "author": {"author_id": 3, "author_email": "julien@jomier.com", "author_lastname": "Jomier", "author_firstname": "Julien"}, "content": "<b>Summary:</b>\r\nThis paper presents an open-source toolkit for physics-based animation. The toolkit can be applied to Medical Imaging analysis and simulation.\r\n \r\n<b>Hypothesis:</b>\r\nNA\r\n\r\n<b>Evidence:</b>\r\nNA\r\n\r\n<b>Open Science:</b>\r\nThe paper fully supports the concept of Open-Science.\r\n\r\n<b>Reproducibility:</b>\r\nI did not download the source code.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe toolkit is fully open-source. It uses some third party packages that may limit its portability.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code is available under GNU LGPL.\r\n\r\n<b>Code Quality:</b>\r\nThe code uses modern coding style. Heavily templated. The documentation looks very good and complete.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe toolkit can be applied to many different fields.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors should continue to support the toolkit and advertise it more.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nMaybe some concret applications and example on real cases would have been a plus for this paper.\r\nI could not find the list of supported platforms/compilers...\r\nDo you use any regression testing to make sure your code compiles regularly on all the platforms?\r\nAny plan to use CMake (www.cmake.org) to build this toolkit in the future?\r\n\r\n<b>Additional Comments:</b>\r\nThe paper is well written. The examples are very nice and the videos are impressive.\r\nVery nice job!\r\n", "review_id": 79}, {"date": "09-14-2005", "author": {"author_id": 68, "author_email": "andinet.enqu@kitware.com", "author_lastname": "Enquobahrie", "author_firstname": "Andinet"}, "content": "<b>Summary:</b>\r\nThe authors introduced an open source toolkit that is useful for physics-based simulations, analysis and visualization.\r\n \r\n<b>Hypothesis:</b>\r\nNon applicable\r\n\r\n<b>Evidence:</b>\r\nNon applicable\r\n\r\n<b>Open Science:</b>\r\nThe toolkit is freely available for use. \r\n\r\n<b>Reproducibility:</b>\r\nDemos of different applications using the toolkit were provided by the authors. However, source code for the applicatioons hasn\\\\\\'t been provided. The reproducibility of the demos could not been tested. \r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors have described well the advantage of their toolkit compared to other commerical softwares and open source softwares.\r\n\r\n<b>Open Source Contributions:</b>\r\nA souce code hasn\\\\\\'t been provided.\r\n\r\n<b>Code Quality:</b>\r\nNon applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nThe toolkit would be useful for image analysis technqiues based on physics principles such as simulated annealing segmentation algorithms.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\n\r\n", "review_id": 74}, {"date": "06-27-2006", "author": {"author_id": 445, "author_email": "marfGm@gmail.com", "author_lastname": "Rodriguez-Florido", "author_firstname": "Miguel Angel"}, "content": "<b>Summary:</b>\r\nAuthors present an open source programming toolkit for physics-based simulation, collision detection, deformation, etc. First, they describe the origin of the\r\ntoolkit. Later, they comment the basic features, and finally they discuss the pros and cons of the toolkit.\r\n \r\n<b>Hypothesis:</b>\r\nNon Applicable\r\n\r\n<b>Evidence:</b>\r\nAuthors don\\'t provide any \\\"speculation\\\", but they assume that the third-party dependences ensure a common framework.\r\n\r\n<b>Open Science:</b>\r\nThis work is the result of a great workgroup (PhD and Master Thesis students, researchers, etc.), and they provide a web site for code, data, etc, and their work is a contribution to Open Science.\r\n\r\n<b>Reproducibility:</b>\r\nI have downloaded the code and data, but in my opinion it\\'s difficult to compile it correctly. I have tried some demos but I got some errors. These errors are the result of the strong third-party dependences. How the say in their ToDo.txt fie: \\\"Automize cross-compilation (windows vs. linux) so compatibility can be easily tested with a minimum of human interaction\\\" is needed.\r\nPerhaps, it would be useful a small quick-start guide in the paper (annexes or similar).\r\n\r\n<b>Use of Open Source Software:</b>\r\nThey comment something about the utility of OpenSource for accessing to the implementations details, and their developments are done under OpenSource.\r\n\r\n<b>Open Source Contributions:</b>\r\nThey provide all the code, but I have had some problems to compile and use it. This is due to the strongly dependence with third-parties.\r\n\r\n<b>Code Quality:</b>\r\nI have compiled under linux and it works. We hope to try it under windows. I haven\\'t checked the source code style, but they say in their paper that they have used template programming\r\nand metaprogramming.\r\n\r\n<b>Applicability to other problems:</b>\r\nI think that this work is very useful in surgical simulation. Our group is working in this discipline, and thanks to the Open Source philosophy, we are installing/running/testing the toolkit to study the viability of including some of their work in our applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nAvoid the strong third-parties dependences. However, they say in their paper that one of their aim is to complete the transition of all code into a completely generic programming\r\nframework.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nA quick-start guide for running demos.\r\n\r\n<b>Additional Comments:</b>\r\nIt is a great and interesting work. Congratulations.\r\nMy rating is based on the IJ reviewer guidelines.\r\n\r\n\r\n", "review_id": 230}, {"date": "09-11-2005", "author": {"author_id": 136, "author_email": "delfin@cc.gatech.edu", "author_lastname": "Nain", "author_firstname": "Delphine"}, "content": "<b>Summary:</b>\r\n[Short description of the paper. In two or three phrases describe the problem that was addressed by the authors and the approach they took to solve it.]\r\n\r\nThis paper describes an open source toolkit for physics based simulation that has been used for research and education since 2001. The toolkit provides implementation of state of the art physics based algorithms and has been used for a variety of physics-based simulations, as demonstrated by the demos that accompany this paper.\r\n \r\n<b>Hypothesis:</b>\r\n[If Applicable: Describe the assumptions that the authors have made and they hypothesis of their work, note that not all papers will fit the model of hypothesis driven work, for example, the description of an image database, or the description of a toolkit will not be driven by an hypothesis, in which case, please simply write : âNon Applicableâ in this field or delete the subtitle.]\r\n\r\nnot applicable\r\n\r\n<b>Evidence:</b>\r\n[Describe the evidence that the authors provide in order to support their claims in the paper. This is a key component on Open Science, opinions that are not supported by evidence should be labeled as âspeculationsâ or âauthorâs opinionâ while. The same rule applies to the text of the reviews: claims should be supported by evidence]\r\n\r\nnot applicable\r\n\r\n<b>Open Science:</b>\r\n[Describe how much the paper and its addendums adhere to the concept of Open Science. Do the authors provide the source code of the programs used in their experiments? Do the authors provide the input images that they used? Or are those images publicly available? Do the authors provide the output images that they show in the paper? Do the authors provide enough details for you to be able to replicate their work?]\r\n\r\nThis paper adheres to the principle of open science. The source code is free and openly available for download with demos available. The user can either use the code as it is or adapt the source code for its own experiments/algorithms. The images are freely available.\r\nI have not downloaded the code for my own use, but the authors point out there is a steep learning curve to use the toolkit due to delayed documentation and advanced programming techniques such as generic and metaprogramming. However, the toolkit is used in the classroom, indicating that it can be used by university students.\r\n\r\n<b>Reproducibility:</b>\r\n[Did you reproduce the authorsâ work?\r\nDid you download their code? Did you compile it? Did you run it?\r\nDid you managed to get the same results that they reported?\r\nWere there information missing from the paper, that was necessary for you to reproduce the work? Suggest improvements that will make easier for future readers to reproduce this work.]\r\nI have not downloaded the code.\r\n\r\n<b>Use of Open Source Software:</b>\r\n[Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]\r\n\r\nThe authors used open source software released under the GNU Lesser General Public License.\r\nIn section 2, the authors point out that OpenTissue contains a variety of algorithms, but they fail to specify how many developers contributed, the number of principal developers and their experience in collaborating to develop open source code. This would be valuable information for other toolkit developers.\r\nIn section 3, the authors motivate the coding style of the toolkit (generic and metaprogramming) with the advantages (flexibility, more concise code, etc), disadvantages (compiler support, compiler errors). This is valuable information. The authors should also point out if they decided to use this coding style from the start, why, and if not, what made them decide to switch to this coding style.\r\nIn section 4, the authors point out that there is no clickable drag and drop GUI and motivate that choice.\r\n\r\n<b>Open Source Contributions:</b>\r\n[Do the authorâs provide their source code? Is it in a form that is usable? Do they describe clearly how to use of the code? How long did it take you to use that code?]\r\nyes, the authors provide source code. \r\nThe other questions are not applicable since I didn\\\\\\'t download the code.\r\n\r\n<b>Code Quality:</b>\r\n[If the authors provided their source code: Was the code easy to read? Did they use a modern coding style? Did they rely on non-portable mechanism? Was it suitable for multiple-platforms?]\r\nyes, the code uses modern coding style. The code relies on third party libraries (section 4), which limits it portability. The authors point out how to reduce that dependency.\r\n\r\n<b>Applicability to other problems:</b>\r\n[Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]\r\nyes, this toolkit would be very useful for a computer graphics class, or even a physics class.\r\n\r\n<b>Suggestions for future work:</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\n\r\nfuture directions: since the toolkit is used in a classroom setting, this provide an ideal environment to conduct user studies. THe authors could set up experiments to learn how long it takes a student to learn particular skills, such as 1) basic use of the toolkit 2) does the toolkit improve their understanding of physics-based animation concepts? 3) how long/how easily did students learn modern programming skills 4) was the toolkit successful in helping students develop new algorithms?\r\n\r\nAnother improvement would be to find ways to improve the delayed documentation. In particular, are there ways to help the developers easily document code? Should documentation be mandatory? Should there be a template for documentation? \r\n\r\n<b>Requests for additional information from authors:</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\nThe demos are very impressive! This paper nicely presents the toolkit with its features, advantages and disadvantages. The multidisciplinary aspect of the toolkit is also very nice.\r\n\r\nTypo: there is a word missing at the end of the 4th sentence in section 2 (after \\\"physics-based\\\").\r\n", "review_id": 64}], "publication_id": 44},
{"reviews": [], "publication_id": 45},
{"reviews": [], "publication_id": 46},
{"reviews": [], "publication_id": 54},
{"reviews": [], "publication_id": 55},
{"reviews": [{"date": "11-14-2005", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "I successfully run it on my host. I\\\\\\\\\\\\\\'m able to read lsm files in 3D with the good spacing which is very nice\r\nHowever,\r\n<ul>\r\n<li>I have to replace <pre>#include \\\\\\\\\\\\\\\"tiffio/tiffio.h\\\\\\\\\\\\\\\"</pre> by <pre>#include \\\\\\\\\\\\\\\"tiffio.h\\\\\\\\\\\\\\\"</pre> in itkLSMImageIO.cxx to build the test.\r\n<li>the reader works only if there is only one chanel, and return a quite strange \\\\\\\\\\\\\\\"Cannot open the file!\\\\\\\\\\\\\\\" if the lsm contains 2 chanels. You can get a (big) lsm file with 2 chanels at <a href=\\\\\\\"http://voxel.jouy.inra.fr/blastocyste.lsm\\\\\\\">http://voxel.jouy.inra.fr/blastocyste.lsm</a> if needed.\r\n</ul>\r\nIt really nice to have a LSM reader for ITK.\r\nThanks for that work !\r\n", "review_id": 130}, {"date": "11-14-2005", "author": {"author_id": 310, "author_email": "mathieu.malaterre@gmail.com", "author_lastname": "Malaterre", "author_firstname": "Mathieu"}, "content": "<b>Build errors:</b>\r\nThere are build errors on the Insight Journal, because the version used is ITK 2.2.1 whereas the code <b>needs</b> ITK CVS, due to some very recent change in ITK CVS, in particular TIFFImageIO and the tiff library.\r\n", "review_id": 129}], "publication_id": 56},
{"reviews": [], "publication_id": 57},
{"reviews": [], "publication_id": 58},
{"reviews": [], "publication_id": 59},
{"reviews": [], "publication_id": 60},
{"reviews": [{"date": "01-27-2006", "author": {"author_id": 232, "author_email": "millerjv@research.ge.com", "author_lastname": "Miller", "author_firstname": "James"}, "content": "<b>Summary:</b>\r\nUnary functor filter to perform the modulus operator per pixel.\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis is subclass of UnaryFunctorImageFilter\r\n\r\n<b>Code Quality:</b>\r\nVisual inspection of the code looks fine.\r\n\r\n\r\n<b>Suggestions for future work:</b>\r\nShould probably use the ConceptChecking facilities to ensure the input image type is integral.\r\n\r\n", "review_id": 153}, {"date": "01-30-2006", "author": {"author_id": 2746, "author_email": "bill.lorensen@gmail.com", "author_lastname": "Lorensen", "author_firstname": "Bill"}, "content": "<b>Summary:</b>\r\nAn itk UnaryImageFilter that computes the modulus of an image.\r\n \r\n<b>Evidence:</b>\r\nThe figures in the paper illustrate the technique. A test is also provided with both input and output images.\r\n\r\n<b>Open Science:</b>\r\nAll the code is present.\r\n\r\n<b>Reproducibility:</b>\r\nI downloaded the code. It compiled on both Visual Studio 7 and Borland.\r\nI had to edit the CMakeLists.txt file to add ${EXECUTABLE_OUTPUT_PATH} to the ADD_TEST command so that I could run the tests with ctest.\r\n<pre>\r\nADD_TEST(Modulus ${EXECUTABLE_OUTPUT_PATH}/modulus ${CMAKE_SOURCE_DIR}/Spots.png out.png distance.png)\r\nADD_TEST(CompareImage ${EXECUTABLE_OUTPUT_PATH}/ImageCompare out.png ${CMAKE_SOURCE_DIR}/modulus.png)\r\n</pre>\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe author used CMake and itk.\r\n\r\n<b>Open Source Contributions:</b>\r\nAll source and test code was provided.\r\n\r\n<b>Code Quality:</b>\r\nProgramming style conforms to itk style. Name of class and methods are acceptable. A PrintSelf method is provided.\r\n\r\n<b>Suggestions for future work:</b>\r\nBefore adding to itk, the operator== and operator!= methods should be added to the Functor. This corresponds to recent changes in itk. Also, the test should be modified to use the itk testing framework before adding to itk. This work can be done by the itk Shepard for this code.\r\n", "review_id": 160}], "publication_id": 61},
{"reviews": [], "publication_id": 62},
{"reviews": [{"date": "02-01-2006", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper describes an implementation of an image processing filter that given an image and a mask, will take the minimum value of the image among the pixels indicated by the mask, and will fill the image pixels (under the mask) with that value.\r\n \r\n<b>Hypothesis:</b>\r\nNonApplicable\r\n\r\n<b>Evidence:</b>\r\nThe authors provide their source code, input images and outpur images, as well as a test. The output image provided by the author was replicated by this reviewer.\r\n\r\n<b>Open Science:</b>\r\nThe paper follows quite well the principles of Open Science. The source code, and images are provided, as well as a test that makes very easy to run the filter.\r\nI wished the author would have added a bit more on the background of this filter, althought the references to the book by Soille is probably what I should follow. A more compeling example of the applicability of this filter would have been nice too. For example, the original motivation of the author for implementing this filter, but again, the author refers to other publications for details on applications for which this filter is suitable.\r\n\r\n<b>Reproducibility:</b>\r\nThe author work was easy to reproduce. All the material was included in the submission. The reviewed configured, compiled and ran the code without modifications and with minimal effort. The reviewer tested this code in a Linux Debian machine with a dual pentium IV at 2.4Ghz, and 1Gbyte of RAM. The output of the test matched well the image provided by the author. There was no information missing as far as replicating the work was concerned.\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe author uses ITK and contributes a new ITK image filter, actually based on a previous contribution by the same author.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe author contributes his source code, there are some questionable practices in the implementation of the filter, such as the arbitrary shifting of the image intensities, but they are at least well documented upfront, so the use is aware that they are being performed when the filter is executed.\r\n\r\n<b>Code Quality:</b>\r\nThe code has good quality. It should run in multiple platforms, although the reviewer only tried it on Linux with gcc 3.4. The code respects most of the ITK coding style. Minimal modifications would be needed for including this filter in the ITK toolkit.\r\n\r\n<b>Applicability to other problems:</b>\r\nI would have to consult the references cited by the author in order to get more familiar with potential applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nIt would seem that a similar filter could be implemented for imposing the maxima from a mask.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nAs I mention before, it would have been nice to have a more compeling story for the need of this filter, and its applications. The author went quite to the point on how the filter was implemented and how to use it. An example of what the author is actually doing with this filter would have improve the paper.\r\n\r\n<b>Additional Comments:</b>\r\n\r\n\r\n", "review_id": 165}, {"date": "02-10-2006", "author": {"author_id": 102, "author_email": "sylvainjaume@gmail.com", "author_lastname": "Jaume", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThe paper describes a morphological filter to fill every regions but a region marked by the user.\r\nThe filter takes two inputs: an image and a marker image. The pixels with a non-zero intensity in the marker image define the marked region.\r\n \r\n<b>Evidence:</b>\r\nThe testing example clearly demonstrates the applicability of the filter. However the paper could explain the result with more details.\r\nIn a reply to the previous review, the author gives some context information about the minima-imposition technique and the problem he tries to address.\r\nAn illustration of this problem could help potential users understand how this filter could be useful in their applications.\r\nBesides some theoretical background would not hurt (given only the table of contents of the book of Soille is Open Science!).\r\n\r\n<b>Open Science:</b>\r\nI very much appreciate the author\\\\\\'s initiative to provide not only the materials to reproduce the results, but also the TeX files to reproduce the paper.\r\nOpen Science all the way!\r\n\r\n<b>Reproducibility:</b>\r\nI reproduced the reported result using the input image provided: the resulting image looks identical as the test image that comes in the tar file.\r\nThe code compiled smoothly with MS VS8.\r\n\r\n<b>Open Source:</b>\r\nThe code is implemented as an ITK filter that embeds a sequence of filters. Code quality is excellent.\r\nCould the algorithm be modified to remove the shift filter and gain additional performance?\r\n\r\n<b>Suggestions for future work:</b>\r\nI would suggest to describe an application where this filter could be useful, or even better to illustrate such an application with an example.", "review_id": 178}], "publication_id": 63},
{"reviews": [{"date": "12-09-2005", "author": {"author_id": 171, "author_email": "rupert.brooks@gmail.com", "author_lastname": "Brooks", "author_firstname": "Rupert"}, "content": "<FONT COLOR=\\\"red\\\">UPDATE:</FONT>\r\nAfter corresponding with the author, i would adjust my comments somewhat. Specifically, the reader was never intended to read minc version 1 files, so the fact that it doesn\\'t is not really a problem. Some problems that i was having were due to a faulty build of the minctools i was using, rather than anything to do with this code particularly.\r\n\r\nFor those who might like to use this module, i would point out two things: \r\n<OL>\r\n<LI>You can convert your old minc 1 files, such as brainweb files, to minc 2 using the mincconvert utility found on the website listed in the paper. Note that mincconvert does not automatically get installed with the release that I used (2.0.09), you have to manually install it, this should be fixed in the next release The command line to use is:\r\n<CODE>\r\nmincconvert -2 input.mnc output.mnc\r\n</CODE>\r\n<LI>Secondly, when i built the minc tools, i ran into problems using the HDF library version 1.6.5, but it works fine with 1.6.4. I am not sure why, but if you experience HDF errors when trying to convert minc files, this may be the source of the trouble.\r\n</OL>\r\n\r\n\r\n<b>Summary:</b>\r\nThe paper presents code to enable ITK to read and write the MINC2 file format.\r\n \r\n<b>Evidence:</b>\r\nThe authors provide a small test program which manipulates one test dataset that is provided. The test strategy seems to be visual - the results of the program are inspected for correctness by eye - rather than numerical.\r\n\r\n<b>Open Science:</b>\r\nThe paper adheres to the principles of open science. The work is reproducible.\r\n\r\n<b>Reproducibility:</b>\r\nI downloaded, compiled and ran the code. In that sense I reproduced the work. However the test strategy may not be adequate to fully test the code.\r\n\r\nAs an example, I tried to use the code to read my own data, but I had difficulty. I was only able to read the data provided with the code. In particular, i was not able to read data from MNI Brainweb, which would probably be a major use of this module. I got the following error in all cases:\r\n<CODE>\r\nrbrook@spender{IO}../../test/itkMINC2ImageIOTest ~/t1_icbm_normal_1mm_pn3_rf20.mnc \r\n This is a test for MINC2!!\r\nexception in file reader \r\nitk::ERROR: MINC2ImageIO(0x85a9b80): Unknown component type: 0\r\nUnknown\r\n</CODE>\r\nI am not sure if this problem was due to my data being in MINC1 format, or other reasons. The MINC2 library is supposed to be backwards compatible with MINC1, but it may be the case that the module presented here does not support reading minc1. I did not pursue this in great detail at this time.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe provided code will allow the open source ITK package to read the file format of the open source MINC tools. It is entirely open source based.\r\n\r\n<b>Open Source Contributions:</b>\r\nSource code is provided, however, it does not compile without editing. The line\r\n<CODE>\r\n#include \\\"itkMINC2ImageIOFactory.h\\\"\r\n</CODE>\r\nmust be commented out of itkMINC2ImageIOTest.cxx for it to compile. Furthermore, the writing in the paper implies that other code may exist that was not provided. Specifically, they mention that the module was added to ITK as an advanced option, but no CMAKE was provided. Also, the use of the pluggable factories was discussed - but an itkMINC2ImageIOFactory class was not provided. The commented line above implies that it exists somewhere.\r\n\r\nAdditional documentation on building the needed external libraries may be helpful. To assist other reviewers, i give some tips here - these worked for me on RedHat8 linux, there may be other and better solutions.\r\n<OL>\r\n<LI>In addition to the minc2, hdf and netcdf libraries, i found that the szip library was also required. Its true that its required for HDF, not for this code particularly, but its still useful to know.\r\n<LI>When building and installing these libraries, build and install them in this order: netcdf, szip, hdf, minc2.\r\n<LI>When linking the provided code, i found that the following link order worked \r\n<CODE><.o files> ... other stuff.... -lminc2 -lnetcdf -lhdf5 -lsz -lz </CODE>\r\n</OL>\r\n\r\n<b>Code Quality:</b>\r\nThe authors name and affiliation only appears in the .h file, not at the top of the .cxx file. The test file does not seem to meet the ITK testing standard of testing every method thoroughly. Beyond that, I did not read the code in detail.\r\n\r\n<b>Suggestions for future work:</b>\r\nI think that a more thorough test strategy would be needed to verify the code. As an example, minc is capable of storing data internally in any orientation and order (that is xyz, zyx, row major, column major, etc). I have seen other minc reading code work (using the minc1.4 library) on some orders and not others, so a thorough testing is required. Same applies for different numbers of dimensions, and different types of data (byte, int, etc).\r\n\r\nAdding the Factory classes would be very useful. \r\n\r\nA CMAKE build script, or instructions for modding the ITK CMakeList would also be helpful.\r\n\r\nIs the code intended to read MINC version 1 files? The minc2 library should be capable of it and this would be useful. \r\n\r\n<b>Additional Comments:</b>\r\nI think that this is an extremely useful contribution. Once tested and shown to be reliable, i would probably use this daily in my work. The MINC tools provide a valuable set of open source medical imaging tools, complementary to ITK. Furthermore, there is much data available in MINC, and the conversion process into a format that ITK can read and vice versa is time-consuming and risks losing data. \r\n\r\nWith regard to the paper itself, it would be important to add the author and date somewhere. It is not obvious how to contact the author. Style and grammar wise there are some issues, but as the main contribution is the code, i consider this relatively less important.", "review_id": 138}, {"date": "02-03-2006", "author": {"author_id": 310, "author_email": "mathieu.malaterre@gmail.com", "author_lastname": "Malaterre", "author_firstname": "Mathieu"}, "content": "<b>Summary:</b>\r\nThis is submission to add support for MINC2 file format for the Insight toolkit.\r\n \r\n<b>Evidence:</b>\r\nAuthor provide the standard mechanism in ITK to read and write IO file (lacking the factory, but author seems to have it).\r\n\r\n<b>Open Science:</b>\r\nThe work is reproducible.\r\n\r\n<b>Reproducibility:</b>\r\nI did download, compile and run the code (test example + demo file). Nothing is described to let people know about expected result.\r\n\r\n#1. The code is missing a CMakeLists.txt file. Here is the one I used:\r\n---------------------------------------------------------------------------------------------------\r\nPROJECT(ITKMINC)\r\nFIND_PACKAGE(ITK REQUIRED)\r\nINCLUDE(${ITK_USE_FILE})\r\nINCLUDE(${ITKMINC_SOURCE_DIR}/FindMINC2.cmake)\r\nINCLUDE_DIRECTORIES(${MINC2_INCLUDE_DIR})\r\nADD_EXECUTABLE(itkminc itkMINC2ImageIOTest.cxx itkMINC2ImageIO.cxx)\r\nTARGET_LINK_LIBRARIES(itkminc ITKIO ${MINC2_LIBRARIES} hdf5 netcdf)\r\n---------------------------------------------------------------------------------------------------\r\n\r\nand I also wrote a FindMINC2.cmake since the library is not so standard (very new)\r\n\r\n---------------------------------------------------------------------------------------------------\r\nFIND_PATH(MINC2_INCLUDE_DIR minc2.h\r\n/usr/include\r\n/usr/local/include\r\n)\r\nFIND_LIBRARY(MINC2_LIBRARIES minc2\r\n/usr/lib\r\n/usr/local/lib\r\n)\r\n---------------------------------------------------------------------------------------------------\r\n\r\nThen on a regular debian system you also need to install the following package:\r\nnetcdfg-dev\r\nlibhdf5-serial-dev\r\nRecommended package are:\r\nminc-tools\r\nhdf5-tools\r\n(although minc-tools only support minc1 file).\r\n\r\nI ran into multiple compilation issues, first one is none const correctness which is a big issue for ITK. I made some change to the code to replacer \\\\\\'char*\\\\\\' with std::string and char** with std::vector<std::string>\r\nThis affect: GetDimensionOrder / SetDimensionOrder\r\nFurthermore m_DimensionOrder was leaking (not destroyed in destructor) replacing it with std::string, ensure both const correctness and prevent memory leak. Same problem with m_DimensionName (never deleted).\r\nThen the test file try to includes: itkMINC2ImageIOFactory.h which not available, removing the guilty line fix the compilation\r\nThere is problem with #define MINC2_MAXDIM 10 what does it refers to ? This is only in the cxx, and not header, this cannot be user driven. More comment should be made about this #define\r\nEven after all those patch the code compiles with lots of warnings:\r\n\r\n/tmp/minc/itkMINC2ImageIO.cxx: In member function \\\\\\'virtual void itk::MINC2ImageIO::Read(void*)\\\\\\':\r\n/tmp/minc/itkMINC2ImageIO.cxx:111: warning: comparison between signed and unsigned integer expressions\r\n/tmp/minc/itkMINC2ImageIO.cxx: In member function \\\\\\'virtual void itk::MINC2ImageIO::ReadImageInformation()\\\\\\':\r\n/tmp/minc/itkMINC2ImageIO.cxx:253: warning: comparison between signed and unsigned integer expressions\r\n/tmp/minc/itkMINC2ImageIO.cxx:354: warning: comparison between signed and unsigned integer expressions\r\n/tmp/minc/itkMINC2ImageIO.cxx: In member function \\\\\\'virtual void itk::MINC2ImageIO::Write(const void*)\\\\\\':\r\n/tmp/minc/itkMINC2ImageIO.cxx:474: warning: comparison between signed and unsigned integer expressions\r\n/tmp/minc/itkMINC2ImageIO.cxx:479: warning: unused variable \\\\\\'dimseparation\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx:480: warning: unused variable \\\\\\'dimstart\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx:581: warning: comparison between signed and unsigned integer expressions\r\n/tmp/minc/itkMINC2ImageIO.cxx:538: warning: unused variable \\\\\\'minval\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx:539: warning: unused variable \\\\\\'maxval\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx:541: warning: unused variable \\\\\\'nChannels\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx: At global scope:\r\n/tmp/minc/itkMINC2ImageIO.cxx:593: warning: unused parameter \\\\\\'fileName\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx:593: warning: unused parameter \\\\\\'buffer\\\\\\'\r\n/tmp/minc/itkMINC2ImageIO.cxx: In member function \\\\\\'void itk::MINC2ImageIO::SetSliceScalingFromLocalScaling(mivolume*)\\\\\\':\r\n/tmp/minc/itkMINC2ImageIO.cxx:631: warning: comparison between signed and unsigned integer expressions\r\n/tmp/minc/itkMINC2ImageIO.cxx:636: warning: comparison between signed and unsigned integer expressions\r\n\r\nRunning through valgrind lead to the following memory leak:\r\nRunning the example throught valgrind lead to the following problems:\r\n\r\n==22892== Conditional jump or move depends on uninitialised value(s)\r\n==22892== at 0x80AB747: _miget_volume_class (volume.c:885)\r\n==22892== by 0x80ABFBB: miopen_volume (volume.c:1061)\r\n==22892== by 0x809A392: itk::MINC2ImageIO::ReadImageInformation() (itkMINC2ImageIO.cxx:190)\r\n==22892== by 0x80945BE: itk::ImageFileReader<itk::Image<unsigned short, 3>, itk::DefaultConvertPixelTraits<unsigned short> >::GenerateOutputInformation() (itkImageFileReader.txx:138)\r\n==22892== by 0x475BF12: itk::ProcessObject::UpdateOutputInformation() (itkProcessObject.cxx:690)\r\n==22892== by 0x8083FFD: itk::ImageBase<3>::UpdateOutputInformation() (itkImageBase.txx:174)\r\n==22892== by 0x471692F: itk::DataObject::Update() (itkDataObject.cxx:342)\r\n==22892== by 0x475BFCC: itk::ProcessObject::Update() (itkProcessObject.cxx:554)\r\n==22892== by 0x806E804: main (itkMINC2ImageIOTest.cxx:71)\r\n\r\nInspecting result, using the micnc tools still gives some errors are reported:\r\n$ mincstats LF2.mnc\r\n*** /tmp/minc-install/bin/mincstats - reported max (6) doesn\\\\\\'t equal header (255)\r\n$ mincstats test5.mnc\r\n*** /tmp/minc-install/bin/mincstats - reported max (0.0015259) doesn\\\\\\'t equal header (1)\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe provided code will allow the open source ITK package to read the file format of the open source MINC tools. It is entirely open source based.\r\n\r\n<b>Open Source Contributions:</b>\r\nAuthor did provide part of the code they use. More code need to be sent for full integration into ITK. See Reproducibility for problems at compile time.\r\n\r\n<b>Code Quality:</b>\r\nOn overall the code did not respect ITK coding style ( identation, comment, use of cerr instead of itkDebugMacro). there are at least two functions not used:\r\nReadVolume and WriteSlice. There are some commented code at toplevel of cxx file.\r\n\r\nThe code itself might also be leaking since I can see a:\r\n midimhandle_t *hdims = new midimhandle_t[m_NDims];\r\nbut nowhere can I find a delete[]\r\n\r\nAnd a minor problem is the use of const char pointer instead of cstring:\r\n const char *vname = \\\\\\\"vector_dimension\\\\\\\";\r\nshould be\r\n const char vname[] = \\\\\\\"vector_dimension\\\\\\\";\r\n\r\nLast point: the code is not PIMPLed. This means that ITK will have to include netcdf, hdf and minc header file every time one include the itkMINC2 header.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe code should be reviewed by author for next submission. More test should be written to. In particular it should not segfault on minc1 file. Commented code should go away, unused code too.\r\nAlso submission to Insight Journal require the use of template. As far as I understand this is not the case:\r\nhttp://www.itk.org/Wiki/ITK_Procedure_for_Contributing_New_Classes_and_Algorithms#How_to_Prepare_a_Submission_to_the_Insight_Journal\r\n\r\n<b>Additional Comments:</b>\r\nAs usual file format are the entry point to ITK world and therefore is always very welcome. \r\nAs a side note the external libraries involve are huge, therefore I would delay until some agreement is made for which library actually goes into ITK.\r\n", "review_id": 173}, {"date": "07-03-2006", "author": {"author_id": 197, "author_email": "richard.beare@ieee.org", "author_lastname": "Beare", "author_firstname": "Richard"}, "content": "<b>Summary:</b>\r\nThis paper introduces IO support for MINC 2.0 images. MINC, from the Montreal Neurological Institute, is a format derived from netcdf and hdf5, and there is a range of valuable tools that will be much more accessible if the file format is usable from ITK. \r\n\r\n<b>Evidence:</b>\r\nThe authors provides example data files and sample code. There is no confirmation that the data is correct once loaded - This could be done using the other minc tools, or ImageCompare.\r\n\r\n<b>Open Science:</b>\r\nThe work adheres to Open Science principles.\r\n\r\n<b>Reproducibility:</b>\r\nI was successful in reproducing the work.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe minc libraries are open source and use other open source tools.\r\n\r\n<b>Open Source Contributions:</b>\r\nYes, but see suggestions for future work.\r\n\r\n<b>Suggestions for future work:</b>\r\nWhile this contribution is a very good start, it isn\\\\\\'t fully integrated into the toolkit. It would be a great benefit if it was. Other reviewers have recommended ways in which the end user can carry out this integration, and I had much the same experience. I would strongly encourage ITK developers to look at including support for MINC2 directly in ITK, because there are a variety of valuable applications from MNI that work with minc format images. \r\n\r\nI discovered incompatibility problems between the code included in this project and various versions of the minc2 libraries. It appears that the most recent version of minc2 changed the API slightly, resulting in compilation errors for this project. Earlier versions had problems with some releases of hdf5. I hope that these are issues that will get sorted out with time.\r\n\r\n\r\n<b>Additional Comments:</b>\r\nA good start for what should become a very valuable contribution.", "review_id": 233}], "publication_id": 64},
{"reviews": [{"date": "01-09-2006", "author": {"author_id": 286, "author_email": "dan.muel@gmail.com", "author_lastname": "Mueller", "author_firstname": "Dan"}, "content": "<b>Summary:</b>\r\nThe authors discuss how to extract regional minima/maxima regions from binary/greyscale images. Two approaches are presented and compared: 1. the current ITK approach using the HConvexImageFilter and HConcaveImageFilter, and 2. a new approach using a simple flooding-based algorithm (referred to by the authors as <i>ValuedRegionalExtremaImageFilter</i>).\r\n \r\n<b>Hypothesis:</b>\r\nThe hypothesis is that the ValuedRegionalExtremaImageFilter approach is computational faster than the HConvexImageFilter/HConcaveImageFilter approach. Test results indicate that the proposed approach (ValuedRegionalExtremaImageFilter) is faster.\r\n\r\n<b>Evidence:</b>\r\nEach approach has been implemented in ITK and execution times reported in the paper.\r\n\r\n<b>Open Science:</b>\r\nFull open source for the filters, examples and tests, as well as input images, are provided. \r\n\r\n<b>Reproducibility:</b>\r\nI was able to download, compile, and run the work. However, I had some minor problems compiling the code because I was using an older version of ITK (InsightToolkit-2.2.0). Compiling with InsightToolkit-2.4.1 was successful. I was also unable to run the tests because they rely on the DART Image Compare program. (Does anyone know how I can obtain the Image Compare program for testing Insight Journal articles? The IJ WIKI mentions that DART tests use Image Compare, but it does not explain how to obtain it for desktop testing/reproducibility.)\r\n\r\n<b>Use of Open Source Software:</b>\r\nUses ITK.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code was relatively easy to get going (besides the minor unrelated issues listed above).\r\n\r\n<b>Code Quality:</b>\r\nThe code quality is fairly easy to read. However, I would like to see more comments within ValuedRegionalExtremaImageFilter::GenerateData() more fully explaining the algorithm - I find it hard to read what is being done and why.\r\n\r\n<b>Final Thoughts:</b>\r\nThanks for this addition to ITK. The speed increases for finding regional maxima/minima will help enhance various segmentation tasks. A comprehensive, well presented paper.\r\n\r\n", "review_id": 147}], "publication_id": 65},
{"reviews": [{"date": "01-30-2006", "author": {"author_id": 132, "author_email": "karthik.krshnan@gmail.com", "author_lastname": "Krishnan", "author_firstname": "Karthik"}, "content": "<b>Compiling matitk.dll</b>\r\nI was able to compile the code with VS71 as the compiler. If the matlab version you have is old (for instance 6.5), you will need to get the <a href=\\\"http://www.mathworks.com/support/solutions/data/1-1BRI9.html?solution=1-1BRI9\\\">options file</a> for VS71.\r\n\r\nI made the suggested changes to the bin/win32/mexopts/msvc71opts.bat file. (setting ITKBIN, ITKSRC environment variables and adding the working directory to the list paths. <tt>path(path,\\\"c:/tmp/foo\\\")</tt>).\r\n\r\nI had two errors compiling the code, since the code was instantiating curvature flow filters etc on unsigned int images. The errors were trivial to remove. Below is the patch to remove the compiler errors and will be fixed in ITK CVS.\r\n\r\nRegarding the dll shipped with the paper, the permissions of the dll needs to have executable permission otherwise matlab fails to load the dll.\r\n\r\n<b>Testing</b>\r\n\r\nI was able to load the built in mri dataset and perform filtering etc in a jiffy. That was convenient.\r\n\r\n<b>Usability</b>\r\n\r\nTraditionally matlab has been a storehouse for well established image processing/ enhancement algorithms. There are several external analysis packages available such as LightSpeed, SPM etc.. I do not know of any packages that perform registration. ITK on the other hand has bleeding edge segmentation and registration algorithms along with basic image processing algorithms. \r\n\r\nA very useful thing to do will be to conveniently perform registration in ITK and continue with filtering and analysis in MATLAB, since MATLAB lacks registration algorithms. MATITK provides two registration algorithms, Demos and TPS. I tried out Demons and it seemed to work fine. It should probably supply a lot more registration algorithms. Also, there is no way to currently specify the origin or the images. For instance the fixed and moving images could be acquired in different reference frames.\r\n\r\nAny submission to MATLAB central ?\r\n\r\n\r\n<b>Inclusion in the toolkit</b>\r\n\r\nI propose the framework be included with InsightApplications. I am sure many in the academic community would find it useful.\r\n\r\n\r\nIndex: Algorithms/itkMinMaxCurvatureFlowFunction.txx\r\n===================================================================\r\nRCS file: /cvsroot/Insight/Insight/Code/Algorithms/itkMinMaxCurvatureFlowFunction.txx,v\r\nretrieving revision 1.23\r\ndiff -u -b -r1.23 itkMinMaxCurvatureFlowFunction.txx\r\n--- Algorithms/itkMinMaxCurvatureFlowFunction.txx\t13 Mar 2005 23:19:40 -0000\t1.23\r\n+++ Algorithms/itkMinMaxCurvatureFlowFunction.txx\t30 Jan 2006 16:08:14 -0000\r\n@@ -369,7 +369,7 @@\r\n {\r\n gradient[2] = -1.0;\r\n }\r\n- theta = acos( gradient[2] );\r\n+ theta = acos( (double)gradient[2] );\r\n \r\n if ( gradient[0] == 0 )\r\n {\r\n@@ -377,7 +377,7 @@\r\n }\r\n else\r\n {\r\n- phi = atan( gradient[1]/ gradient[0] );\r\n+ phi = atan( (double)gradient[1]/ (double)gradient[0] );\r\n }\r\n \r\n \r\nIndex: BasicFilters/itkSparseFieldLevelSetImageFilter.txx\r\n===================================================================\r\nRCS file: /cvsroot/Insight/Insight/Code/BasicFilters/itkSparseFieldLevelSetImageFilter.txx,v\r\nretrieving revision 1.36\r\ndiff -u -b -r1.36 itkSparseFieldLevelSetImageFilter.txx\r\n--- BasicFilters/itkSparseFieldLevelSetImageFilter.txx\t22 Dec 2004 15:18:23 -0000\t1.36\r\n+++ BasicFilters/itkSparseFieldLevelSetImageFilter.txx\t30 Jan 2006 16:08:14 -0000\r\n@@ -480,7 +480,7 @@\r\n { this->SetRMSChange(static_cast<double>(m_ValueZero)); }\r\n else\r\n {\r\n- this->SetRMSChange(static_cast<double>( vcl_sqrt(rms_change_accumulator / static_cast<ValueType>(counter)) ) );\r\n+ this->SetRMSChange(static_cast<double>( vcl_sqrt((double)(rms_change_accumulator / static_cast<ValueType>(counter)) )) );\r\n }\r\n }\r\n \r\n@@ -841,7 +841,7 @@\r\n length += dx_backward * dx_backward;\r\n }\r\n }\r\n- length = vcl_sqrt(length) + MIN_NORM;\r\n+ length = vcl_sqrt((double)length) + MIN_NORM;\r\n distance = shiftedIt.GetCenterPixel() / length;\r\n \r\n output->SetPixel( activeIt->m_Value , \r\n\r\n", "review_id": 159}], "publication_id": 66},
{"reviews": [], "publication_id": 67},
{"reviews": [], "publication_id": 68},
{"reviews": [], "publication_id": 69},
{"reviews": [], "publication_id": 70},
{"reviews": [{"date": "02-11-2006", "author": {"author_id": 232, "author_email": "millerjv@research.ge.com", "author_lastname": "Miller", "author_firstname": "James"}, "content": "This submission provides a functor style filter to perform operations similar to the AccumulateImageFilter.\r\n\r\nThe difference with respect to the AccumulateImageFilter is that this filter is templated over a functor. This allows a variety of accumulation methods (mean, min, max, median, etc.). This makes a nice design, allowing it to be easily extended by providing a new functor to perform the \\\"accumulation\\\" of a dimension.\r\n\r\nWe have discussed extending the AccumulateImageFilter with additional methods using a set of modes. The functor style allows for the filter to be extended more easily.\r\n\r\nThe author indicates the AccumulateImageFilter cannot be modified to do this without jeapordizing backward compatibility. I offer two suggestions that may address this:\r\n\r\n1. AccumulateImageFilter could be made a subclass of the ProjectionImageFilter, where the subclass specifies a functor that allows the current AccumulateImageFilter functionality (mean and sum).\r\n2. Or, the AccumulateImageFilter could be extended to have an extra template parameter (the functor) but that template parameter will default to the function that provides the current AccumulateImageFilter functionality.\r\n\r\nA comment on the API. The AccumulateImageFilter use Set/GetAccumulateDimension() methods to indicate the projection direction. The filter in this submission provides a Set/GetAxe() method. I suggest the Set/GetAxe be renamed to Set/GetAccumulateDimension(). Alternatively, the method could be Set/GetAxis(). However, in ITK we never refer to a dimension as an axis. So the method should really be Set/Get*Dimension() (perhaps Set/GetProjectionDimension()).\r\n\r\n\r\n\r\n", "review_id": 179}, {"date": "12-05-2006", "author": {"author_id": 526, "author_email": "todd.gable@ge.com", "author_lastname": "Gable", "author_firstname": "Todd"}, "content": "I found the AccumulateImageFilter incomplete, it only collapses the last dimension and with only the option to use the mean. The Image projection filter did exactly what I wanted with the flexibility of choosing which functor to use (mean, median, max, etc.). I was surprised something like this didn&#39;t already exist in ITK, Image projection should be added to an ITK release soon.", "review_id": 442}], "publication_id": 71},
{"reviews": [], "publication_id": 72},
{"reviews": [], "publication_id": 73},
{"reviews": [], "publication_id": 74},
{"reviews": [{"date": "02-15-2006", "author": {"author_id": 102, "author_email": "sylvainjaume@gmail.com", "author_lastname": "Jaume", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThe paper describes two connected component algorithms and analyzes their improved performance compared to the connected component filter in the InsightToolkit.\r\nIn a three-step process, every connected component in a binary image receives a different label. The pixel intensity inside every component is replaced with the value of its label.\r\nThis operation is particularly useful as a pre-processing step to extract the largest component in an image or to measure the size of anatomical structures.\r\n\r\n<b>Evidence:</b>\r\nThe author describes his experiments in details and gives useful tips for researchers interested in optimizing their algorithms.\r\nThe code and data for the performance analysis are provided. However a pair of example input/output images would help to check if the executable gives the expected result.\r\n\r\n<b>Open Science:</b>\r\nFully Open Science. Almost Open Data: the input images are provided, not the output images.\r\nI understand that this was not intentional but the author did not see the need for providing the output images. Those images could be easily added as a revision.\r\nI really appreciate that the author comments his experiment process and mentions other directions.\r\n\r\n<b>Reproducibility:</b>\r\nI compiled the code with MS VS8 and run it. The process is seamless.\r\nI could not compare the output image I got with what the code is expected to return (see above comment).\r\n\r\n<b>Open Source:</b>\r\n100% ITK. Excellent code quality.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nI would like to see a pair of input/output images in the paper and the archive, along with the list of arguments used.\r\n\r\n<b>Additional Comments:</b>\r\nWhat would be impact on the performance to collapse the labels in a way that all labels from 0 to number_of_components are used?\r\nI tried the code on an image with 2 components on a black background, and the result image had labels 0, 1 and <b>18</b>.\r\nI would like to avoid having a second filter to re-label 0, 1 and 18 to 0, 1 and 2.", "review_id": 188}, {"date": "02-20-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<b>Summary:</b>\r\nThe author describe some methods to improve the performance of the connected component filter, including a new algorithm, and show an important increase of performance.\r\n \r\n<b>Evidence:</b>\r\nThe author compare the output of the current itk\\'s filter and his modified ones. However he doesn\\'t show the result images, thing that shouold be done to validate his program of comparison of labeled images.\r\n\r\n<b>Open Science:</b>\r\nThe autho provide a good description of his work on current filter, and of the new algorithm, and even give some comment on optimization methods. This is open science.\r\n\r\n<b>Reproducibility:</b>\r\nSeveral test are failing, both on my 32 and 64 bits linux box. It should be fixed before including the result in ITK\r\n\r\n<b>Open Source Contributions:</b>\r\nThe code is usable without problem\r\n\r\n<b>Code Quality:</b>\r\nCode have very good quality\r\n\r\n<b>Applicability to other problems:</b>\r\nAgain a filter which can be used as the base of lots of image analysis methods\r\n\r\n<b>Suggestions for future work:</b>\r\nI think the algorithm can be threaded, and thus, give another performance improvement.\r\nAlso, I think you should use an internal type which support a higher range of values (for example NumericTraits< PixelType >::AccumulateType), so the labeling can succeed even if the number of values is near the maximum value of the type. This addition would require to change the labels (with a new equivalency table ?) and would also avoid the problem of relabeling after the labeling process only to have labels set like 0, 1 and 18. The cost of shouldn\\'t be too high.\r\n\r\n<b>Additional Comments:</b>\r\nthe \\\"only\\\" 4 starts are only for the broken tests; it\\'s a very good contribution.\r\nI will send you the error messages.", "review_id": 195}], "publication_id": 75},
{"reviews": [{"date": "02-26-2007", "author": {"author_id": 557, "author_email": "kevin.robinson@eeng.dcu.ie", "author_lastname": "Robinson", "author_firstname": "Kevin"}, "content": "<strong>Summary:<br /></strong><font size=\\\"\\\\\\\\\\\\\\\">The author demonstrates that Vincent&#39;s reconstruction by dilation algorithm is more suitable for processing non-integer data than Robinson&#39;s (which was the one then implemented in ITK)</font><br /><br /><strong>Evidence:<br /></strong><font size=\\\"\\\\\\\\\\\\\\\">Tests of the author&#39;s implementation of Vincent&#39;s algorithm produce identical results in less time.</font><br /><strong><br />Open Science:<br /></strong><font size=\\\"\\\\\\\\\\\\\\\">Satisfactory information seems to be provided in all respects.</font><br /><strong><br /></strong><strong>Open Source Contributions:<br /></strong><font size=\\\"\\\\\\\\\\\\\\\">Drop in replacement routines are provided.</font><br /><strong><br /></strong><strong>Applicability to other problems:<br /></strong><font size=\\\"\\\\\\\\\\\\\\\">See comments below.</font><br /><strong><br /></strong><strong>Additional Comments:</strong><br /><font size=\\\"\\\\\\\\\\\\\\\">It was interesting to discover that the downhill filter algorithm had been implemented in ITK, even if I only found out after it had been superseded. I would like to pass on a few thoughts on the subject.<br /></font><font size=\\\"\\\\\\\\\\\\\\\"><br />I would certainly agree with the author&#39;s comment on page 2, that the `pure&#39; implementation may perform better than the one implemented in ITK. At the heart of the original downhill algorithm was an assumption of integer data. I wouldn&#39;t hesitate in recommending Vincent&#39;s algorithm over my own where non-integer data is to be accommodated. I have never so far found myself working with other than integer data in my career in medical image analysis, hence my own design decisions in this regard. The core of the algorithm is the dynamically allocated `istart&#39; array (see [1], Appendix B, page B-15) which effectively implements an ordered array of lifo lists. This approach cannot be taken with non-integer data. For full details of the algorithm see Chapter 4 of [1], which is an expanded version of the Pattern Recognition Letters paper cited by the author.<br /><br />It is interesting to note (though not necessarily significant) that the time for processing the `cthead&#39; test image (0.0218) reported in the authors paper is identical to that reported in [1] for the same (Vincent) algorithm applied to another 256x256 test image (Study 2 MIP, see [1], Table 4.2, p110). In this case the downhill algorithm took just 0.0094 seconds to perform the same processing, while the modified ITK version reported in the author&#39;s paper took 0.1324. I would conclude (not having examined the ITK code in detail) that the port to a non-integer handling algorithm has, of necessity, neutralised the performance gains of the original downhill filter design.<br /><br />Finally it may be of interest that a number of other image processing filters can be approached in a similar way, for instance the grassfire distance transform. Again see Chapter 4 and Appendix B of [1], for more details.<br /><br />[1] Efficient pre-segmentation filtering in mrcp, K Robinson. Ph.D. Thesis, Dublin City University, Ireland, 2005, <a href=\\\"http://www.eeng.dcu.ie/~robinsok/pdfs/Robinson_PhDThesis2005.pdf\\\">http://www.eeng.dcu.ie/~robinsok/pdfs/Robinson_PhDThesis2005.pdf</a></font>", "review_id": 458}, {"date": "02-20-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<b>Summary:</b>\r\nThe paper describe a new implementation of the morphological reconstruction filters, and show an important increase of performance.\r\n \r\n<b>Evidence:</b>\r\nThe author show that the output of the new filter is exactly the same the output of the old one.\r\n\r\n<b>Open Science:</b>\r\nThe author provides a good description of his filter, the source code, and the input images. The output images are produced by the filters without problem.\r\n\r\n<b>Reproducibility:</b>\r\nI was able to build the project and run the test on linux mandriva 32 and 64 bits without any problem.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe code can be replace without any problem the old one - I\\'m already using that code as a replacement of the old filters.\r\n\r\n<b>Code Quality:</b>\r\nThe code quality is very good and well documented. The usage of functor avoid duplication of code - that was not the case with the old filters.\r\n\r\n<b>Applicability to other problems:</b>\r\nMorphological reconstruction is very useful, and is already used in several filters in ITK. It is a base transform for the family of connected filters.\r\n\r\n<b>Suggestions for future work:</b>\r\nContinue to implement such efficient filters :-)\r\n", "review_id": 194}], "publication_id": 76},
{"reviews": [{"date": "04-14-2006", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis papers describes the implementation of a exact signed distance map as an ITK filter according to the paper by Maurer et al. This implementation is compared against the current Danielsson distance map existing in ITK.\r\n\r\n \r\n<b>Hypothesis:</b>\r\nIt was claimed that the Maurer algorithm for computing distance maps was more efficient than the method by Danielsson. The ITK toolkit only had an implementation of the Danielsson filter and was lacking the implementation of Maurer\\\\\\'s algorithm. By providing now open source implementation of these two very useful methods, it becomes possible to experimentally verify the performance ratio between these two algorithms. It is reasonable to expect that the availability of this comparison will encourage improvements in the open source implementations of each one of them.\r\n\r\n<b>Evidence:</b>\r\nThe authors ran the existing Danielsson distance map and their new implementation of the Maurer\\\\\\'s algorigthm in a set of synthetic binary images, both in 2D and 3D. Computational times for these test are reported in the paper.\r\n\r\n<b>Open Science:</b>\r\nThe papers is an excellent example of the Open Science methodology. The description of the problem is clear and direct. The authors provide the source code of the implemented filter as well as tests for running the filter in several synthetc images. The input images and output images are provided. \r\n\r\n<b>Reproducibility:</b>\r\nThe material provided by the authors was sufficient for reproducing the work. It took only about 30 minutes to download, configure, build and run the code with its tests.\r\n\r\nThe only minor drawback was that the CMakeLists.txt file provided by the authors assumes that the code is going to be built in-place, and that the images resulting from the tests will be put in the Source directory also. This reviewer used the code in an out-of-source build, and therefore was forced to make a couple of changes in the CMakeLists.txt file. The section changed was the following:\r\n\r\n\r\n\r\nADD_TEST(Run1 ${SignedMaurerDistanceMapImageFilterTest} \r\n ${CMAKE_SOURCE_DIR}/binaryPhantom.hdr ${CMAKE_BINARY_DIR}/out1.hdr)\r\nADD_TEST(CompareImage1 ImageCompare ${CMAKE_BINARY_DIR}/out1.hdr\r\n ${CMAKE_SOURCE_DIR}/binaryPhantom_out.hdr)\r\n\r\nADD_TEST(Run2 ${SignedMaurerDistanceMapImageFilterTest} \r\n ${CMAKE_SOURCE_DIR}/SquareBinary201.hdr ${CMAKE_BINARY_DIR}/out2.hdr)\r\nADD_TEST(CompareImage2 ImageCompare ${CMAKE_BINARY_DIR}/out2.hdr\r\n ${CMAKE_SOURCE_DIR}/SquareBinary201_out.hdr)\r\n\r\nADD_TEST(Run3 ${SignedMaurerDistanceMapImageFilterTest} \r\n ${CMAKE_SOURCE_DIR}/peep0_seg01.hdr ${CMAKE_BINARY_DIR}/out3.hdr)\r\nADD_TEST(CompareImage3 ImageCompare ${CMAKE_BINARY_DIR}/out3.hdr\r\n ${CMAKE_SOURCE_DIR}/peep0_seg01_out.hdr)\r\n\r\n\r\nWhere the \\\\\\\"${CMAKE_BINARY_DIR}\\\\\\\" was added before \\\\\\\"out.hdr\\\\\\\"\r\n\r\n\r\n\r\nIt will also be desirable to use names out1.hdr, out2.hdr, and out3.hdr for each one of the test,\r\nin that way the three images will still be availble at the end of the test. There is not need to reuse\r\nthe filename, since these images are pretty small anyways.\r\n\r\nThe reviewer used this code in Cygwing wth gcc 3.4, in a laptop Dell D810 with Pentium 4 at 1.86Ghz.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors made the optimal combination of open source use. Their work is based on open source tools (ITK), and their contribution is also sent back as an open source filter .\r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code is in very good shape. It was possible to use it without any modifications. The distance map filter contributed by the authors is already in the form of an ITK filter, and could be included in the ITK toolkit with minimal modifications, mostly related to coding style.\r\n\r\n<b>Code Quality:</b>\r\nThe provided has good quality and already follows most of the ITK coding practices. The authors also included in their implementation a very similar API to the one of the Danielsson distance. It is therefore very easy to replace one with the other in the places where a distance map filter is needed.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe Distance Map filter is an extremely useful tool in medical image processing. The superior performance of the Maurer\\\\\\'s algorithm with respect to the Danielsson algorithms seems to indicate that this new implementation should replace the Danielsson distance in some places in the Toolkit. For example in the CannyLevelSet segmentation filter.\r\n\r\n\r\n<b>Suggestions for future work:</b>\r\nThe RemoveEDT() method could probably be speed up by using an inlined implementation. \r\nThe use of acronyms such as EDT is dicouraged in ITK. It will be more convenient to use the full spelling : ExactDistanceTransform.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe authors mention in the paper, evaluations of the method in 3D images. It would have been nice to include those 3D images along with the 2D ones. The infrastructure of the Insight Journal would have supported those images easily, and will have provided a convincing evidence to readers that the filter is effective in 3D.\r\n\r\nThe comparision of the output between the Maurer\\'s and Danielsson\\'s filter should have included a subtraction of the two output images. The paper presents the two images, which at naked eye look identical. It is interesting however to compute the difference and illustrates the kind of patterns that the difference image will have. This will be useful for those who need to make a decision regarding which one of these two filters to use. The filter SquaredDifferencesImageFilter could provided this comparison easily.\r\n\r\nhttp://www.itk.org/Insight/Doxygen/html/classitk_1_1SquaredDifferenceImageFilter.html\r\n\r\n\r\n\r\nThis reviewer was able to verify the good behavior of the filter in a 3D image, by just chaning the dimension of the image in the test provided by the authors.\r\n\r\n\r\n\r\n<b>Additional Comments:</b>\r\nThis is an excellent contribution to the medical image processing community, and a success story for the approach of Open Science and electronic publishing. The posting of this paper made possible in a single day to improve performance in method used by other groups in the country. Despite the fact that this algorithm has been published for about 3 years, this new open source implementation raises its impact by making it inmediately available to readers. We anticipate that this filter will make it soon to a future release of the ITK toolkit.\r\n\r\n", "review_id": 221}, {"date": "02-19-2006", "author": {"author_id": 146, "author_email": "vamsi2200@rediffmail.com", "author_lastname": "Jammalamadaka", "author_firstname": "Vamsi"}, "content": "<b>Summary:</b>\r\nITK filter to perform signed distance transform.\r\n \r\n<b>Reproducibility:</b>\r\nI was able to download, compile, and run the work. \r\n\r\n<b>Use of Open Source Software:</b>\r\nThis is clearly Open Source code. It is written completely in itk\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors provide the full source code and documentation. It took me about 10 minutes to download and run the code.\r\n\r\n<b>Code Quality:</b>\r\nThe code quality is very good. It is easy to understand. The author provide documentation along with the code.\r\n\r\n\r\n<b>Additional Comments:</b>\r\nThis is a very useful filter to perform fast distance transforms.\r\nOur team is implementing a warping algorithm for which we use the signed distance transform on 3d images. Generating the signed distance transform is the most time consuming part of our algorithm. Due to this filter there is a 10 fold improvement in speed of our algorithm . \r\nThanks for this addition to ITK.\r\n", "review_id": 192}, {"date": "02-19-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<b>Summary:</b>\r\nThe paper describe a new filter to compute the distance map of a binary image. The author provides a more efficient filter than the current filter available in ITK\r\n \r\n<b>Evidence:</b>\r\nThe author provides source code and input and output images so it\\\\\\'s easy to validate the behavior of the filter.\r\n\r\n<b>Open Science:</b>\r\nThe author provides a good description of is filter, the source code, and the input and output image. It can be even better by also providing the source code of the timing test.\r\n\r\n<b>Reproducibility:</b>\r\nI was able to reproduce the work, with some small problems: I\\\\\\'m used to build the code in a \\\\\\\"build\\\\\\\" directory. The build succeed, but the test failed when run out of the source directory.\r\nI compile and run the code on a mandriva linux 2006.0 with a pentium 4 and 2GB of RAM.\r\nAs said above, it would have been easier with the source code of the timing test.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe code is easily usable - it is really closed itk\\\\\\'s danielsson filter.\r\n\r\n<b>Code Quality:</b>\r\nThe code quality is quite good, but the core of the implementation is not documented - it should be done before inclusion in ITK to make modification of the code easier.\r\nIndentation doesn\\\\\\'t follow the ITK convention.\r\n\r\n<b>Applicability to other problems:</b>\r\nDistance transform is the base of lots of algorithms - This efficient version will be useful in lots of cases.\r\n\r\n<b>Suggestions for future work:</b>\r\nIn the title, it\\\\\\'s said that the filter perform the computation in linear time. It would be great to see a graph which show that in the paper - \\\\\\\"time = f( number of pixels)\\\\\\\" instead of \\\\\\\"time = f( number of pixels per dimension )\\\\\\\".\r\nThe filter should report its progress - it currently doesn\\\\\\'t report it.\r\nThe ability to select the background color is interesting, but unless the common usage of this filter is for labeled images, I think it would be better to be able to select the foreground value, like it\\\\\\'s done in other filters which manipulate binary images.\r\nFinally, I would suggest to implement the squared option in a separate filter. The progress report would be easier to implement this way, and it would be possible to implement concept check for pixel types.\r\n\r\n<b>Additional Comments:</b>\r\nNote that a template for IJ contribution is available at http://voxel.jouy.inra.fr/darcs/contrib-itk/template/, and should avoid the problems of build directory, for example.\r\nThanks for that filter !\r\n", "review_id": 193}], "publication_id": 77},
{"reviews": [{"date": "04-28-2006", "author": {"author_id": 3, "author_email": "julien@jomier.com", "author_lastname": "Jomier", "author_firstname": "Julien"}, "content": "<b>Summary:</b>\r\nThis paper proposes an improvement to the GaussianDerivativeImageFunction while respecting backward compatibility.\r\n \r\n<b>Reproducibility:</b>\r\nI was able to compile the code <b>but only after modifing the main CMakeLists.txt</b>.\r\nNote that since the source code is templated there is no need to create a library for it. CMake was confused about this.\r\nThe following lines:\r\n\r\n #Add Source\r\n #SUBDIRS(Source)\r\n\r\nshould be removed from the main CMakeLists.txt\r\nThis is why the code is not showing up on the Insight Journal website.\r\n\r\n<b>Code Quality:</b>\r\nThe code looks good and respects ITK style for the most part.\r\n\r\n<b>Requests for additional information from authors:</b>\r\na) I could not find the RecomputeContinuousGaussianKernel() function in the current ITK cvs class.\r\nb) The plan is to test that the current ITK cvs is broken.\r\nThe best way is to add the current test Insight/Testing/Code/Common/itkGaussianDerivativeImageFunctionTest.cxx in your publication\r\nand add a test for spaced images at the end of this test. It would be great if you can submit a new revision with this modification.\r\nc) Why is this code not working in 3D?\r\n\r\n<b>Other comments</b>\r\nThis is a very good work. Thanks for the contribution!\r\n", "review_id": 226}], "publication_id": 78},
{"reviews": [], "publication_id": 79},
{"reviews": [], "publication_id": 80},
{"reviews": [], "publication_id": 81},
{"reviews": [], "publication_id": 83},
{"reviews": [], "publication_id": 84},
{"reviews": [{"date": "07-11-2006", "author": {"author_id": 286, "author_email": "dan.muel@gmail.com", "author_lastname": "Mueller", "author_firstname": "Dan"}, "content": "<b>Summary:</b>\r\nThis paper describes the implementation of an enhanced wrapping system for ITK. The wrappers allow access to ITK filters, algorithms and pipelines using Python (TCL and Java are on the way: waiting for other contributers/helpers).\r\n \r\n<b>Hypothesis:</b>\r\nThis paper suggests that the proposed wrapping system is easier to use, better documented, and more Python friendly than the current wrapping system.\r\n\r\n<b>Evidence:</b>\r\nThe authors present an easy to follow installation guide, a developers guide, and various examples demonstrating usage. The code is easy to understand and the Python functionality really streamlines prototyping with ITK. I have not personally used the existing wrapping system, but my experience with WrapITK has been extremely positivie. The claims made by the authors (ease of use, good documentation, and Python friendly) are well supported from the article examples and my own usage/exploration.\r\n\r\n<b>Open Science:</b>\r\nThe authors provide the cmake files for the wrapping system and point to other required software - all publically available (ie. CMake, ITK, and CableSwig).\r\n\r\n<b>Reproducibility:</b>\r\nI was able to download, configure, and compile WrapITK (with some minor issues - see below). \r\n\r\nMy system configuration was as follows:\r\n<ul>\r\n<li>Operating System=Windows XP SP2\r\n<li>CMake=CMake 2.4.2\r\n<li>Compiler=Microsoft.NET 2003 (7.1.3088)\r\n<li>ITK=InsightToolkit-2.8.1\r\n<li>CableSwig=CVS checkout on 10th July 2006, 9:30AM (GMT+10:00)\r\n<li>WrapITK=Nightly archive from http://voxel.jouy.inra.fr/darcs/contrib-itk/WrapITK/WrapITK.tar.gz downloaded on 10th July 2006, 8:45AM (GMT+10:00)\r\n<li>Python=Python 2.4.3 (#69, Mar 29 2006, 17:35:34) [MSC v.1310 32 bit (Intel)] on win32\r\n</ul>\r\n\r\nI applied the given patches, and I worked through most of the examples and achieved the same/similar results.\r\n\r\n<b>Use of Open Source Software:</b>\r\nUses CMake, ITK, CableSwig, GCC_XML, Python.\r\n\r\n<b>Open Source Contributions:</b>\r\nAll source code is provided.\r\n\r\n<b>Code Quality:</b>\r\nThe code is easy to read, and the installation/developer guides are easy to follow.\r\n\r\n<b>Applicability to other problems:</b>\r\nWrapITK allows for easy prototyping with ITK. I have been using ITK for various image analysis tasks for ~12months, and have found prototyping to be a somewhat tedious task (ie. create a temp CMake project, create main file, add includes, add all input arguments, compile, run, and repeat). Prototyping with WrapITK is <b><i>very</i></b> easy and can be achieved using either the command line interpreter or custom scripts. While the setup time may be large (it took me ~1 day to download, configure, and compile all components), I envisage that the time/engery/frustration I will save using WrapITK to prototype will far outweigh this initial outlay of time.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe article should be updated to include the itk.echo(.) function and itk.pipeline class from itkExtras/__init__.py.\r\n\r\n<b>Minor issues compiling WrapITK:</b>\r\nI encountered some minor issues compiling WrapITK on Windows. I have detailed these in an email sent to insight-users@itk.org on 11th July 2006 (http://public.kitware.com/pipermail/insight-users/2006-July/018621.html).\r\n\r\nThese issues included:\r\n1. Error accessing __FUNCSIG__ in itkGDCMSeriesFileNames.h.\r\n2. Object file format limit exceeded error (C1128) when selecting extra types to wrap (ie. setting WRAP_unsigned_short=ON).\r\n3. Ambiguous call to overloaded function \\\\\\'sqrt\\\\\\' in itkSignedMaurerDistanceMapImageFilter.txx\r\n4. Error accessing protected member EnlargeOutputRequestedRegion(.) in itkScalarConnectedComponentImageFilter.cxx.\r\n5. Minor error with Python site-packages installation for Windows.\r\n6. Incorrect string formatting in Python win32.\r\n", "review_id": 253}], "publication_id": 85},
{"reviews": [], "publication_id": 86},
{"reviews": [], "publication_id": 87},
{"reviews": [{"date": "04-20-2006", "author": {"author_id": 171, "author_email": "rupert.brooks@gmail.com", "author_lastname": "Brooks", "author_firstname": "Rupert"}, "content": "<P><b>Summary:</b>\r\n<P>This paper is a revised version of one submitted previously. It is the submission of classes to read and write MINC2 format files within the ITK pluggable factory framework.\r\n\r\n<P>This submission is significantly improved from the last version. I will incorporate this code in my code tree and begin using it regularly. Despite a few issues, I am confident enough to trust it on simple cases. However, I recommend a good code polishing and more extensive test suite.\r\n \r\n<P><b>Hypothesis:</b>\r\n<P>n/a\r\n\r\n<P><b>Evidence:</b>\r\n<P>A test which reads a minc2 file (provided), prints out a coordinate from it, and writes it out again is provided. There is no numerical testing of the result, it is presumed that the reader will view the output themselves. In fact, the provided file is rather anomalous, as its direction cosine vectors are not normalized - if you normalize them, then it seems that the directions are just along the regular axes anyway, so i am not entirely sure that this tests what it is supposed to. However, I tested it on a file where the direction cosines are normalized and not aligned with the coordinate axes and it works fine.\r\n\r\n<P><b>Open Science:</b>\r\n<P>Source code is provided. This work will, in effect, make two large bodies of open-source medical imaging software interoperable and so is very useful to open science.\r\n\r\n<P><b>Reproducibility:</b>\r\n<P>I downloaded and compiled the code. I did not actually test the CMakeLists, i just plugged the code into my own code tree where i had a place for it. \r\n\r\n<P>One edit was required to get it to compile under Visual C++7. There were some moderately serious problems with the MINC writing part. The code had some nasty access violations - I fixed the issues enough to get the test working, but i suspect the code may still need a little polishing. See code quality section below.\r\n\r\n<P><b>Use of Open Source Software:</b>\r\n<P>The work makes ITK read the open-source minc data format. It is entirely open source.\r\n\r\n<P><b>Open Source Contributions:</b>\r\n<P>The work is open source. \r\n\r\n<P><b>Code Quality:</b>\r\n<P>There were some minor difficulties compiling this code on Windows. I also had some memory access violations on the write. I tweaked it and got it to work with the following changes. From the tweaking, my overall impression is that the code is good, but not yet perfect. \r\n\r\n<P>In particular, I would expect problems when facing files where the data is not scalar or the number of dimensions is not 3. \r\n\r\n<P>I suspect there are memory leaks in the code as well, some \\\\\\\"new\\\\\\\"s do not have corresponding deletes. See the first changes in the .cxx file below.\r\n\r\n<P>Here are my diffs to the code, interspersed with comments about why.\r\n\r\n<CODE>\r\n<BR>bash-3.00$ diff /cygdrive/c/temp/itkMINC2ImageIO.h ../src/IO/itkMINC2ImageIO.h\r\n<BR>132c132,133\r\n<BR>< int m_DimensionIndices[5];\r\n<BR>---\r\n<BR>> // int m_DimensionIndices[5];\r\n<BR>> int * m_DimensionIndices;\r\n</CODE>\r\n\r\n<P>I changed this while i was fixing the access violations. The declaration of DimensionIndices was inconsistent with the declaration of the other Dimension parameters.\r\n\r\n<CODE>\r\n<BR>bash-3.00$ diff /cygdrive/c/temp/itkMINC2ImageIO.cxx ../src/IO/itkMINC2ImageIO.cxx\r\n<BR>239a240\r\n<BR>> m_DimensionIndices = new int[MINC2_MAXDIM+1];\r\n</CODE>\r\n\r\n<P>This is to make the allocation of m_DimensionIndices compatible with the other dimension parameters. I didnt put in a corresponding delete, because i was not sure where to put it. Im not sure where the other dimension parameters are deallocated. so there is probably a memory leak.\r\n\r\n<CODE>\r\n<BR>241c242,243\r\n<BR>< for (int i = 0; i <= MINC2_MAXUSE; i++)\r\n<BR>---\r\n<BR>> // for (int i = 0; i <= MINC2_MAXUSE; i++)\r\n<BR>> for (int i = 0; i <= MINC2_MAXDIM; i++)\r\n</CODE>\r\n\r\n<P>Im not sure what the difference between MAXDIM and MAXUSE is. Further in the code, there is a loop over MAXDIM and the fact that m_DimensionName was not fully initialized caused problems.\r\n\r\n<CODE>\r\n<BR>610c612\r\n<BR>< buffer += Strides[1];\r\n<BR>---\r\n<BR>> //buffer += Strides[1];\r\n612c614,615\r\n<BR>< buffer += Strides[2];\r\n<BR>---\r\n<BR>> //buffer += Strides[2];\r\n<BR>> //std::cout<<\\\\\\\"max \\\\\\\"<<tmpmaxval<<\\\\\\\" min \\\\\\\"<<tmpminval<<std::endl;\r\n</CODE>\r\n\r\n<P>Originally there was an access violation in here. I had all kinds of problems with this function. Looking at Strides in the debugger, it doesnt look at all like i think it should and besides, if you increment buffer... why increment it by Strides again later. Anyway, i just made it increment by one each time through the loop, and all seems to work. But ultimately, i see why the author wants the more sophisticated approach - maybe this could be handled on the ITK end with an iterator?\r\n\r\n<CODE>\r\n<BR>1179c1182\r\n<BR>< unsigned long coords[m_NDims];\r\n<BR>---\r\n<BR>> unsigned long * coords=new(unsigned long[m_NDims]);\r\n</CODE>\r\n\r\n<P>This makes it compile on Windows. No, i did not put in the corresponding delete.\r\n\r\n<P><b>Applicability to other problems:</b>\r\n<P>MINC is widely used, so there are likely many projects that can make use of this work.\r\n\r\n<P><b>Suggestions for future work:</b>\r\n<P>Ultimately, it would be nice to have this completely integrated in the pluggable factory design for ITK. It simply involves including itkMINC2ImageIOFactory.h and adding the line\r\n<CODE>\r\n<P> ObjectFactoryBase::RegisterFactory( MINC2ImageIOFactory::New() ); \r\n</CODE>\r\nto the itkImageIOFactory.cxx file and should be done when this code is integrated.\r\n\r\n<P><b>Requests for additional information from authors:</b>\r\n<P>n/a\r\n\r\n<P><b>Additional Comments:</b>\r\n<P>When testing this code, I was confused at first because itk::Image does not support direction cosines at all, and one must use itk::OrientedImage to do so. This is done correctly in this project, and mentioned in comments in the test file, but it might be worth drawing the readers attention to it more specifically.\r\n\r\n<P>The paper does not follow the itkJournal typographical conventions.\r\n\r\n<P>The test file provided has direction cosines that do not have magnitude 1\r\n\r\n<P>Minor spelling and grammar issues:\r\n<UL>\r\n<LI><I>wed site</I> should be <I>web site</I>\r\n<LI><I>miset_real_value_hyperslsab</I> should be <I>miset_real_value_hyperslab</I>\r\n<LI><I>are copied into a temporary buffer one by one and send to</I> - should be <I>sent to</I>.\r\n</UL>\r\n", "review_id": 223}], "publication_id": 88},
{"reviews": [{"date": "11-17-2007", "author": {"author_id": 692, "author_email": "heibel@cs.tum.edu", "author_lastname": "Heibel", "author_firstname": "Hauke"}, "content": "<p><strong>Summary:</strong><br />The authors are providing very well documented code and classes to compute a generalized euclidean distance transform.<br /> <br /> <strong>Open Science:</strong><br />The given publication offers an efficient way to compute euclidean distance transforms in 2D as well as 3D being integrated as an ImageToImageFilter into the ITK framework. For the computation of non-squared distances as well as signed distance maps, the authors utilize existing ITK algorithms on top of their own so they are following the paradigm of reusing as much existing code as possible.<br /><br /> <strong>Reproducibility:</strong><br />I did not ran the author&#39;s tests but tested the algorithm (extensively) in my own framework. The integration was done within minutes due to well written examples which are present within the publication.<br /><br /> <strong>Open Source Contributions:</strong><br />The algorithm implements the distance transform based on &quot;Distance Transforms of Sampled Functions.&quot; by Pedro F. Felzenszwalb and Daniel P. Huttenlocher which is new in the ITK framework.<br /><br /> <strong>Code Quality:</strong><br />All code is very well documented as well as very well structured and designed. A few abbreviations are used but they are already marked as to be replaced by the according long versions.</p><p> <strong>Applicability to other problems:</strong><br />Euclidean distance transforms are used in many applications/algorithms (registration, skeletonizing, etc.) and thus they are an important part within the ITK framework.</p><p>The work of the authors is probably of special interest to those who are computing distance transforms on &quot;large&quot; volumes, since it does not only have reasonable performance (~31s on 512x512x488, UseSpacing = true) but also a low memory print as opposed to the parallel maurer version introduced recently.</p><p><strong>Suggestions for future work:</strong> <br />Force the &#39;pow&#39; calls in the itkLowerEnvelopeOfParabolas.txx to float/double precision to prevent compile errors.</p><p>E.g. change </p><p>::minimalSpacing = static_cast&lt;SpacingType&gt;(pow(10, -MinimalSpacingPrecision));&nbsp;</p><p>to</p><p>::minimalSpacing = static_cast&lt;SpacingType&gt;(pow(10.0, -1.0*MinimalSpacingPrecision));</p><p><strong>Requests for additional information from authors:</strong><br />I&#39;ve stumbled over a small problem when I was reading binary unsigned short images from HD and wanted to perform a distance transform on them. I was wondering why the assert</p><p>assert(std::numeric_limits::is_signed);</p><p>was failing (itkLowerEnvelopeOfParabolas.txx l. 321). My input image was as said before unsigned short and my output image was float. After looking at the publication into section 3.1 at the description of the template parameters I found that you state that normally the TApexHeightType &quot;is the type of voxels in the distance image&quot;, i.e. TDistanceImage::PixelType.</p><p>This is now confusing me, since within the itk::GeneralizedDistanceTransformImageFilter the parameter is typedef&#39;ed to TFunctionImage::PixelType.</p><p>What is the correct version? I personally just did a quick-hack-test and interchanged TFunctionImage with TDistanceImage within the LEOP typedef but since I am not sure about the side effects I am not really happy with it, even though now I am getting correct distance transforms when enabling pixel spacing. </p><p> <strong>Additional Comments:</strong><br /> Great work and I am still giving full credit even in presence of the small issue mentioned above since the rest of the publication is so well done.&nbsp;</p>", "review_id": 608}, {"date": "07-06-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<b>Summary:</b>\r\nThe authors are providing code and detailed paper for a new distance transform for ITK, and examples of applications\r\n \r\n<b>Reproducibility:</b>\r\nThe articl lack of a test infrastructure. CMake let the developer define very easily some test (see modified code)\r\n\r\n<b>Open Source Contributions:</b>\r\nAll the sources are there, and the test program are documented. Configuring and building the code was done in a few minutes\r\n[Do the authorâs provide their source code? Is it in a form that is usable? Do they describe clearly how to use of the code? How long did it take you to use that code?]\r\n\r\n<b>Code Quality:</b>\r\nThe code is very clean\r\n\r\n<b>Applicability to other problems:</b>\r\ndistance transform is very important in image analysis, so this code will be useful in many cases\r\n\r\n<b>Suggestions for future work:</b>\r\n<ul>\r\n<li>use cmake\\\\\\'s tests\r\n<li>avoid using too much template parameters (they are difficult to wrap), and static attributes (they are not supported by the wrappers)\r\n<li>use concept checking rather than assert when possible, so we get the error at compile time, and we get it even if compiled in release mode\r\n</ul>\r\n\r\n<b>Requests for additional information from authors:</b>\r\nOne thing I\\\\\\'m not sure, is the usage of maxApexHeight. It has the type of the distance map pixel, but is used with the function pixel type in your examples. Does it mean that we must use the same type for distance map and function ?\r\n\r\n<b>Additional Comments:</b>\r\nI have modified your contribution to:\r\n<ul>\r\n<li> run tests with cmake\r\n<li> drop some template parameter - the parameter can now be chosen at run time\r\n<li> add progress report\r\n<li> set a GetMaximumApexHeight() static method, so it can be used with wrappers\r\n<li> wrap the classes and run a python test\r\n<li> fix a warning when function and distance type are different\r\n</ul>\r\nI will send you a tarball of the modified code. It can also be downloaded at http://voxel.jouy.inra.fr/darcsweb/darcsweb.cgi?r=generalizedDistanceTransform\r\n\r\nvery nice article\r\n", "review_id": 241}], "publication_id": 90},
{"reviews": [], "publication_id": 91},
{"reviews": [], "publication_id": 92},
{"reviews": [], "publication_id": 93},
{"reviews": [], "publication_id": 94},
{"reviews": [{"date": "09-05-2006", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThe authors provide an \\\"update\\\" to their current efforts in developing the BioImage Suite. The BioImage Suite fully utilizes several readily available software packages to provide a \\\"user-friendly user interface\\\" for medical image analysis. The paper describes the various algorithms in the package as well as some of the biomedical applications have been developed with the suite. The discussion includes a description of licensing and availability.\r\n\r\n<b>Hypothesis:</b>\r\nN/A\r\n\r\n<b>Evidence:</b>\r\nAs the paper title suggests, this is suppose to be an \\\"update\\\" to the previous paper. The evidence should be in the \\\"updating\\\" of the textual description of the package. While I think that the suite is both interesting and potentially useful, I found the paper to be lacking a bit. I found much the the text to be the same (almost word for word) with the previous submissions which the authors are updating.\r\n\r\n<b>Open Science:</b>\r\nThe package will be open-source (and available under the GPL) soon. The package can be downloaded now following registration. The authors note that there is one library which is closed. The issue becomes whether this hinder the open-science movement to build upon their success. As the authors point out, the single library is a small component and their hands are tied due to other licensing. However, even with the restrictions (by third-parties), the authors still have the right to publish the methods included within the code. (See next section)\r\n\r\n<b>Reproducibility:</b>\r\nSince the package will be largely open source, reproducibility should be straightforward (although that is only a best guess as I have not reviewed the source). With regards to the single closed library, the authors will not be able to provide source code, but they should be publishing (in great detail) the methods within the library as that is not restricted. As such, anyone who has a valid licence of numerical recipes (which many do) can recreate the functionality. In the same manner, anyone with the appropriate Vector Vision Link licence should be able to write the appropriate connection code.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors take full advantage of open source software from the programming languages used (tcl/tk) to the graphics drivers (mesa), when needed. The exciting aspect of this work is the combination of all of these tools into a useful package. As already noted, there are some minor restrictions with the Vector Vision Link software and the Numerical Recipes software.\r\n\r\n<b>Open Source Contributions:</b>\r\nI do not have the source code. It was not included with submission. The website has a mechanism to get the software.\r\n\r\n<b>Code Quality:</b>\r\nDitto\r\n\r\n<b>Applicability to other problems:</b>\r\nThis suite has great application to many different clinical problems. I look forward to exploring its potential.\r\n\r\n<b>Suggestions for future work:</b>\r\nIf not available, I suggest that the authors post or publish the methods within the closed library so others can properly reproduce the work.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\n\r\n", "review_id": 367}, {"date": "08-31-2006", "author": {"author_id": 8, "author_email": "gavinb@cs.mu.oz.au", "author_lastname": "Baker", "author_firstname": "Gavin"}, "content": " <b>Summary:</b>\r\n\r\n<!-- Short description of the paper. In two or three phrases describe the\r\nproblem that was addressed by the authors and the approach they took to\r\nsolve it. -->\r\n\r\nThis paper describes <b>BioImage Suite</b>, an software package for medical\r\nimage analysis. It is has been used in a wide variety of applications,\r\nincluding fMRI, DTI, and segmentation. The aim is to provide easy-to-use\r\ntools, with a strong clinical application focus.\r\n\r\nThe BioImage Suite is in a similar solution space to Slicer, Brainsuite and\r\nAnalyse. It comprises a GUI and a series of command-line tools for batch\r\nprocessing, and has been developed internally at Yale over the past 10\r\nyears, being used on a variety of projects.\r\n\r\nThis paper is an updated version of a\r\n<a href=\\\\\\\"http://hdl.handle.net/1926/37\\\\\\\">previous submission which described the\r\nBioImage Suite</a>, and the authors have fulfilled their promise to publish\r\nthe source of the package. The content of the paper itself appears to be\r\nvirtually the same as to last years\\\\\\' submission, with some changes to reflect the\r\nbeta release of the source code.\r\n\r\n<b>Hypothesis:</b>\r\n\r\n<!-- If Applicable: Describe the assumptions that the authors have made and\r\nthey hypothesis of their work, note that not all papers will fit the model\r\nof hypothesis driven work, for example, the description of an image\r\ndatabase, or the description of a toolkit will not be driven by an\r\nhypothesis, in which case, please simply write : Non Applicable in this\r\nfield or delete the subtitle. -->\r\n\r\nThat the BioImage Suite can support clinical image analysis applications,\r\nand that it is user-friendly and well-documented.\r\n\r\n<b>Evidence:</b>\r\n\r\n<!-- Describe the evidence that the authors provide in order to support\r\ntheir claims in the paper. This is a key component on Open Science, opinions\r\nthat are not supported by evidence should be labeled as speculations or\r\nauthors opinion while. The same rule applies to the text of the reviews:\r\nclaims should be supported by evidence -->\r\n\r\nThe project website includes quite a comprehensive set of\r\n<a href=\\\\\\\"http://www.bioimagesuite.org/public/Intro.html\\\\\\\">online\r\ndocumentation</a>, which describes how to use the various components of the\r\nsystem in some detail, including screenshots and tutorial-style information.\r\nThe system appears to be reasonably user-friendly, based on studying the\r\navailable screenshots.\r\n\r\nWhile the system has obviously seen considerable use and wide application\r\nover the years, the paper did not discuss clinical applications or present a\r\ncase-study.\r\n\r\n<b>Open Science:</b>\r\n\r\n<!-- Describe how much the paper and its addendums adhere to the concept of\r\nOpen Science. Do the authors provide the source code of the programs used in\r\ntheir experiments? Do the authors provide the input images that they used?\r\nOr are those images publicly available? Do the authors provide the output\r\nimages that they show in the paper? Do the authors provide enough details\r\nfor you to be able to replicate their work? -->\r\n\r\nThe authors provide access to the full source code (and nearly all the\r\ndependent libraries). The paper shows examples and screenshots of the\r\napplication running. The binary distribution also includes some example\r\nimage data.\r\n\r\n<b>Reproducibility:</b>\r\n\r\n<!-- Did you reproduce the authors work? Did you download their code? Did\r\nyou compile it? Did you run it? Did you managed to get the same results\r\nthat they reported? Were there information missing from the paper, that was\r\nnecessary for you to reproduce the work? Suggest improvements that will make\r\neasier for future readers to reproduce this work. -->\r\n\r\nI followed the instrucions on the project website to obtain the software.\r\nThis involved a quick registration process, and was then able to download\r\nthe software. I obtained the latest source\r\n(<tt>bioimagesuite_1.995_src_507.zip</tt> dated 24th August 2006) as well as\r\nthe pre-built binaries for Linux.\r\n\r\nI was unable to completely build the software from source on my machine\r\n(Debian GNU/Linux Etch, i586). While I do have LAPACK, BLAS, ATLAS and all\r\nsuch packages installed (including clapack.h), I do not have\r\nCLAPACKConfig.cmake and could find no reference via Google. I managed to\r\nhack past this problem, only to encounter other difficulties which prevented\r\nfurther progress.\r\n\r\nI untarred them into a private directory, adjusted the path settings\r\naccording to the documentation. (The install documentation says that\r\nuntarring will result in three directories, but it omits mention of the\r\n<tt>bioimage_extra</tt> directory.) The system assumes that the software is\r\ninstalled under <tt>/usr/local</tt>, which was not an option in this\r\ninstance. While the scripts to run BioImage have a BASE directory, it is\r\nnot used by the scripts, and changing the paths is most cumbersome.\r\n\r\nSome issues: the <tt>bioimagesuite/setpaths.sh</tt> script refers to FSL,\r\nwhich is not included. The <tt>setextra.sh</tt> script refers to minc20,\r\nwhich is under the extra directory but the script assumes it is under the\r\nbase directory. The configuration tries to set TCL_LIB_PATH, but the\r\ncorrect environment variable (according to the documentation I consulted)\r\nspecifies TCLLIBPATH, ie. without the underscores). Also, since this\r\npackage is distributing its own copy of Tcl, the TCL_LIBRARY environment\r\nvariable needs to be set to the base path of <tt>init.tcl</tt>.\r\n\r\nWith my custom script (see below) I was able to successfully run the suite.\r\nI loaded some test data (<tt>mni_305.hdr</tt>), and carried out some common\r\ntasks: preprocessing, bias-field correction, smoothing, histogram\r\nsegmentation, morphology and others. I was able to perform these common\r\noperations without needing to refer to the documentation, supporting the\r\nease of use claim.\r\n\r\n<b>Use of Open Source Software:</b>\r\n\r\n<!-- Did the authors use Open Source software in their work? Do they\r\ndescribe their experience with it, advantages and disadvantages? Do they\r\nprovide advice for future users of those Open Source packages? -->\r\n\r\nThe BioImage Suite makes extensive use of existing FLOSS projects, including\r\nITK, VTK, LAPACK, Mesa 3D, Tcl/Tk, IWidget, and Metakit. It leverages these\r\nlibraries to provide a high-level interface. (It also appears to include\r\nthe HDF5 package, which doesn\\\\\\'t seem to be mentioned in the documentation.)\r\nThe paper does not discuss in any detail how these libraries were used.\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\n<!-- Do the authors provide their source code? Is it in a form that is\r\nusable? Do they describe clearly how to use of the code? How long did it\r\ntake you to use that code? -->\r\n\r\nThe complete source code is made available on the BioImage website, which is\r\navailable after a brief registration step. The source comprises some\r\n300,000 lines of source files, representing a very significant contribution\r\nto the community.\r\n\r\nThis website also features user forums, encompassing support, discussion on\r\nfMRI, DTI, integrating with other software, news and discussion.\r\nseveral relevant papers and resources are provided, including tutorials\r\nand user manual.\r\n\r\nAs the project is making the transition from an internal project to its\r\nfirst public release, various environmental issues have become apparent, as\r\nnoted above. This is due to the inevitable dependencies and assumptions\r\nthat one is able to make in a controlled or homogeneous environment, such as\r\nthe presence of dependent libraries or tools, and the locations and paths of\r\ncomponents, and so on. As the project progresses in its new public phase,\r\nthese issues will surely be ironed out and the project should become more\r\neasily deployable on external systems.\r\n\r\n<b>Code Quality:</b>\r\n\r\n<!-- If the authors provided their source code: Was the code easy to read?\r\nDid they use a modern coding style? Did they rely on non-portable mechanism?\r\nWas it suitable for multiple-platforms? -->\r\n\r\nThe code is broken up into sensible modules (such as GUI, Imaging, and so\r\non). The layout of the source code is generally readable and consistent,\r\nbut often uses extremely long lines (>80 characters). Most classes have\r\nsmall, cohesive methods. The class interfaces seem to be generally\r\nwell-defined. There is still a certain amount of debug code, such as\r\n<tt>cout</tt> and <tt>printf</tt> calls sprinkled about (while others use\r\nthe VTK debug macros). There are quite a few instances of literal constants\r\nand magic numbers, such as IDs for menu items which must be the same between\r\nmodules, or processing modes, colour constants, lookup tables, etc. The\r\ncoding conventions are fairly similar to the ITK conventions (making the\r\ntransition of contributions easier to manage). (A few dozen source files\r\nwere chosen semi-randomly across the various directories in the\r\nsource code for inspection.)\r\n\r\nThere is very little documentation within the code. Using a tool such as\r\nDoxygen and providing inline documentation of classes and methods would\r\nimprove the maintainability of the code, and enable external developers to\r\nget up to speed and contribute and enhance the code base.\r\n\r\nThe code is generally designed for portability, as evidenced by the fact\r\nthat it runs on Windows, Linux, Solaris and Mac OS X. This is obviously in\r\nno small part thanks to the portability of the underlying libraries, however\r\nthe authors have gone to great lengths to not only support the major\r\nplatforms in their own code, but to provide pre-built binaries for each\r\nalso.\r\n\r\n<b>Applicability to other problems:</b>\r\n\r\n<!-- Do you find that the authors methods can be applied to other image\r\nanalysis problems? Suggest other disciplines or even other specific projects\r\nthat could take advantage of this work -->\r\n\r\nThe suite includes implementations of several useful algorithms, which would\r\nbe very useful in their own right. Some of these may be appropriate to make\r\nas contributions to the ITK or VTK core. While the suite contains tools for\r\nspecific applications such as angiography, it provides general segmentation\r\nand registration tools, which may be equally used in other areas such as\r\nthoracic imaging or brain sementation.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<!-- Suggest to authors future directions for improving their methods, or\r\nother domains from which they could learn technique that could help them\r\nadvance in their research. -->\r\n\r\n<i>Building</i>\r\n\r\nMaking the codebase easier to build on different systems is the biggest\r\nhurdle to adoption by external developers, and to a lesser extent users.\r\nThe paths configuration could be streamlined, to make it easier to install\r\nin a custom root (for example, <tt>/opt/bioimage</tt>).\r\n\r\n<i>Distribution</i>\r\n\r\nThe binary distributions are broken up into four differnent tarballs for\r\ndownload. Since they are all required, and are built to be run together, it\r\nwould be helpful to have a single tarball to download all the required\r\nbinaries.\r\n\r\n<i>Documentation</i>\r\n\r\nThe system currently has minimal developer documentation. Information such\r\nas the build and runtime dependencies, minimum versions of packages required\r\n(eg. CLAPACK/LAPACK), CMake, and so on would be very useful. Since the\r\nsystem provides much code that could be re-used elsewhere, providing an API\r\nreference (much like ITK does with the doxygen-generated docs) would be\r\nextremely valuable.\r\n\r\n<i>Startup Scripts</i>\r\n\r\nThe scripts included assume the system is installed in <tt>/usr/local</tt>,\r\nand are difficult and tedious to update.\r\n\r\nDue to the difficulty of changing all the paths in all the startup scripts,\r\nI wrote a single script that sets all the paths at once, which are all\r\nrelative to a single base directory. This avoids the problems of requiring\r\nBioImage Suite be installed in <tt>/usr/local</tt>, and makes it easier to\r\nconfigure and customize, since it is all relative to one single base\r\ndirectory variable. The script is below:\r\n\r\n<pre>\r\n#!/bin/sh\r\n\r\nBASE=`pwd`\r\nITK_DIR=$BASE/itk241_yale\r\nVTK_DIR=$BASE/vtk44_yale\r\nEXTRA_DIR=$BASE/bioimagesuite_extra\r\nBIS_DIR=$BASE/bioimagesuite\r\n\r\nMAIN_DIR=${BIS_DIR}/main\r\nBIN_DIR=${BIS_DIR}/bin\r\nAPPS_DIR=${BIS_DIR}/apps\r\nMJACK_DIR=${BIS_DIR}/mjack\r\nVTKNR_DIR=${BIS_DIR}/vtknr\r\nDATATREE_DIR=${BIS_DIR}/datatree\r\n\r\nPATH=$BIS_DIR/bin:$EXTRA_DIR/bin:$VTK_DIR/bin:$BIN_DIR:$MAIN_DIR:$APPS_DIR:$MJACK_DIR:$VTKNR_DIR:$DATATREE_DIR:$PATH\r\nLD_LIBRARY_PATH=$ITK_DIR/lib/InsightToolkit:$VTK_DIR/lib:$VTK_DIR/lib/vtk:$EXTRA_DIR/lib:$LD_LIBRARY_PATH\r\n\r\nexport PATH\r\nexport LD_LIBRARY_PATH\r\n\r\nTCL_LIBRARY=$VTK_DIR/lib/tcl8.4\r\nTK_LIBRARY=$VTK_DIR/lib/tk8.4\r\nTCLLIBPATH=$VTK_DIR/lib/tcllib1.8\r\n\r\nexport TCL_LIBRARY\r\nexport TK_LIBRARY\r\nexport TCLLIBPATH\r\n\r\npxmenu.tcl\r\n</pre>\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<!-- Did you find that information was missing from the paper? Maybe\r\nparameters for running the tests? Maybe some images were missing? Would you\r\nlike to get more details on how the diagrams, or plots were generated? -->\r\n\r\nIt would be very interesting to have not just an overview of the system, but\r\na discussion of the design of the package. How do the components fit\r\ntogether? How did they design the architecture, with its blend of C++ and\r\nTcl code? How can some of the core algorithms be reused in other projects?\r\n\r\nCross-platform development is very important, and the developers seem to\r\nhave an interesting approach involving VMWare Server. A discussion of their\r\napproach, for building, testing, deployment, etc would also be of interest\r\nto many developers.\r\n\r\nGiven the fact that the BioImage Suite has apparently been in widespread use\r\nwithin Yale for many years, it would have been most useful to present some\r\ncase studies to show how it is being used, what benefits it confers to the\r\nusers, and how it is employed in clinical diagnosis and interventions. The\r\ncore of the paper is a general overview of the features of the system, and\r\ndoesn\\\\\\'t provide much detail on how the code was implemented.\r\n\r\nOf particular interest to many members of the community would be a\r\ndiscussion of how the system interfaces to the Brainlab IGS system (a\r\nsuggestion from a reviewer in last year\\\\\\'s submission). Of course, the\r\npublication of this module\\\\\\'s source would be very useful.\r\n\r\n<b>Additional Comments:</b>\r\n\r\n<!-- This is a free-form field -->\r\n\r\nThe suite is built upon a large number of other libraries, most of which\r\nappear to be published under a BSD-style license. The authors are\r\npublishing this suite under the GPL, which has implications on the other\r\nlibraries whose source is distributed alongside. It is not a foregone\r\nconclusion that all these licenses are GPL-compatible, and some legal advice\r\nmay be appropriate to ensure no terms are being bent. It is somewhat of a\r\nconcern that the authors state in the paper that a core library will remain\r\nproprietary, as this is obviously not compatible with the GPL (depending on\r\nthe linkage between the module and the rest of the system).\r\n\r\nThe Numerical Recipes code is obviously proprietary and will remain so,\r\nfree/open alternatives to a significant number of these algorithms are available\r\nelsewhere (eg. GSL, etc) which may overcome this particular limitation,\r\nso it should be possible to replace this with code and free the affected module.\r\n\r\nSince the authors use VMWare extensively for their multi-platform\r\ndevelopment, perhaps they would consider providing a\r\n<a href=\\\\\\\"http://www.vmware.com/vmtn/appliances/\\\\\\\">\r\nVirtual Server Appliance</a> with BioImage Suite ready to run. This would\r\nenable people to try the software after a single download, and would avoid\r\npotential compatability issues with DLLs, configuring paths, and so on.\r\n\r\n<b>Conclusion</b>\r\n\r\nIn summary, the project includes full source code, documentation and sample\r\ndata. The suite clearly addresses the need to have productive tools and\r\ninterfaces for working with medical image data. The paper provides a good\r\noverview of the suite, but leaves the reader wanting to know more detail\r\nabout how it was designed and how it is being used in practice. This suite\r\nis of general and broad interest, for researchers to analyse and explore\r\nimage data. This package should prove very popular and useful for a wide\r\nvariety of users, and anyone interested should download it to evaluate it\r\nfor their application.\r\n", "review_id": 349}, {"date": "09-06-2006", "author": {"author_id": 63, "author_email": "pkaz@cs.jhu.edu", "author_lastname": "Kazanzides", "author_firstname": "Peter"}, "content": "<b>Summary:</b>\r\nThis paper describes the BioImage Suite, which is a collection of image analysis tools, including GUI-based and command-line programs, developed at Yale University.\r\n \r\n<b>Hypothesis:</b>\r\nN/A\r\n\r\n<b>Evidence:</b>\r\nN/A\r\n\r\n<b>Open Science:</b>\r\nThe authors are releasing the bulk of the source code under the GPL license. One library cannot be released as open source due to licensing issues. A pre-release version (binary and source) is available from the web site, though it currently requires a user name and password (easy to obtain after registering).\r\n\r\n<b>Reproducibility:</b>\r\nI downloaded the Windows binary and installed it on Windows XP. I used the suggested root directory (C:\\\\Yale). The installation consisted of unzipping 4 ZIP files (not 3 as mentioned in the documentation). The program is starting by running a batch file. This was very easy to do and worked. I also downloaded the source code, but did not try to compile it myself.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe paper mentions that BioImage Suite uses VTK, ITK, and TCL/TK (with extensions such as IWidgets). In addition, by reviewing the downloaded files, it is clear that it also uses other open source packages such as Xerces, MINC, and CLAPACK.\r\n\r\nThe project uses the CMake and Subversion open source tools.\r\n\r\n<b>Open Source Contributions:</b>\r\nThis is a significant amount of software that is being made available to the research community. The authors are working to replace some of the closed source libraries. The authors provide binary versions for many different operating systems.\r\n\r\n<b>Code Quality:</b>\r\nI downloaded, but did not review, the source code. The design of the web site is very good and appears to have ample documentation.\r\n\r\n<b>Applicability to other problems:</b>\r\nThere are a lot of image analysis tools, which should be applicable to a wide range of medical applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors state that they make extensive use of VMWare for testing the software on different operating systems, but do not describe the testing framework. For a software package of this size, I would strongly urge the developers to create an automated testing framework (e.g., using Dart), if they have not already done so.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe authors mention similar open source packages, such as Slicer, Brainsuite, and SPM, but do not offer a comparison to BioImage Suite. Given that they recently received an NIH grant for âcontinued development and maintenanceâ, I assume that they must have already described (at least in the proposal) the new features that their package could offer.\r\n\r\n<b>Additional Comments:</b>\r\nI find the GUI to be less âsexyâ than the 3D Slicer package (though I am more familiar with 3D Slicer). The availability of command line tools is a nice feature in BioImage Suite and the generation of Makefiles to manage the batch processing is a good idea.\r\n\r\nThe VVLink capability is interesting (I also read the ISBI06 paper available on the website). \r\n\r\n\r\n", "review_id": 378}, {"date": "08-23-2006", "author": {"author_id": 447, "author_email": "samset@bwh.harvard.edu", "author_lastname": "Samset", "author_firstname": "Eigil"}, "content": "<b>Summary:</b>\r\nA medical image processing suite is described. The system packages existing algorithm in an easy-to-use application. The software is in wide use at Yale and local collaborating laboratories.\r\n \r\n<b>Hypothesis:</b>\r\nNon applicable\r\n\r\n<b>Evidence:</b>\r\nThe authors give a clear description of the software, and examplifies the capability of the software in clinical applications with several screenshots.\r\n\r\n<b>Open Science:</b>\r\nThe BioImage Suite is publically available for download. Usename and password is given on request. The source-code was not readily available (it would requre a separate request). The authors give a good description of core algorithms that are being used in the software and give referenes to these.\r\n\r\n<b>Reproducibility:</b>\r\nDownloading and running the precompiled version of the software went smoothly. When not installing to the default location, the file start_bioimagesuite had to be modified (in addition to files mentioned in the webpage)\r\nNo attempt was made to get source code or compile it.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors use existing opensource software such as VTK, ITK and CLapack. \r\n\r\n<b>Open Source Contributions:</b>\r\nThe code was not easily available, and was not reviewed. The authors claim that the source code will be made available under GPL (except for a part of the software). The authors do not discuss the choice of licence.\r\n\r\n<b>Code Quality:</b>\r\nNon applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nThe software system that is presented can have a wide use in image processing problems. It seems that it can provide a good platform to package image processing algorithms to end users. The authors empasize that the system is easy to learn and use, which is often not the case for academic software. There is no discussion of how BioImage Suite compares to other systems like Slicer, Brainsuite, SPM or Analyze.\r\n\r\n<b>Suggestions for future work:</b>\r\nFor this reviewer the software related to VectorVision link would have the highest interest. This cannot currently be opensources. The suggested work to enable this would therefor be very usefull for the Image-Guided-Therapy community.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nIt would be interesting to know more about the data model used in the system.\r\n\r\n]\r\n\r\n", "review_id": 311}], "publication_id": 95},
{"reviews": [{"date": "09-05-2006", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThis paper describes the method of data visualization within the BioImage software. It includes a description of the software tools used to built the Datatree interface as well as applications that one might want to use the datatree tool.\r\n \r\n<b>Hypothesis:</b>\r\nN/A\r\n\r\n<b>Evidence:</b>\r\nThis submission doesn\\'t include addition information such as the software, source or applications for each of the examples. Since this is a description of the tool, there is no description of an evaluation/validation of the tool in the context of the applications.\r\n\r\n<b>Open Science:</b>\r\nOnce available, this will be open source software available for evaluation by independent investigators; however, it is now only release with registration as beta software. It will also be important to include the code for the specific examples described in the paper as these examples are the applications where the datatree tool is being used.\r\n\r\n<b>Reproducibility:</b>\r\nN/A\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis is built upon open source software (with a couple of small exceptions described in the other paper on the bioimage suite).\r\n\r\n<b>Open Source Contributions:</b>\r\nThis will be a useful open source software package when fully available.\r\n\r\n<b>Code Quality:</b>\r\nCannot evaluate\r\n\r\n<b>Applicability to other problems:</b>\r\nThe authors already describe several applications of this tool. There are many more applications in the field.\r\n\r\n<b>Suggestions for future work:</b>\r\nNothing in particular.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nUnfortunately, this is a case where the code really needs to be more available. I believe that the authors will eventually get there, but cannot evaluate right now. I hope that the example applications will also be available with the package in order to evaluate their utility as well as the foundation for new applications.\r\n\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 371}], "publication_id": 96},
{"reviews": [{"date": "09-04-2006", "author": {"author_id": 456, "author_email": "cheng@isis.georgetown.edu", "author_lastname": "Cheng", "author_firstname": "Patrick"}, "content": "<b>Summary:</b>\r\nThis paper describes a framework for developing various IGT applications.\r\n \r\n<b>Hypothesis:</b>\r\nNon Applicable\r\n\r\n<b>Evidence:</b>\r\nThe author claimed that, ââ¦with the purpose of providing a safe, dynamic and extensible software framework for image-guided therapy in a novel operation facility called AMIGOâ, however he didnât provide further evidence on how this framework achieved these design goals. \r\n\r\n<b>Open Science:</b>\r\nThe seamless integration with Slicer gives this toolkit a good support for developing variety of applications for surgical guidance and therapy. Its intention to go open source will surely benefit the research community\r\n\r\n<b>Reproducibility:</b>\r\nThere is no source code published with this paper at this moment.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis work has taken full advantage of existing open source software toolkits, such as Slicer, OpenTracker, GIHI, and ACE etc. \r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code will be release under open source license. \r\nWill the example applications also be available for the public?\r\n\r\n<b>Code Quality:</b>\r\nNot applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nSome interesting clinical applications have been shown in this paper developed using the framework. It shows that this framework is quite flexible and has a wide range of clinical applications.\r\n\r\n<b>Suggestions for future work:</b>\r\nHave you considered the synchronization issue between hardware devices and application? Difference hardware devices in the surgical guidance system have different response frequency. There is also latency issue when communicating through the network. When integrating the information from difference sources together in the surgical scene, you need to be very careful about the accuracy of the information you are presenting to the surgeon. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nNone.\r\n\r\n<b>Additional Comments:</b>\r\nNone.\r\n\r\n\r\n", "review_id": 365}, {"date": "08-10-2006", "author": {"author_id": 282, "author_email": "perrine.paul@univ-rennes1.fr", "author_lastname": "Paul", "author_firstname": "Perrine"}, "content": "<b>Summary:</b>\r\nAuthors presents a software framework whose purpose is to develop specific image-guided applications using multiple intra-operative imaging. The framework is based upon an extended open-source interfacing of the open-source OPenTracker library and an imager hardware interface GIHI, using 4 separate new modules. The framework was implemented to support multiple system interactions and visualization tasks, with a dynamic execution model. \r\n \r\n<b>Hypothesis:</b>\r\nThere is a need in image-guided therapy for software framework satisfying the following requirements: using multiple imaging instruments with proper functionality, portability, abstraction and speed. The fact of tracking multiple tools or getting multiple images at the same time in real-time is of course of great interest for image-guided surgery, in particular for augmented reality or augmented virtuality. \r\n\r\n<b>Evidence:</b>\r\nThe demonstration of the interest was based on the presentation of 5 clinical applications. However, the code is not yet available, it will be on the 19th of October. I was then not able to reproduce the presented results. The need of a framework allowing aplication as separate silos was justified by the regulatory requirements.\r\n\r\n<b>Open Science:</b>\r\nThe presented framework is is the spirit of open science, for 2 reasons: 1) it is based upon existing open-source libraries, and extended or interfaced them 2) The source code of the programs used in their experiments was not provided yet but it will be open source. It consists on an add-on to an existing open source library Open tracker and to a global framework library, the SIGN, interfacing other opens ource librairies.\r\n\r\n<b>Reproducibility:</b>\r\nNot available since no code was not provided\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe framework The SIGN is based upon (instead of duplicating) existing open-source efforts, as OpenTracker, VTK, KWWidgets, ITK, SPLOT , GIHI, Xerces and Ace. \r\n\r\n<b>Open Source Contributions:</b>\r\nNo code available. I was not able to compile the GIHI part, and the openTracker v1.3 is not available directly on the indicated link.\r\n\r\n<b>Code Quality:</b>\r\nThe developments was made in C, said to respect portability rules. But the code is not available. Nothing said about dart test or others.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe authors have shown the applicability to a large range of problem, by showin 5 different applications. The replay posibilities could be really interesting for pedagogical purposes, or to make some e-books for surgeon. \r\n\r\n<b>Suggestions for future work:</b>\r\n It will be of interest in the future first release to have the demonstrations application code, and an image simulator, or at least the replay. Moreover you could include to your software an aplication validation strategy, which could lead to both performance evaluation and validation of each developped application using the software. Most of time when developping an application using intraoperative imaging, you have not a wide access to the intraoperative imaging. Including simulators of different kind (for tools, images, etc...) is really important for rapid prototyping. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe relation with the AMIGO operating room was not clear, since it was no more mentionned after its presentation. Figures are of interest for demonstrations of the workflow interest, I would like to have them bigger and with a detailed description. What is the black window in figure 4? It would be of interest to underline the differences with other available Image-guided surgery toolkits, as <A HREF=\\\\\\\"http://www.igstk.org/index.htm\\\\\\\">IGSTK</A>. What is reference (11)? Reference (9) and (10) are not cited in the text. \r\nCould you add a reference for MRML?\r\n\r\n<b>Additional Comments:</b>\r\nThe note was given following the reviewer\\\\\\'s guideline: detail of note: 1/2 Code not available but built upon open-source libraries+1/1 adress a real software-based need within the community+ 0.5/1 No material provided but concepts are well described + 1/1 all research projects in image-guided surgery would benefit of this work . Total: 3.5/5=> 4\r\n\r\n", "review_id": 296}, {"date": "08-31-2006", "author": {"author_id": 63, "author_email": "pkaz@cs.jhu.edu", "author_lastname": "Kazanzides", "author_firstname": "Peter"}, "content": "<b>Summary:</b>\r\nThis paper describes the Slicer Image Guided Navigator (SIGN) software being developed at BWH. It adds support for imaging and tracking systems to 3D Slicer (it seems), using the GIHI and OpenTracker open source libraries, respectively.\r\n \r\n<b>Hypothesis:</b>\r\nN/A\r\n\r\n<b>Evidence:</b>\r\nN/A\r\n\r\n<b>Open Science:</b>\r\nThe paper promises to adhere to the principles of open science, although the primary source code will not be available until October 19.\r\n\r\n<b>Reproducibility:</b>\r\nThe SIGN source code is not available for download. I downloaded the GIHI source code (SVN repository) but did not compile it. I tried to find OpenTracker V1.3 but it is not available from the specified web site, which lists V1.1.1 as the latest version. There is a note to contact the project administrator to get a developers version from SVN. I did not do this. Some of the documentation refers to OpenTracker V1.2 and later, so clearly the repository must contain more recent versions.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe SIGN projects uses a lot of open source software, including VTK, KWWIDGETS, ITK, OpenTracker, GIHI, XERCES, and ACE. It also uses the SPLOT package (extensions to OpenTracker), which I assume will be available as open source software. The relationship to 3D Slicer is not entirely clear. The paper states that the SIGN is designed to be âhighly interoperableâ with 3D Slicer. Can the SIGN run without Slicer? If so, it seems it would duplicate some of the functionality of Slicer. If not, Slicer should be added to the list of open source software.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe paper states that The SIGN will be released as open source on Oct 19. It also says that information will be given at www.ncigt.org. I only found a brief reference to the SIGN under the â3D Slicer Engineeringâ project.\r\n\r\n<b>Code Quality:</b>\r\nI looked at the GIHI source code, which is written in C for portability to older platforms. It is supported on Linux and Solaris at this time. The code quality seems fine, though one cannot call it \\\\\\\"modern\\\\\\\". Note, however, that The SIGN source code, which is the primary subject of this paper, may not have any similarities to GIHI.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe SIGN is an application framework and is therefore applicable to a large number of problems. 3D Slicer has been successfully applied to a number of applications, and it is reasonable to expect the SIGN (which seems to add intraoperative imaging and tracking support to 3D Slicer) to also be widely applicable.\r\n\r\n<b>Suggestions for future work:</b>\r\nObviously, finish the software and make it available as open source! Also, improve the operating system support (e.g., some components, such as GIHI, are limited at this time -- just Linux and Solaris).\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThis paper presents a clear overview, but is short on technical details. Section 2.3 is especially brief and refers to (11) for comprehensive details. There actually is no reference 11 (maybe this should be 10?). I would have liked to see some explanation of the dynamic data structures. \r\n\r\nSome block diagrams, flowcharts, etc. describing the software would be a welcome addition. \r\n\r\n\r\n<b>Additional Comments:</b>\r\n\r\nFollowing are some minor typos:\r\n<ul>\r\n<li>Section 2.3 (noted above) and 2.4 refer to (11), but there is no reference with this number.</li>\r\n<li>The Medscan description says âin order to encoding all servicesâ, which should be âin order to encode all servicesâ.</li>\r\n<li>The section numbering seems to be off. I believe Sections 3.1, 4, 4.1, 4.2, 4.3 should have been 3.1, 3.2, 3.3, 3.4, 3.5.</li>\r\n<li>In Section 4.1 (Cardiac navigation), âcourse orientationâ should be âcoarse orientationâ.</li>\r\n<li>In Conclusions, âMyâ should be âByâ.</li>\r\n</ul>\r\n\r\n\r\n\r\n", "review_id": 348}, {"date": "09-05-2006", "author": {"author_id": 68, "author_email": "andinet.enqu@kitware.com", "author_lastname": "Enquobahrie", "author_firstname": "Andinet"}, "content": "<b>Summary:</b>\r\n\r\nThe paper describes an open source software framework for building a multi-modality image guided therapy application. \r\n \r\n<b>Hypothesis:</b>\r\nThe designed software framework is useful for building image guided therapy applications.\r\n\r\n<b>Evidence:</b>\r\nFive applications developed using SIGN have been presented. However, source code was not provided for these applications. \r\n\r\n<b>Open Science:</b>\r\nThe software framework design and distribution scheme follows open science principles. The software framework uses heavily other open source toolkits such as OpenTracker, GIHI, VTK, ITK, KWWidgets, Xerces and Aceto. The source code for these toolkits are readily availbale. And, the source code for SIGN is scheduled to be released by Oct.19. \r\n\r\n<b>Reproducibility:</b>\r\nN/A\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe developers of SIGN have used open source toollkits such as OpenTracker, GIHI, VTK, ITK.\r\n\r\n<b>Open Source Contributions:</b>\r\nAuthors stated that the source code will be released by Oct 19th.\r\n\r\n<b>Code Quality:</b>\r\nN/A\r\n<b>Applicability to other problems:</b>\r\nSIGN is a useful software framework is useful to develop other image guide therapy applications.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<b>Requests for additional information from authors:</b>\r\nSafe software design principles and practicses employed in the SIGN software framework have not been discussed in the paper.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 373}, {"date": "08-17-2006", "author": {"author_id": 472, "author_email": "chent@cs.queensu.ca", "author_lastname": "Chen", "author_firstname": "Thomas kuiran"}, "content": "<b>Summary:</b>\r\nThe paper demonstrated a new software framework (named âSlicer Image-Guided Navigatorâ or SIGN) for Image-Guided Therapy that aims to provide real-time intraoperative surgical navigation with dynamic visualization and interactions with multiple imaging and tracking devices, through a seamless integration of dynamic data structures (medical reality modeling language, or MRML). The software package was developed based on various open-source frameworks and will itself be open-source soon to be available to the public.\r\n \r\n<b>Hypothesis:</b>\r\nThe authors argue that newly emerging image-guided procedures and therapies have seen increasing use of multiple imaging modalities and tracking devices at the same time in the OR. I agree that new surgical navigation applications are therefore desired to seamlessly interact with different imaging and tracking systems through a virtually transparent interface (to the users) with significant portability and expendability. In addition, more and stricter regulatory requirements pose new challenges on academic software development for research tools in clinical treatments. \r\n\r\n<b>Evidence:</b>\r\nSeveral clinical-relevant applications were presented using the current development of SIGN. The software framework was itself very well established and clearly presented through detailed designs of various system components that handle different hardware and software interfacings (i.e. GIHI for the imager interfacing, OpenTracker for the tracker interfacing, and Hybrid for event and data handling). References to the open-source resources used were also adequately provided.\r\n\r\n<b>Open Science:</b>\r\nI think the proposed software framework is clearly designed with open-source development and distribution in mind. According to the paper, SIGN was developed primarily based on the open-source 3D Slicer framework and has extensively employed many other open-source frameworks (e.g., OpenTracker, GIHI, VTK, ITK, etc.) to develop its major system components (e.g., MedScan). The authors have also promised the release of SIGNâs original source codes on October 19th, 2006 to the open-source community. So it is evident to me that the proposed software framework will eventually benefit the public by contributing to the open-source community. \r\n\r\n<b>Reproducibility:</b>\r\nSince the source codes of SIGN will not be made available to general public until October 19th, 2006, I havenât been able to reproduce the authors work as described in this paper. However, I was able to download and install the OpenTracker package from the link provided by the paper. I should point out that there is one small mistake in the paper regarding the latest version of OpenTracker (the paper mentioned that the latest version is v1.3, while on OpenTrackerâs website, it states that v1.1.1 is its latest release). For GIHI, I kept getting a âconnection timeoutâ to the link suggested by the paper, so I have not been able to test it during the writing of this review. \r\n\r\n<b>Use of Open Source Software:</b>\r\nAn extensive use of the existing open-source software is evident in the development of SIGN. The framework was developed primarily based on the open-source 3D Slicer framework and has employed many other open-source frameworks (including OpenTracker, GIHI, VTK, ITK, KWWidgets, Xerces and Aceto) to develop its major system components.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors have promised the release of SIGNâs original source codes on October 19th, 2006 to the open-source community. No test is possible until then.\r\n\r\n<b>Code Quality:</b>\r\nThe authors have promised the release of SIGNâs original source codes on October 19th, 2006 to the open-source community. No examination of the code quality is possible until then.\r\n\r\n<b>Applicability to other problems:</b>\r\nMy understanding of the major strength of SIGN is in its ability to interface multiple imaging and tracking devices with seamless dynamic data integration and visualization. This framework could be extended to various existing image-guided surgical navigation systems that employ a broad range of imaging (e.g., CT, MRI, and US) and tracking (e.g., optical or magnetic) systems. In addition, the dynamic data encapsulation of SIGN (using MRML) may be applicable to many data management applications (not limited to medical applications) that wish to easily share, convert, and transfer data between different formats.\r\n\r\n<b>Suggestions for future work:</b>\r\nWas there a high-level design approach employed to outline the interrelationship between all the interfacing components in SIGN? Event handling for hybrid devices (devices of all kinds) in a generic interface is very attractive to many software engineering applications, but in general remains extremely complicated (essentially each device has its own protocol for communications). So in the future design of SIGN (and its extensions), a high-level design approach (e.g., Rational Rose or generic UML) is very helpful here to sort out all relationships between multiple system components at different interacting levels.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nPlease see the following additional comments.\r\n\r\n<b>Additional Comments:</b>\r\n1. In imaging hardware (Section 1.1), ultrasound (US) was not mentioned here as newly emerging imaging modalities. However, later on in the following sections, US was indicated apparently as one of the imagers in SIGN. \r\n\r\n2. In tracking devices (Section 1.2), the authors illustrate many types of tracking systems including their advantages and disadvantages. However, no single reference was given here. More references are necessary here.\r\n\r\n3. AMIGO (Section 1.4) was described as the context of the proposed framework (the ultimate application), however, there was no a word or two later in the paper briefing how, in a larger picture, SIGN is (or will be) adopted in AMIGO. Please provide a brief explanation of this link somewhere after SIGN is introduced.\r\n\r\n4. GIHI was written in C. Shouldn\\\\\\'t it consider using C++? Or at least a combination of C (for portability) and C++ (expandability)? Seems to me that GIHI requires many service/component extensions, either current or in the future. C is indeed portable and efficient but fairly poor at expandability, especially for a large system like SIGN that has multiple software components. \r\n\r\n5. Was there a specific design software used to design the overall structure of SIGN and its interactions with other system components (like OpenTracker and GIHI)? SIGN seems to be a very large, complicated, and distributed (multiple components acting in an asynchronous fashion) system employing a great amount of events and their handlers. It seems (at least to me) virtually impossible to design such a dynamic system efficiently and completely without the assistance of some professional design approaches (e.g, Rational Rose). \r\n\r\n6. In hybrid interfacing (Section 2.3), from a system-design point of view, why Terason is designed as a separate module that is parallel to MedScan? At a high level in the overall system, shouldn\\\\\\'t Terason be part of the GIHI library whose primary duty is to handle the interfacing with various imaging devices (which include US)? Please clarify.\r\n\r\n7. In the illustration of SIGN (Section 2.4 the last paragraph), I was a bit confused here: the tracker is presumably a monitoring device that traces the motion of the objects in real time. It is supposed to be a passive observer. So what does it mean that once connected to the data object in MRML tree, the tracker could move an object around the scene? Or maybe it was my incorrect interpretation? Please clarify a bit here.\r\n\r\n8. In the introduction of SIGN (Section 2.4), the authors claimed that âThe framework was designed to be highly interoperable with the 3D Slicer â¦â. However, the exact relationship between SIGN and 3D Slicer still remains unclear to me even after reading through the entire paper. Was SIGN designed and developed primarily based on the 3D Slicer framework? Or they simply just share the same data structure protocol (using MRML)? Please clarify the term âinteroperableâ in more details here.\r\n\r\n\r\n", "review_id": 300}, {"date": "08-14-2006", "author": {"author_id": 471, "author_email": "pettri@medisin.uio.no", "author_lastname": "Risholm", "author_firstname": "Petter"}, "content": "<b>Summary:</b>\r\nThe abundance of imaging devices, tracking devices and other electronic devices which image guided therapy relies on has resulted in many efforts to develop sofware frameworks which abstracts the inherent complexity of integrating such devices in image guided therapy software applications. Important requirements of such frameworks are portability, usability, synchronization, flexibility and speed. The authors describe a new framework which aims at supporting all of these requirements. Three main software components constitute the software framework. OpenTracker is a general data streaming components which can interface to such datasources as tracking devices, ECG devices and imaging sources. Another component handles interfacing to imaging hardware, GIHI, which can be used to extract tracking data from imaging devices where that is relevant, extract images in addition to provide a interface for controlling imaging parameters. The last component is VTK which is used for visualization purposes. XML is used to configure the framework and can be set up such that data can flow between the components in an almost seamless manner.\r\n \r\n<b>Hypothesis:</b>\r\nNot applicable.\r\n\r\n<b>Evidence:</b>\r\nA number of clinical examples are presented in the paper. However, the only example which is backed up by a reference to show its clinical relevance is the endoscopic navigation. \r\nI don\\\\\\\\\\\\\\'t really see how ITK is integrated in this framework.\r\n\r\n<b>Open Science:</b>\r\nMost of the source code is currently available such as OpenTracker and GIHI. The rest of the source code is set to be released in October. However, most of the source code which is due to be released are the parts which provides the interfaces between the various components. However, I didn\\\\\\\\\\\\\\'t quite understand whether the source code for the examples also will be released?\r\n\r\n<b>Reproducibility:</b>\r\nNot applicable since the source code is not publicly available.\r\n\r\n<b>Use of Open Source Software:</b>\r\nI don\\\\\\\\\\\\\\'t know. There is no section which discusses the licenses of the software components.\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\n<b>Code Quality:</b>\r\n\r\n<b>Applicability to other problems:</b>\r\nThe framework should be applicable to many image guided applications due to its flexible nature.\r\n\r\n<b>Suggestions for future work:</b>\r\nI would definitely like to see how ITK is integrated in the framework. A seamless integration of ITK, or other image processing libraries, into image guided therapy frameworks is something I still haven\\\\\\\\\\\\\\'t witnessed.\r\n\r\nThe paper doesn\\\\\\\\\\\\\\'t discuss the advantages/disadvantages of The SIGN compared to other image guided therapy frameworks such as IGSTK, Julius etc.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\nI\\\\\\\\\\\\\\'m looking to following the further development of the framework as it has many good things going for it. In particular, the interface to the popular slicer, VTK and ITK in addition to the novel hybrid data flow component.\r\n", "review_id": 298}], "publication_id": 97},
{"reviews": [{"date": "08-22-2006", "author": {"author_id": 6, "author_email": "i.wolf@dkfz.de", "author_lastname": "Wolf", "author_firstname": "Ivo"}, "content": "<b>Summary:</b>\r\nThe paper describes the software package âImageLibâ which aims at rapid application development and prototyping in the field of biomedical image processing. The focus of the package is its extensibility by user-written components, which is technically detailed in the paper. The implementation relies on Borland C++ Builder and, on the visualization side, seems to be restricted to displaying 2D images (no volume or surface rendering).\r\n\r\n<b>Open Science:</b>\r\nThe source code is not provided. The compiled package and all described tools are supposed to be available for download at http://www.u-clermont1.fr/erim/.\r\n\r\n<b>Reproducibility:</b>\r\nThe link to the actual package (http://www.u-clermont1.fr/erim/Logiciels/ImgeLib/ipfulib/imagelibcpp.zip) on the page http://www.u-clermont1.fr/erim/Logiciels/ImageLib/download_new%20sauvegarde.html did not work.\r\n\r\n<b>Use of Open Source Software:</b>\r\nNo open source software mentioned.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code is not provided, but it is describe how to extend the package and how to use the provided tools.\r\n \r\n<b>Code Quality:</b>\r\nNo code available.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nAre there ready-to-use modules for typical image processing tasks available? Is it planned to wrap ITK or VTK for use within the package? A discussion of the advantages/disadvantages compared to other systems would be interesting, e.g., compared to VolView (http://www.volview.org), 3D Slicer (http://www.slicer.org), SCIRun (http://software.sci.utah.edu/scirun.html), or MeVisLab (http:// www.mevislab.de).\r\n", "review_id": 308}, {"date": "09-05-2006", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThe authors describe ImageLib which is both a development platform and GUI application. The application includes basic image manipluation tools and the plug-in interface allows for including custom processing algorithms. The text describes both the application and the plug-in interface. The paper concludes by stating \\\"Neither the library code nor processing plug-in are publicly available on the website for now, but it remains possible to obtain some of them by contacting the authors.\\\"\r\n \r\n<b>Hypothesis:</b>\r\nN/A. This is a straightforward description of the application and plug-in interface at a high level.\r\n\r\n<b>Evidence:</b>\r\nN/A. I suppose that the evidence is the application that is included with the submission.\r\n\r\n<b>Open Science:</b>\r\nThis really doesn\\'t fit the open science model. The methods described are proprietary to the Borland compiler and the code is not available. However, the interface between the application and plug-ins is open, therefore, allowing users of the package to build custom, open plug-ins. Indeed, this model is exactly the same used by Kitware for VolView. The plug-in architecture is open, so that some aspects of the work could be published openly much like ITK plugs into VolView. Nonetheless, one might be concerned about how the application could manipulate the data before and after the application calls the plug-in. This aspect of the work could not be evaluated openly.\r\n\r\n<b>Reproducibility:</b>\r\nN/A\r\n\r\n<b>Use of Open Source Software:</b>\r\nThere is no discussion of (or implication of) the use of open source software. In addition, it appears that the application is proprietary to the Borland compiler. This is not a big issue given that the code is not readily available, but it does imply that the code would be very proprietary if it were available.\r\n\r\n<b>Open Source Contributions:</b>\r\nN/A\r\n\r\n<b>Code Quality:</b>\r\nN/A\r\n\r\n<b>Applicability to other problems:</b>\r\n[Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]\r\n\r\n<b>Suggestions for future work:</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\n\r\n<b>Requests for additional information from authors:</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 370}, {"date": "07-21-2006", "author": {"author_id": 445, "author_email": "marfGm@gmail.com", "author_lastname": "Rodriguez-Florido", "author_firstname": "Miguel Angel"}, "content": "<b>Summary:</b>\r\n Authors propose a new version of a programming environment for 3D biomedical images. The environment provides all the required tools to add image\r\nprocessing functions. A fast prototyping application is proposed. The component-oriented architecture makes it posible to share image processing and \r\nhandling resources under windows. \r\n<b>Hypothesis:</b>\r\nNon Applicable\r\n<b>Evidence:</b>\r\nNon Applicable\r\n<b>Open Science:</b>\r\nThe environment is described with enough detail to understand how it works, but I have tried to download the binaries, but I get an error: \\\\\\\"The requested URL /erim/Logiciels\\\\\\\\ImageLib\\\\\\\\download_new.html was not found on this server.\\\\\\\" , so I am not able to run and try the environment.\r\nIn addition, authors don\\\\\\'t provide the source code, and the software only runs under windows.\r\n<b>Reproducibility:</b>\r\nSoftware is not available at http://www.u-clermont1.fr/erim/Logiciels%5CImageLib%5Cdownload_new.html\r\n<b>Use of Open Source Software:</b>\r\nAuthors use their own software under C++, and they have developed this environment joining their own processing modules.\r\n<b>Open Source Contributions:</b>\r\nAuthors don\\\\\\'t provide their source code. They comment in their paper that code and processing plugin are not available on the website for now.\r\n<b>Code Quality:</b>\r\nThey don\\\\\\'t provide their source code, but the paper says that they use C++ templates.\r\n<b>Applicability to other problems:</b>\r\nI think this project is very interesting, but it should be better if it runs under other platforms. Moreover, if they would provide the source code \r\nmany users will work under their environment, and could contribute to it.\r\nIn any case, this software could be used to many kinds of problems in medical image processing.\r\n<b>Suggestions for future work:</b>\r\nI would suggest to authors to open the source code, and include it under sourceforge. I think that it would help so much in their research.\r\n<b>Requests for additional information from authors:</b>\r\nNon Applicable\r\n<b>Additional Comments:</b>\r\nI think that this is a good work and the result of the work for many years, and the collaboration between many researchers/developers. It would be great\r\nif this environment was open source.\r\nMy rating is based on the IJ reviewer guidelines.\r\n\r\n", "review_id": 274}], "publication_id": 98},
{"reviews": [], "publication_id": 99},
{"reviews": [], "publication_id": 100},
{"reviews": [], "publication_id": 101},
{"reviews": [], "publication_id": 102},
{"reviews": [], "publication_id": 103},
{"reviews": [{"date": "08-31-2006", "author": {"author_id": 450, "author_email": "alice.villeger@laposte.net", "author_lastname": "Villeger", "author_firstname": "Alice"}, "content": "<b>Summary:</b>\r\n<p>The authors advertise a software package to be used within the Mathematica environment: their MathVision tool can be used to quickly design (and test, and improve) prototype algorithms for medical image analysis.</p>\r\n \r\n<b>Hypothesis:</b>\r\n<p>Not Applicable</p>\r\n\r\n<b>Evidence:</b>\r\n<p>Examples are provided for two applications (differential calculus on images, and geometry-driven diffusion) and results are shown on hand and brain images.</p>\r\n\r\n<b>Open Science:</b>\r\n<p>The source code is available only to partners who contribute code to the project. The input images shown in the paper are not provided, and no output images have been submitted.</p>\r\n\r\n<b>Reproducibility:</b>\r\n<p>I do not have the Mathematica software, so I could not reproduce the work.</p>\r\n\r\n<b>Use of Open Source Software:</b>\r\n<p>This work is based on Mathematica, which is a proprietary product.</p>\r\n\r\n<b>Open Source Contributions:</b>\r\n<p>A piece of code is provided, but I could not use it as I do not have the Mathematica software.</p>\r\n\r\n<b>Code Quality:</b>\r\n<p>I cannot comment on this as I am not familiar with the Mathematica language.</p>\r\n\r\n<b>Applicability to other problems:</b>\r\n<p>The authors suggest using this tool for prototyping medical image analysis applications, but the mathematical methods involved seem generic enough to be applied to other disciplines (for instance astronomical images, or satellite images)</p>\r\n\r\n<b>Suggestions for future work:</b>\r\n<p>Not being a Mathematica user, I cannot really comment on this.</p>\r\n\r\n<b>Requests for additional information from authors:</b>\r\n<p>Data was missing.</p>\r\n\r\n<b>Additional Comments:</b>\r\n<p>The paper is fairly well written. However, it contents a few comments that should be removed: e.g. \\\"(!!! its a GIF file here, not DICOM .. do you have a DICOM version)\\\" on page 6.</p>", "review_id": 354}, {"date": "08-22-2006", "author": {"author_id": 37, "author_email": "jmelonak@ece.gatech.edu", "author_lastname": "Melonakos", "author_firstname": "John"}, "content": "<b>Summary:</b>\r\n[Short description of the paper. In two or three phrases describe the problem that was addressed by the authors and the approach they took to solve it.]\r\nThis paper describes a software package to be used in conjunction with the Mathematica software for the mathematical prototyping in medical image analysis. The authors make particular mention of the applicability of this tool to the design or rapid prototyping stage of medical image analysis. Their MathVisionTools, as used via Mathematica, provide an interesting resource for algorithm engineers.\r\n \r\n<b>Hypothesis:</b>\r\n[If Applicable: Describe the assumptions that the authors have made and they hypothesis of their work, note that not all papers will fit the model of hypothesis driven work, for example, the description of an image database, or the description of a toolkit will not be driven by an hypothesis, in which case, please simply write : âNon Applicableâ in this field or delete the subtitle.]\r\nNot Applicable\r\n\r\n<b>Evidence:</b>\r\n[Describe the evidence that the authors provide in order to support their claims in the paper. This is a key component on Open Science, opinions that are not supported by evidence should be labeled as âspeculationsâ or âauthorâs opinionâ while. The same rule applies to the text of the reviews: claims should be supported by evidence]\r\nThis paper provides examples on the following applications:\r\n\r\n1) Differential Calculus on Images\r\n2) Geometry-driven diffusion\r\n\r\nThey show results on hand and brain images.\r\n\r\n<b>Open Science:</b>\r\n[Describe how much the paper and its addendums adhere to the concept of Open Science. Do the authors provide the source code of the programs used in their experiments? Do the authors provide the input images that they used? Or are those images publicly available? Do the authors provide the output images that they show in the paper? Do the authors provide enough details for you to be able to replicate their work?]\r\nSource Code - The paper states that source code is available on an exchange basis for partners that contribute code to the project.\r\nData - No data is provided. The paper uses two files: \\\\\\'hands.gif\\\\\\' and \\\\\\'mr128.gif\\\\\\' which have not been included with the submission. Likewise the output images have not been submitted.\r\n\r\n<b>Reproducibility:</b>\r\n[Did you reproduce the authorsâ work?\r\nDid you download their code? Did you compile it? Did you run it?\r\nDid you managed to get the same results that they reported?\r\nWere there information missing from the paper, that was necessary for you to reproduce the work? Suggest improvements that will make easier for future readers to reproduce this work.]\r\nDue to the lack of data, I was unable to reproduce the work.\r\n\r\n<b>Use of Open Source Software:</b>\r\n[Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]\r\nThe authors use a pseudo-open source strategy by offering code to \\\\\\\"partners who contribute back to the project\\\\\\\". Additionally, this code assumes the use of proprietary Mathematica, which may not be bad considering the unparalled ability of Mathematica to work at a high level of abstraction.\r\n\r\n<b>Open Source Contributions:</b>\r\n[Do the authorâs provide their source code? Is it in a form that is usable? Do they describe clearly how to use of the code? How long did it take you to use that code?]\r\nThe author\\\\\\'s do provide various pieces of the MathVisionTools. I loaded the Mathematica notebooks and was unable to run the code using Mathematica 5.0. It should be noted that I am a relatively new user of mathematica and did not know how to debug the errors.\r\n\r\n<b>Code Quality:</b>\r\n[If the authors provided their source code: Was the code easy to read? Did they use a modern coding style? Did they rely on non-portable mechanism? Was it suitable for multiple-platforms?]\r\nSince the code is written in Mathematica, it is as portable as Mathematica.\r\n\r\n<b>Applicability to other problems:</b>\r\n[Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]\r\nThere are many disciplines which can benefit from a Mathematica rapid prototyping tool. This is very nice work which may be extended to other applications.\r\n\r\n<b>Suggestions for future work:</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\nPerhaps you could include more instructions to aid Mathematica beginners to use these tools.\r\n\r\n<b>Requests for additional information from authors:</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\nThe data would be nice along with a description of how to run the notebook.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\nThere are several spots in the paper which include proofreading comments which should be cut out for the final submitted version.\r\n\r\nThis is very nice work that deserves much credit. My review, however, is based on the Insight Journal reviewer guidelines.\r\n", "review_id": 309}, {"date": "09-04-2006", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<b>Summary:</b>\r\nThis paper describes a framework for applying high level mathematical operations to medical image processing problems. The paper addresses the need of the commuinty for having tools suitable for performing high level operations when analyzing images. The authors develop a toolkit based on \\\\\\\"Mathematica\\\\\\\". The toolkit is available to everybody but the download process requires to get a username/password, the request is always granted.\r\n \r\n<b>Hypothesis:</b>\r\nThe paper advances the hypothesis that high level mathematical operations are needed in order to solve complex problems in medical image analysis.\r\n\r\n<b>Evidence:</b>\r\nThe paper in itself does not provide any evicence supporting the claims of the hypothesis, other than citations to previous publications.\r\n\r\n<b>Open Science:</b>\r\nThe paper does not satisfy the basic criteria of Open Science. The source code of the tools is only available upon request. The toolkit itself requires users to have licenses of a commercial product (Mathematica). The autors do not provide input images, nor output images, nor parameters that may make possible for a reader to repeat any of the examples presented in the paper. There is no easy way of verifying what the authors did. The paper is mostly focused on providing verbal support for the notion that they toolkit is extremely powerful and that it provides a cost-effective solution to medical imaging problems.\r\n\r\n<b>Reproducibility:</b>\r\nAfter contacting the authors, and receiving guidance from them, the reviewer was able to download the toolkit. However this reviewer was not able to reproduce the work reported by the authors due to the lack of an available license of Mathematica. The paper does not provide facilitate the process of replicating the work. In this regards it fails to satisfy the basic criteria of a scientific paper: \\\\\\\"Reproducibility\\\\\\\".\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors distribute their work as Open Source software, the download process requires to apply for a username/password with the authors, at www.mathvisiontools.net. In order to use the toolkit, the users must have a license of Mathematica.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe authors provide the source code upon request. The final paragraph of the paper states that the authors are interested on establishing collaborations with academic and industrial institutions on \\\\\\\"exchange basis\\\\\\\". \r\nIt is not clear what this means in practice. This reviewer suggest that the authors should clarify their position on Open Source, in particular, they should specify the terms under which they are willing to share the source code of the toolkit described in the paper.\r\n\r\n<b>Code Quality:</b>\r\nIt was not possible for this reviewer to evaluate the quality of the source code, given that a license of Mathematica was required.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe work of the authors seems to be applicable to a wide range of problems, but this can only be judge so far from the verbal description presented in their paper. At this point there is no way for readers or reviewers to verify the suitability of the MathVisionTools for such potential uses.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors should clarify their position in Open Source. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nIt seems that they are suggesting a novel licensing agreement for sharing source code. This is worth discussing in detail, since it may be a license that other institutions may want to use too. Currently, there are many different licenses for open source software, and it is always good to have additional alternatives. I would seem that the authors suggest to provide a license based on reciprocity. That is, they may be willing to share their private source with other institutions on the basis that those institutions will also share their private source code with them. This may be too burdersome for the general public to pursue, but still worth considering for specific inter-institutional collaborations.\r\n\r\n\r\n<b>Additional Comments:</b>\r\nThis reviewer wished the authors could have valued better the opportunity to participate in an Open Science event based on the concepts of enforcing the reproducibility of technical reports. Their paper however is based on the traditional and now outdated approach of providing verbal support for the advantages of their methodology, instead of making it possible for the commuity at large to directly verify such claims by their own experimentation.\r\n", "review_id": 358}], "publication_id": 104},
{"reviews": [{"date": "08-22-2006", "author": {"author_id": 37, "author_email": "jmelonak@ece.gatech.edu", "author_lastname": "Melonakos", "author_firstname": "John"}, "content": "<b>Summary:</b>\r\n[Short description of the paper. In two or three phrases describe the problem that was addressed by the authors and the approach they took to solve it.]\r\nThis paper presents an algorithm for colonoscopic navigation. The algorithm specifically seeks to address the dynamical nature of the colon due to the anatomical contraction and expanding of the colon. The authors present results on one dataset and point out limitations to their method.\r\n \r\n<b>Hypothesis:</b>\r\n[If Applicable: Describe the assumptions that the authors have made and they hypothesis of their work, note that not all papers will fit the model of hypothesis driven work, for example, the description of an image database, or the description of a toolkit will not be driven by an hypothesis, in which case, please simply write : âNon Applicableâ in this field or delete the subtitle.]\r\nNot Applicable\r\n\r\n<b>Evidence:</b>\r\n[Describe the evidence that the authors provide in order to support their claims in the paper. This is a key component on Open Science, opinions that are not supported by evidence should be labeled as âspeculationsâ or âauthorâs opinionâ while. The same rule applies to the text of the reviews: claims should be supported by evidence]\r\nThe authors show preliminary results on one dataset.\r\n\r\n<b>Open Science:</b>\r\n[Describe how much the paper and its addendums adhere to the concept of Open Science. Do the authors provide the source code of the programs used in their experiments? Do the authors provide the input images that they used? Or are those images publicly available? Do the authors provide the output images that they show in the paper? Do the authors provide enough details for you to be able to replicate their work?]\r\nNo source code or data is provided.\r\n\r\n<b>Reproducibility:</b>\r\n[Did you reproduce the authorsâ work?\r\nDid you download their code? Did you compile it? Did you run it?\r\nDid you managed to get the same results that they reported?\r\nWere there information missing from the paper, that was necessary for you to reproduce the work? Suggest improvements that will make easier for future readers to reproduce this work.]\r\nI was unable to reproduce the results due to lack of source code and data.\r\n\r\n<b>Use of Open Source Software:</b>\r\n[Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]\r\nAs far as I can tell, the authors make no mention of the platform on which they developed their code.\r\n\r\n<b>Open Source Contributions:</b>\r\n[Do the authorâs provide their source code? Is it in a form that is usable? Do they describe clearly how to use of the code? How long did it take you to use that code?]\r\nNo source code was provided.\r\n\r\n<b>Code Quality:</b>\r\n[If the authors provided their source code: Was the code easy to read? Did they use a modern coding style? Did they rely on non-portable mechanism? Was it suitable for multiple-platforms?]\r\nNot Applicable\r\n\r\n<b>Applicability to other problems:</b>\r\n[Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]\r\nThis work is highly optimized for endoscopic navigation and thus may apply to any problems relating to endoscopic navigation.\r\n\r\n<b>Suggestions for future work:</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\nThe authors may wish to look to control theory results for some inspiration (perhaps the Kalman filter could be used)?\r\n\r\n<b>Requests for additional information from authors:</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\nData and source code are needed.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\nThis appears to be nice work for the guidance of endoscopes. The paper nicely formulates the problem and motivates the research. The paper also details the limitations of the proposed method and includes details for future work.\r\n\r\nThe review score is based on the Insight Journal reviewer guidelines. See: http://insightsoftwareconsortium.org/wiki/index.php/IJ-Reviewer-Guidelines\r\n", "review_id": 310}, {"date": "08-23-2006", "author": {"author_id": 447, "author_email": "samset@bwh.harvard.edu", "author_lastname": "Samset", "author_firstname": "Eigil"}, "content": "<b>Summary:</b>\r\nA system for colonoscopy navigation is presented. A computer vision based method based on pattern extraction and tracking was described.\r\n \r\n<b>Hypothesis:</b>\r\nNon applicable\r\n\r\n<b>Evidence:</b>\r\nThe method was tested one image, and some illustrations are given in the paper. Quantitative validation is missing\r\n\r\n<b>Open Science:</b>\r\nNo source code is provided. The software systems used are not described.\r\n\r\n<b>Reproducibility:</b>\r\nNo source code and no image data was provided\r\n\r\n<b>Use of Open Source Software:</b>\r\nNot described\r\n\r\n<b>Open Source Contributions:</b>\r\nNo source code provided\r\n\r\n<b>Code Quality:</b>\r\nNo source code provided\r\n\r\n<b>Applicability to other problems:</b>\r\nThe method might be applicable to other endoscopic procedures.\r\n\r\n\r\n", "review_id": 313}], "publication_id": 105},
{"reviews": [{"date": "08-21-2006", "author": {"author_id": 10, "author_email": "hamarneh@cs.sfu.ca", "author_lastname": "Hamarneh", "author_firstname": "Ghassan"}, "content": "<b>Summary:</b>\r\n\r\nSoftware that enables overlaying colours, vectors, ellipsoids or curves over triangular meshes.\r\n \r\n<b>Hypothesis:</b>\r\n\r\nIn addition to the visualization geometric surfaces of objects (e.g. as output by segmentation techniques), there is a need to visualize different types of data associated with different locations on these surfaces. There is a need for an open source, freely available software allowing for visualizing scalar and vector fields, ellipsoids and space curves. The software provided addresses this issue.\r\n \r\n<b>Evidence:</b>\r\n\r\nI believe this is a valuable contribution to the MIA open science community specific to the area of visualization. Different example output results are shown. The software appears simple to use to generate results (see below for more comments).\r\n\r\n\r\n<b>Open Science:</b>\r\n\r\nThe authors provide the source code, the input text files for generating the different visualizations, the output files (BMPs), and the script needed to re-create most of the results.\r\n \r\n\r\n\r\n<b>Reproducibility:</b>\r\n\r\nI did not reproduce the results. However there is a readme.txt file listing what are the commands that must be called to produce (not all) the figures in the paper.\r\n\r\n<b>Use of Open Source Software:</b>\r\n\r\nThe authors use ITK, VTK, CMAKE, KWWIDGETS, TCL/TK. \r\n\r\n<b>Open Source Contributions:</b>\r\n\r\nThe authors provide a readme.txt with the commands needed to regenerate the results.\r\n\r\noutput, data, and code files should have a .tar extension and not a tar.gz extension. I was unable to untar without renaming the files.\r\n\r\nThe authors provide the command line options to generate the 2D snap-shots, with different views, background colors, etc.\r\n\r\nI was unable to locate the command that creates the space curve on the triangular mesh (Figure 5).\r\n\r\nIt is not clearly described how one should input the data for every ellipsoid; what are the 9 numbers that are provided after the header?\r\n-0.1209\t-0.068646\t0.2373\t1\t0\t0\t0\t1\t0\r\nAre these the elements of a 3x3 2nd order tensor or (Gaussian) covariance matrix? What is the order of these numbers is it 11,12,13,12,â¦. Or 11,21,31,â¦ If the 3x3 array is symmetric then why not provide only the 6 distinct elements?\r\n\r\n<b>Code Quality:</b>\r\n\r\nSource code files have variable amount of comments for example itkMeshTovtkPolyData.cxx has no comments at all. Other files are commented.\r\n\r\n<b>Applicability to other problems:</b>\r\n--\r\n<b>Suggestions for future work:</b>\r\n--\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\nWhat sort of interpolation is used to color the faces of the triangles of the mesh given that only scalar values at the vertices are provided?\r\n\r\nFor building and running KWMeshVisu without the GUI, does one still require KWWIDGETS and TCL/TK? \r\n\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 304}, {"date": "08-30-2006", "author": {"author_id": 448, "author_email": "ruben@ctm.ulpgc.es", "author_lastname": "Cardenes", "author_firstname": "Ruben"}, "content": "<b>Summary:</b>\r\nThis paper describes a graphical interface as well as a command line tool developed using ITK, VTK, and KWWidgets, to visualize 3D meshes together with information of several types: scalar, vectorial, ellipsoidal and curves over the surface. \r\n \r\n<b>Hypothesis:</b>\r\nThe authors claim that this tool will strongly simplify qualitative evaluation of data for statistical shape analysis.\r\n\r\n<b>Evidence:</b>\r\nAs the hypothesis made by the authors is qualitative, the evidence will be demonstrated by the practice, (maybe a table with statistics about time spent by experts to analyze a given set of surfaces could be helpful to support this), but I think this is not really necessary after using the software for a while.\r\n\r\n<b>Open Science:</b>\r\nThe authors provide the source code, as well as the data they show in the main text.\r\n\r\n<b>Reproducibility:</b>\r\nI was able to download, and successfully compile and run the code in a Linux workstation (after switching from VTK 5.0 to the cvs version of VTK). I had also to compile KWWidgets in order to get the code compiled. \r\nI was able to run the graphical interface, and to load the data they provided, reproducing the images they show in the paper. \r\nThe versions of ITK, VTK and Tcl/Tk, required o suggested to compile and run the software is not provided. I managed to compile it with the cvs version of VTK (version 5.0 is not supported), ITK 2.4.1, and Tcl/Tk 8.4.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors used open source software (ITK, VTK and KWWidgets and Tcl/Tk), and they comment that the use of KWWidgets simplify the user interface issues, because it has many built-in support for many VTK components. They don\\'t say which version of the software you should use. \r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code is completely included. The main program is a graphical user interface which is easy to use. \r\n\r\n<b>Code Quality:</b>\r\nThe code is written clear, in modern style, using some comments, and in a first view it does not seem to be quite complicated to understand and to use. It also seems to have support to be compiled in WIN32 platform. \r\n\r\n<b>Applicability to other problems:</b>\r\nThis tool can be also applied to see, for instance, thickness maps over 3D structures that could be quite helpful in areas like computer guided medical diagnosis, when the graymatter thickness is measured and visualized. \r\n\r\n<b>Suggestions for future work:</b>\r\nThe input mesh is in metafile format, and is loaded in ITK. Other formats could also be included. \r\nIt would be also interesting to add processing capabilities to this tool. \r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe application crashes when you try to load an attribute with different number of points that the loaded a mesh. A restriction to avoid that would be necessary. \r\n\r\n<b>Additional Comments:</b>\r\nThe interactive colormap managing is a good tool, and can have great advantages for visualization of significances in shapes. \r\nMy final comment to the interested reader is that, although this tool is simple, it could be quite helpful for visualization of attributes over 3D meshes.\r\nThe main problem for some people to start using its own data with this tool can be the file format compatibility. \r\n\r\n", "review_id": 318}], "publication_id": 106},
{"reviews": [], "publication_id": 107},
{"reviews": [{"date": "08-18-2006", "author": {"author_id": 468, "author_email": "yi.gao@gatech.edu", "author_lastname": "Gao", "author_firstname": "Yi"}, "content": "<b>Summary:</b>\r\nThis paper is about a NHLBI sponsored project, LTRC, which creates an open repository of histological, radiological, and clinical data for the studying of COPD and IPF.\r\n \r\n<b>Hypothesis:</b>\r\n1. Open this database will speed up the research process on lung diseases.\r\n2. Image processing community will benefit from the opening of data set.\r\n3. Base on same data set, both clinical and engineering researchers has a common platform to compare there results.\r\n\r\n<b>Evidence:</b>\r\nThere have been some work based on this data set, as given in the reference.\r\n\r\n<b>Open Science:</b>\r\nOpen Science is much more than only Open Source Code. Such opening of data set is extremely welcomed.\r\n\r\n<b>Reproducibility:</b>\r\nN/A\r\n\r\n<b>Use of Open Source Software:</b>\r\nIt didn\\'t use Open Source Software but it will definitely used by many Open Source Software.\r\n\r\n<b>Open Source Contributions:</b>\r\nN/A\r\n\r\n<b>Code Quality:</b>\r\nN/A\r\n\r\n<b>Applicability to other problems:</b>\r\nApart from clinical research of lung disease and medical image analysis area, many other fields like the teaching of lung pathology can make use of this data set.\r\n\r\n<b>Suggestions for future work:</b>\r\n[Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]\r\n\r\n<b>Requests for additional information from authors:</b>\r\n[Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n\r\n", "review_id": 301}, {"date": "07-12-2006", "author": {"author_id": 68, "author_email": "andinet.enqu@kitware.com", "author_lastname": "Enquobahrie", "author_firstname": "Andinet"}, "content": "</b>\r\nThis paper describes initiative for development of an open database containing histological, radiological and clinical data for study of COPD and IPF.\r\n\r\n<b>Hypothesis:</b>\r\nThe hypothesis is that the availability of an open and publicly available database spurs medical research and development efforts for COPD and IPF. Furthermore, performance of image analysis algorithms can be truly compared when evaluated on common database.\r\n\r\n<b>Evidence:</b>\r\nSome research work is already done using this database as listed in the reference section. With the completion and official release of the database, more investigational work using this database is expected.\r\n\r\n<b>Open Science:</b>\r\nOpen database is the backbone of open science. This paper presenting development of an open database definitely adheres to the basic concepts of open science.\r\n\r\n<b>Reproducibility:</b>\r\nNot applicable\r\n\r\n<b>Use of Open Source Software:</b>\r\nNot applicable\r\n\r\n<b>Open Source Contributions:</b>\r\nNot applicable\r\n\r\n<b>Code Quality:</b>\r\nNot applicable\r\n\r\n<b>Applicability to other problems:</b>\r\nDevelopment of an open and publicly accessible database is something that other areas of medical image research should adopt.\r\n\r\n<b>Suggestions for future work:</b>\r\nIt would be very instructive if the authors share their experiences in this project which involves collaboration between multiple institutions and medical professionals. The lessons learned would be valuable for other initiatives which are planning to pull resources/institutions together for database development.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe website link provided in the paper seems to have a problem ( www.ctascstudies.com) I was wondering if this was a temporary server or a general Internet traffic issue.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 259}], "publication_id": 109},
{"reviews": [{"date": "09-05-2006", "author": {"author_id": 79, "author_email": "xenophon.papademetris@yale.edu", "author_lastname": "Papademetris", "author_firstname": "Xenophon"}, "content": "<b>Summary:</b>\r\nThe paper presents a robot assisted needle placement system based on\r\nIGSTK. The platform has been tested and encouraging results are presented.\r\n \r\n<b>Open Science:</b> The authors provided source code and a data set,\r\nunfortunately one also needs a robot and the intra-operative scanner to\r\nreplicate the findings both of which are unfortunately not so easily\r\ndownloadable or available.\r\n\r\n<b>Reproducibility:</b>\r\nI downloaded and looked at the code which is of good quality and looks very\r\nsimilar to code in ITK. I did not attempt to compile it as it requires VTK\r\n5 and ITK 2.6 which I did not have installed on my system, however the\r\nInsight Journal dashboard suggests that it compiled just fine.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors use the usual combination of ITK/VTK and the IGSTK toolkit (as\r\nimplied by the title). The comment about IGSTK being a safe platform for\r\nresearchers and clinicians to use needs to be qualified, especially since\r\nany additional code (extensions, user applications) is perfectly capable of\r\ncrashing even the most stable of systems. \r\n\r\n<b>Open Source Contributions:</b>\r\nThe source code is made available (together with IGSTK and FLTK), see\r\nreproducibility above.\r\n\r\n<b>Code Quality:</b>\r\nSee reproducibility above.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe methodology developed for the application is fairly crude in terms of\r\nwhat constitutes state of the art image analysis. Having said that, the\r\nresults suggest that it is suitable for the application and perhaps use of\r\nmore sophisticated methods might be overkill. \r\n\r\nThe use of a CT scanner for registration is uncommon though, intra-operative\r\nscanners are not as easily available and use of CT scanner in a patient setup is \r\nkept to a minimum for radiation purposes. This makes the method less applicable to\r\nother problems. Point fiducials are time consuming but often easier to implement \r\nin most common situations.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<OL>\r\n<LI> Figure 4: The word ERROR appears in the textbox below the figure. This\r\nis a dangerous think to publish for anything related to\r\nintervention! While in this case, this is not a serious issue, it should be\r\nqualified in the caption. I assume this is the output from the state\r\nmachine.\r\n\r\n<LI> The validation study is not sufficiently well described. What was the\r\nexperimental setup? Did the authors test the amount of time for which\r\ncommunication with the robot remained stable under stress (also leaving the\r\nconnection on for a few hours without actually invoking it). What is the\r\naffect of accidental disconnection of the robot on the software (cables do\r\nget loose in real situations). In general testing of this type needs to\r\nassume that the worst will happen as it often unfortunately does in the\r\ncase of real interventions.\r\n\r\n<LI> I assume that the authors mean \\\\\\\\\\\\\\\"more sophisticated\\\\\\\\\\\\\\\" as opposed to\r\n\\\\\\\\\\\\\\\"more relaxed\\\\\\\\\\\\\\\" registration methods. Iterative closest point methods might\r\nbe appropriate, the authors might also consider robust methods which are\r\nable to do outlier rejection and hence handle any overdetection (the Robust\r\nPoint Matching framework was pioneered by Anand Rangarajan and his\r\ncollaborators comes to mind here, this code is available in various forms).\r\n</LI>\r\n</OL>\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe validation study needs to be better described. What CT scanner was\r\nused what was the environment in which the robot was placed\r\netc. Reproducibility is also critical, how do the results vary if the robot\r\nis imaged twice in the same position, or if the robot is moved back to the\r\nsame position and reimaged. This is really the weak point of this paper.\r\n\r\n\r\n\r\n\r\n", "review_id": 376}, {"date": "09-05-2006", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<b>Summary:</b>\r\nThe authors describe an application of the IGSTK software for robot-guided needle placement. While the paper is loosely about the entire robot-guided application, the method focuses on the registration component of the procedure largely because the is the most critical aspect of the software. The background briefly describes both the hardware and the IGSTK software. The method and results are in regards to the fiducial registration method.\r\n \r\n<b>Hypothesis:</b>\r\nAlthough not a hypothesis, the premise of the paper is that robot-guided needle placement is an important clinical application and requires effective software. Specifically, the software must be effective at registering the tool to the patient. Once achieved, visualization is important.\r\n\r\n<b>Evidence:</b>\r\nThe evidence is through a small validation study on a phantom. The details of the validation study are lacking a bit, but the results suggest that the fiducial registration method is effective.\r\n\r\n<b>Open Science:</b>\r\nThis work is completely open science and includes source code which can be used in conjunction with the paper to evaluate and test the method.\r\n\r\n<b>Reproducibility:</b>\r\nThe source code allows for an evaluation of the method and reproducing the study. The authors also include data in their submission which is great. That being said, there is not much information on the validation study (including the type of phantom) and how the ground truth was determined. Nevertheless, the method is reproducible and would allow another investigator to conduct an independent evaluation.\r\n\r\n<b>Use of Open Source Software:</b>\r\nEverything is open source\r\n\r\n<b>Open Source Contributions:</b>\r\nCode is available; however, I did not have the opportunity to review it thoroughly or run it. It does seems sparse on documentation in the code.\r\n\r\n<b>Code Quality:</b>\r\nSame as above.\r\n\r\n<b>Applicability to other problems:</b>\r\nOne would hope and expect that the application could be applied to other IGS applications. This provides a nice example of how to use IGSTK in a clinical application.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors appropriately suggest future work for themselves. I look forward to following this project into the future.\r\nGet going on the clinical trials to show the work that open-source can and should be used to treat patients.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe paper would benefit from including more references appropriate to the registration method. There are several fiducial based registration papers in the literature.\r\n\r\nThe validation study could be more detailed as well.\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 369}], "publication_id": 110},
{"reviews": [{"date": "08-30-2006", "author": {"author_id": 10, "author_email": "hamarneh@cs.sfu.ca", "author_lastname": "Hamarneh", "author_firstname": "Ghassan"}, "content": "<b>Summary:</b>\r\n\r\nThe authors present a pipeline for establishing 3D shape correspondence. The implementation is based on concepts from earlier work [2-7], including MDL, shape index and curvedness local features, and establishing correspondence on the unit sphere.\r\n\r\n<b>Hypothesis:</b>\r\n\r\n<li> The importance of statistical shape analysis in clinical applications. \r\n<li> The need for open source code and software for establishing 3D shape correspondence statistical model building.\r\n<li> The authorâs submission provides a means to perform 3D statistical shape analysis.\r\n\r\n<b>Evidence:</b>\r\n\r\nThe authors describe and provide code and sample data for creating statistical shape models. The authors made particular choices regarding how these models are created (e.g. MDL-based, specific local features, specific shape representation).\r\n\r\n<b>Open Science:</b>\r\n\r\nSee next section.\r\n\r\n<b>Reproducibility:</b>\r\n\r\nITK classes, code and data are provided. See below.\r\n\r\nI downloaded all the files including the source code, but did not build the code. The authors provide an application (see main.cpp), a single data set of cuboids, and an example of command line argument.\r\n\r\nThe authors write: âA detailed overview of how the example application works is useful to demonstrate how the various classes work together. Initially, an instanceâ¦.â. This paragraph is useful for understanding the framework. It would have been helpful to refer the reader to specific lines from the main.cpp file.\r\n\r\n\r\nThe authors write that the framework is flexible enough allowing the use of other local shape features. However, details describing which classes, source code, or virtual functions (?) need to be implemented or modified to accomplish this. I was expecting to find something like: \r\n\r\n ssmCalculator->SetLocalFeatures( ShapeIndexAndCurvedness);\r\n\r\nIn this way the framework may be used to compare the correspondence results and statistical model created when different local features are used. \r\n\r\n<b>Use of Open Source Software:</b>\r\n\r\nThe authors make use of CMAKE and ITK coding style. Experience or advice related to open source are not given.\r\n\r\n<b>Open Source Contributions:</b>\r\n\r\nThe authors provide the source code (and sample data). Users familiar with CMAKE should be able to build the provided application. CMakeLists.txt is provided.\r\n\r\n<b>Code Quality:</b>\r\n\r\nMain.cpp hardly has any comments. Other random files checked do not have any comments at all.\r\n\r\n<b>Applicability to other problems:</b>\r\n\r\nCode can be applied to general shape correspondence problems in non-medical applications, for example for shape modelling, geometry processing, and computer graphics.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\nI think that it would be valuable to provide a class\r\nitk::SpatialObjectToSpatialObjectRegistrationMethod\r\nwhere this work would be an instantiation of.\r\n\r\nPerhaps ImageToImage, SpatialObjectToSpatialObject, ImageToSpatialObject, and SpatialObjectToImage should all inherit from a higher level ObjectToObjectRegistrationMethod.\r\n\r\nIt would be valuable to be able to specify the different components of the shape correspondence (or the SpatialObjectToSpatialObject â¦) framework in a manner similar to the current image registration framework of ITK. In the image registration framework the user can set the transform, similarity metric, optimization, interpolation etc. It seems to me it is natural to have a similar framework for shape âregistrationâ, where the following can be set: contours vs surfaces, shape representation, correspondence/mapping representation, local features, cost functions, optimization strategy, etc. This will require a substantial investment in designing such a framework, similar to what has been undertaken for the image registration framework (perhaps even learning from that experience to provide improvements). Such a new framework will be more welcoming for other researchers and developers to create other modules (e.g. a new local feature or cost function). The current submission under review could be thought of as a single instantiation of such a general shape correspondence pipeline. The current submission does have some aspects of this general pipeline. \r\nA tutorial similar to the: âHello Worldâ Registration (section 8.2 in the ITK guide, edition 2, ITK2.4) would be beneficial.\r\n\r\nThe MDL approach ties the correspondence problem with building the statistical shape model. It might be beneficial in some cases to examine different statistical analyses or model building approaches assuming an already established correspondence.\r\n\r\n\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n\r\nIt is hard to read the text in the flowchart of Figure 4 in the PDF submission. A higher resolution figure would be good.\r\n\r\nCan the framework be applied in 2D to match contours (not surfaces) of shapes?\r\n\r\nIt appears that the software or code used to produce the images and coloring in Figure 2 is not provided. How can these figures be generated?\r\n\r\n<b>Additional Comments:</b>", "review_id": 345}, {"date": "08-30-2006", "author": {"author_id": 232, "author_email": "millerjv@research.ge.com", "author_lastname": "Miller", "author_firstname": "James"}, "content": "<b>Summary:</b>\r\nThis paper describes (and provides) methods for generating statistical shape models. A minimum description length landmark generation method is implemented. Additional features can also be used to control the selection of landmarks.\r\n\r\nAutomated generation of statistical shape models in important. While specifying shape models manually in 2D is not too taxing, the problem becomes very burdonsome for 3D objects. The methods provided here will increase the use of statistical shape models in ITK.\r\n \r\n<b>Hypothesis:</b>\r\nNon Applicable\r\n\r\n<b>Evidence:</b>\r\n\r\n\r\n<b>Open Science:</b>\r\nPaper provides source code and data.\r\n\r\n<b>Reproducibility:</b>\r\nThe software built without issue for me.\r\n\r\n<b>Use of Open Source Software:</b>\r\nProvides an ITK framework for constructing shape models.\r\n\r\n<b>Open Source Contributions:</b>\r\nSource code provided. While in an ITK framework, many of object inherit from itkObject. Does it make sense for some of the algorithms to be implemented as filters?\r\n\r\nThis paper only covers the construction of the statistical shape model, not its application.\r\n\r\n<b>Code Quality:</b>\r\nSee the above note.\r\n\r\n<b>Applicability to other problems:</b>\r\nStatistical shape models are an important component of medical image analysis. They are not utilized more because of the difficulty in specifying the models in 3D. \r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\nThis paper only covers the construction of the statistical shape model, not its application. Is there another paper on the application or do the authors use existing ITK methods to fit a statistical shape model to an image?\r\n\r\n<b>Additional Comments:</b>\r\n", "review_id": 346}, {"date": "12-12-2006", "author": {"author_id": 529, "author_email": "syrkina@vision.ee.ethz.ch", "author_lastname": "Syrkina", "author_firstname": "Ekaterina"}, "content": "<p><strong>Summary:</strong><br />With this work authors present flexible software for establishing correspondence between shape boundaries over a given training set. This is the main step in statistical shape model building. Application is restricted to the objects with spherical topology. Framework for the model building itself (after establishing correspondence) is not provided, but this is the minor step in the problem.<br /> <br /> <strong>Hypothesis:</strong><br />Not applicable<br /> <br /> <strong>Evidence:</strong><br />As far as I know, presented work is the first open source for this particular problem. Default settings has been proven by appropriate for the MDL approach measurements to give the best results (see authors&#39; IPMI paper), but it also possible to change some parts of the algorithm such as cost function, initial parametrisation, landmark positions, use of features and other fine tunings (up to now I&#39;ve tried only default settings). </p><p> <strong>Open Science:</strong><br /> Source code is available, but there is only one example data set (cuboids). </p><p> <strong>Reproducibility:</strong><br />I&#39;ve downloaded and compiled the code without any problems. </p><p>Running. The following statement from the paper is not correct in the current implementation: &quot;A main() function is provided along with these classes as a ready to use tool. The only parameters to this tool are an input list file, a landmark file, and a model radius.&quot; There is 4th parameter in the last version and I get segmentation fault without it (while there is the check of the number of input parameters in main.cc, I do not get the expected message: &quot;Usage: &quot; &lt;&lt; argv[0] &lt;&lt; &quot; MeshListFile LandmarkFile ModelRadius OutputLandmarkFile&quot;). Would be nice to see more detailed description when running the program (e.g. with &quot;-h&quot;). Also I get warnings with no sense for me: &quot;Couldn&#39;t convert pixel type&quot;.</p><p>Comment for Linux users: data are provided with Windows line breaks, you have to use something like dos2unix to avoid problems. It would be nice to have data for both Linux and Windows platforms. </p><p><strong>Use of Open Source Software:</strong><br />ITK, cmake </p><p> <strong>Open Source Contributions:</strong><br />Source code is provided, main classes are described, but more clear and up to date instructions how to use it are neccesary. </p><p>Classes for mesh writers in different formats are available for output (STL, ASCII). Default output format is *.meta.</p><p>Small text correction: it seems that number of vertices for cuboids given in the Table 2 (that is 486) is not correct (I&#39;ve found only 386 for cuboids data)&nbsp;</p><p><strong>Code Quality:</strong><br />Code is enough commented</p><p><br /> <strong>Applicability to other problems:</strong><br />Can be applied for any problem where statistical shape modeling for triangulated meshes is needed. It is not restricted only to medical applications. </p><p> <br /> <strong>Suggestions for future work:</strong><br />Thought the most difficult part of building statistical shape model is given, construction of the model itself (with PCA) and framework to analyse the model (e.g. calculation of measures, such as specificity and generalisation ability) would make the application more complete. Also, visualisation part is not covered and no hints to visualise data and get 3d images from the paper are given. Default output mesh format also requires some comments.</p><p><strong>Requests for additional information from authors:</strong><br />Up to date parameters to run the program<br /> <br /> <strong>Additional Comments:</strong><br />Very nice and useful job! Thanks! </p>", "review_id": 444}], "publication_id": 111},
{"reviews": [{"date": "10-10-2006", "author": {"author_id": 102, "author_email": "sylvainjaume@gmail.com", "author_lastname": "Jaume", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThe paper describes an implementation of the paper about conformal flattening of triangle surfaces by Angenent et al. 1999.\r\nThe code uses VTK and ITK, and includes a new ITK class, three applications, and two example surfaces.\r\n\r\n<b>Hypothesis:</b>\r\nThe paper addresses the flattening of *triangle* surfaces, typically obtained with the Marching Cubes algorithm. The implementation applies to surfaces of genus zero with no boundaries, i.e. closed surfaces with no handles.\r\nA triangle surface can be mapped on a 2D parameterization under one of two constraints: to preserve the area of the triangles (authalic flattening), or to preserve the angles of the triangles (conformal flattening).\r\nThe authors take the conformal flattening approach.\r\n\r\n<b>Evidence:</b>\r\nTwo example applications are included: one with a synthetic surface and one brain surface.\r\nThe quality of the results is only reported for the synthetic surface. Besides it would be interesting to visualize the angle ratios computed in anglePreserveCheck.\r\nFinally a scalar bar with a title and units would make the figures more informative.\r\n\r\n<b>Open Science:</b>\r\nThe authors provide everything to reproduce the results in the paper. However they do not give some information that the user needs to reproduce similar results with her/his own data.\r\nThe way the triangle meshes were created and the quality of the triangles may dramatically impact the results of the flattening. How the example surfaces were created, and what are the equations or input images?\r\nWhich tools were used, in which order? What are the parameters? What are the potential issues and workarounds (e.g. increasing the value of one parameter)?\r\n\r\n<b>Reproducibility:</b>\r\nThe code compiles like a charm on VS8 and is straightforward to use (one input and one output). I got exactly the results reported in the paper.\r\nTo take advantage of the IJ testing facility, the authors may want to add a test in the CMakeLists.txt.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe authors mention that they use \\\\\\'open-source tools\\\\\\', but these tools require manual editing. More information about this editing would help potential users.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe three applications are easy to compile, to run and to understand.\r\nTheir code only differs in the visualization parameters of their Display method. Would it make more sense to factorize the surface flattening in a single application and the visualization in another?\r\nThis second application could have two sets of parameters: one for nice.vtk and one for brain.vtk.\r\n\r\n<b>Code Quality:</b>\r\nI noticed major VTK memory leaks. For instance instances of vtkIdList are created and never deleted.\r\nTo be consistent with the ITK style, the underscore at the begining of variable names could be removed.\r\nFor the same reason, the name of the class methods could start with a capital letter: setPointP, mapToSphere, mapToPlane, setScale.\r\nAs for the documentation of the methods, it is preferred to write the comments before the method signature.\r\nFuture users of this code would aprreciate if all methods were documented.\r\n\r\nAs it is, the code may cause runtime errors. Calls to \\\\\\'return\\\\\\' are missing after every itkExceptionMacro.\r\nIt is recommended to insert filter->Update() in a try/catch block.\r\nWhy setting point P to -100000 in brainTest.cxx and itkConformalFlatteningFilterTest.cxx?\r\nvtkPolyDataNormals may create some problems since it may duplicate points. In any case, it does not seem to improve the rendering.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe numerous problems that require a 2D parameterization could benefit from this implementation.\r\n\r\n<b>Suggestions for future work:</b>\r\nThe authors may be interested in using the topology correction code OpenTopology published in the InsightJournal.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe implementation could be explained further in the paper (matrix construction, solver for the equation system, vnl functions called, etc.).\r\nHow the equations of section 1 (that can be found in Angenent et al. paper) map to the actual code that the authors contributed?\r\nOnly two sentences at the end of section 1 offer some information about the implementation.\r\n\r\n<b>Additional Comments:</b>\r\nThe information that anglePreserveCheck writes to the standard output needs some revisions: the file is named angleRatioDiff.txt and it contains the ratios for the angles around every node.", "review_id": 408}, {"date": "09-02-2006", "author": {"author_id": 487, "author_email": "xiaoning.qian@gmail.com", "author_lastname": "Qian", "author_firstname": "Xiaoning"}, "content": "<b>Summary:</b> \r\nThis paper describes the implementation of an angle preserving flattening\r\nalgorithm. The algorithm provides one alternative for the brain study after\r\nthe conformal flattening map.\r\n \r\n<b>Hypothesis:</b>\r\nThe implemented algorithm preserves relative angles and guarantees a\r\nbijective map and the original structure can be recovered by inverse\r\nmap. ( The later is not shown as the main point though. )\r\n\r\n\r\n<b>Evidence:</b>\r\nThe authors only provide the results for one synthetic and one brain. They\r\nlook good and the mean and s.t.d. of angle ratios for the brain is valid.\r\nBut as the authors noted, they could not get more brain surface as the\r\ncurrent segmentation algorithms are not able to give them genus zero \r\nsurfaces.\r\n\r\n\r\n<b>Open Science:</b>\r\n The source codes and data for the algorithm used in the experiments is\r\n provided. The authors follow the standards of open source.\r\n\r\n<b>Reproducibility:</b>\r\n I haven\\'t run the algorithm or tests the authors provided.\r\n\r\n<b>Use of Open Source Software:</b>\r\n The codes are based on ITK.\r\n\r\n<b>Code Quality:</b>\r\n I haven\\'t looked at the source codes carefully at this time.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe statistical study for any genus zero surface.\r\n\r\n<b>Suggestions for future work:</b>\r\n The work probably needs more data for testing.\r\n\r\n<b>Additional Comments:</b>\r\n There are some typos in the paper. (for example, in pape 2)\r\nAnd also, it seems to me that the authors directly took the mathematical\r\npart for the reference [1]. I think that some intuitive introduction of the\r\nalgorithm would be better.\r\n\r\n", "review_id": 356}], "publication_id": 112},
{"reviews": [], "publication_id": 113},
{"reviews": [{"date": "10-09-2006", "author": {"author_id": 21, "author_email": "hans-johnson@uiowa.edu", "author_lastname": "Johnson", "author_firstname": "Hans"}, "content": "<b>Summary:</b>\r\nThis article describes a proposed new filter that is a specialization similar to that of the SpatialObjectToImageFilter that is optimized for creating a boundary of an ellipse.\r\n \r\n<b>Hypothesis:</b>\r\nGenerating an image of the boundary of an ellipse is an important and commonly used task.\r\n\r\n<b>Evidence:</b>\r\nNo evidence given.\r\n\r\n\r\n<b>Open Science:</b>\r\nNot much science here, just specialization to fill a need.\r\n\r\n<b>Reproducibility:</b>\r\nI did not compile this source code in my environment.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis is intended to be incorporated into ITK.\r\n\r\n<b>Open Source Contributions:</b>\r\nSource code is provided, along with a minimalistic test case.\r\n\r\n<b>Code Quality:</b>\r\nThis is a specialization of similar ITK filters, and it follows the ITK conventions for coding style.\r\n\r\n<b>Applicability to other problems:</b>\r\nIt seems that this is one of many specializations for converting spatial objects into images.\r\n\r\n\r\n<b>Suggestions for future work:</b>\r\nNone\r\n\r\n<b>Requests for additional information from authors:</b>\r\nNone\r\n\r\n<b>Additional Comments:</b>\r\nNone\r\n", "review_id": 407}, {"date": "09-14-2006", "author": {"author_id": 286, "author_email": "dan.muel@gmail.com", "author_lastname": "Mueller", "author_firstname": "Dan"}, "content": "<b>Summary:</b>\r\nThis paper presents a new fitler (derived from SpatialObjectToImageFilter) which converts only the boundary of an Ellipse SpatialObject to an image.\r\n\r\n<b>Open Science:</b>\r\nAll source and tests are available. However, no baseline output images were provided to test my output with the \\'expected\\' output.\r\n\r\n<b>Reproducibility:</b>\r\nI reproduced the work. I compiled the project on WinXP, with MSVC 8.0, using CMake 2.4.2 with no problems. I ran the test provided with the project and it reportedly passed. I added the #define SAVEIMAGE in itkEllipseBoundaryToImageFilterTest.cxx to force the output image to written to disk - the output was as described in the paper.\r\n\r\nAs meantioned above, it would be useful to provide a baseline output image with the paper.\r\n\r\n<b>Open Source Contributions:</b>\r\nUses ITK.\r\n\r\n<b>Code Quality:</b>\r\nThe code is in the ITK coding style, however some more comments would be good. I am also concerned regarding the use of \\'magic numbers\\':\r\n1. PI is defined as a const in EllipseBoundaryToImageFilter::ConvertOneSOToPoints. Try using \\' #include \\\"vnl/vnl_math.h\\\" \\' and then \\'vnl_math::pi\\' (make sure that the project is linked with the VNL libraries).\r\n2. What is the magic number \\'10.0\\' for in the following line: \\' double numOfIter = maxRadius * 10.0 ; \\' ? Is it possible to compute this number from the input SO? Will this number be correct for all cases? Perhaps I am misunderstanding what it is used for, some more comments would help...\r\n\r\n<b>Suggestions for future work:</b>\r\n1. Use vnl_math::pi (see above).\r\n2. Think about the \\'magic number\\' 10.0 (see above).\r\n3. It\\'s probably wise to separate the single test function into multiple tests. If one test fails, it appears that they <i>all</i> fail, even if this is not the case (because they are in the same function). Have a look at the CMake documentation and ITK test code for how to register multiple tests per project.\r\n4. It seems the code for automatically computing the Size, Spacing, and Origin is disabled - it would be good if the filter could automatically compute these using the SO bounding box, etc.\r\n5. Add a baseline output image (see above).", "review_id": 385}, {"date": "08-28-2006", "author": {"author_id": 23, "author_email": "blloyd@ee.ethz.ch", "author_lastname": "Lloyd", "author_firstname": "Bryn"}, "content": "<b>Summary:</b>\r\nThis filter creates an image from an ellipse spatial object.\r\n \r\n<b>Hypothesis:</b>\r\nNot Applicable\r\n\r\n<b>Evidence:</b>\r\nThe author has written a filter which is faster than alternative exitsing methods in ITK. The speedup is not given and has not been measured or documented.\r\n\r\n<b>Open Science:</b>\r\nThis is open.\r\n\r\n<b>Reproducibility:</b>\r\n[Did you reproduce the authorsâ work? yes\r\nDid you download their code? Did you compile it? Did you run it? yes\r\nDid you managed to get the same results that they reported? yes, using his parameters. For larger radius the method fails.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThis is open.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe code is written in ITK-style and is easy follow. The test gives an example of how to use the filter.\r\n\r\n<b>Code Quality:</b>\r\nThe code is written in the ITK-style. Very easy to compile, it passes all it\\'s tests. If the radius of the ellipse is increased though (e.g. to 50), the method produces an ellipse with holes/gaps. This happens because the method samples the surface and uses constant sampling angle-differences. The sampled points are then passed to a PointSetToImageFilter. On the other hand, if the radius is small too many sampling points are used.\r\n\r\n<b>Applicability to other problems:</b>\r\nNot sure how applicable this is to other projects/applications. The author does not say what the application is and why it needs to be fast.\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n<b>Requests for additional information from authors:</b>\r\n\r\n<b>Additional Comments:</b>\r\n\r\n", "review_id": 332}], "publication_id": 114},
{"reviews": [], "publication_id": 115},
{"reviews": [], "publication_id": 116},
{"reviews": [], "publication_id": 117},
{"reviews": [{"date": "10-30-2006", "author": {"author_id": 133, "author_email": "cates@sci.utah.edu", "author_lastname": "Cates", "author_firstname": "Josh"}, "content": "<p>Summary:<br />This work is an itk file reader for the VoxBo CUB image format.&nbsp; It supports compressed and uncompressed <br />files using zlib.&nbsp; An imageIO class and IO factory are provided, along with a test .cub file and a simple test <br />program.&nbsp; The code conforms to ITK style guidelines, follows the ITK Image IO design pattern and passes <br />the supplied tests.&nbsp; Some additional work on the testing and documentation might be worth considering. </p><p>Open Science:<br />Both the source code and test data are provided.&nbsp; Revision 2 of this submission includes a CMakeLists.txt file.<br /><br />Reproducibility: <br />The code provided compiled without errors on 64-bit SUSE Linux<br />under gcc 4.1.0 and ITK 2.8.1.&nbsp; I was able to run the test examples given in<br />the paper without error.&nbsp; Unfortunately I do not have any way to validate the<br />files produced (see Additional Comments for some suggestions).&nbsp; I did not find<br />inputTestImage.cub.gz included with the submission.&nbsp; Should the line from page<br />3 reading &quot;convertImage inputTestImage.cub.gz outputTestImage2.cub&quot; be edited<br />to read &quot;convertImage outputTestImage1.cub.gz outputTestImage2.cub&quot; instead?<br /><br />Open Source Contributions:<br />This code is certainly a valuable contribution for users of the VoxBo software, which is itself an open-source<br />project.<br /><br />Code Quality:<br />The code is written to conform to the ITK style guidelines and is easy to read.&nbsp; If this code is to be considered <br />for inclusion in ITK, the comment field for the itk::VoxBoCUBImageIO class should be expanded.&nbsp; A <br />short paragraph that summarizes the Background section of the paper would probably suffice.<br /><br />Additional Comments:<br />Note that ITK distributes a version of zlib, so you could use this one instead of relying on the system zlib.<br /><br />For a more robust test that would be supported by the ITK Dartboard image diff system, you might consider <br />extracting a 2D slice from the output of convertImage to compare against a known reference image.&nbsp; <br />Alternatively, you could compute a checksum from the output image data that you compare to a known value.&nbsp;</p>", "review_id": 421}, {"date": "09-05-2006", "author": {"author_id": 102, "author_email": "sylvainjaume@gmail.com", "author_lastname": "Jaume", "author_firstname": "Sylvain"}, "content": "<b>Summary:</b>\r\nThe paper describes new ITK classes to read and write in CUB format (used by the application VoxBo).\r\n\r\n<b>Evidence:</b>\r\nI would like to see a 2D slice of the input image and the same slice after conversion.\r\nThe abstract says \\\\\\\\\\\\\\'no extensive testing is presented and no examples are shown.\\\\\\\\\\\\\\' But really it should!\r\n\r\n<b>Open Science:</b>\r\nThe paper fully adheres to the concept of Open Science. Source code for the classes and for an application are included. The CMakeLists.txt is missing. Please upload a CMakeLists.txt similar to this one:\r\n\r\nPROJECT(VoxBo)\r\n\r\nFIND_PACKAGE( ITK REQUIRED )\r\nINCLUDE( ${ITK_USE_FILE} )\r\n\r\nADD_EXECUTABLE(ConvertImage ConvertImage.cxx itkVoxBoCUBImageIO.cxx itkVoxBoCUBImageIOFactory.cxx)\r\nTARGET_LINK_LIBRARIES(ConvertImage ITKIO ITKCommon)\r\n\r\nADD_TEST(ConvertImage\r\n ${OUTPUT_EXECUTABLE_PATH}/ConvertImage inputTestImage.cub outputTestImage.cub)\r\n\r\nOne input image is included. However the paper mentions other input images. They should all be included.\r\nThe output images should also be included as a reference. So the reader could check she/he gets the same output.\r\nThe author could mention whether the input and output files are exact copies (in which case typing \\\\\\\\\\\\\\'diff inputFile outputFile\\\\\\\\\\\\\\' would suffice to check the result).\r\n\r\n<b>Reproducibility:</b>\r\nI could not compile the code. I tried on Windows and Mac. The compiler complains about missing zlib.h.\r\nI believe you did run your code and got the results you report in the paper.\r\nSo please write a CMakeLists.txt with some tests and upload it to the InsightJournal.\r\nIt will create a Dashboard and, if there is any error when compiling or running your code, you could check the messages and fix the code.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe author mentions an application called VoxBo. However VoxBo is not required to run the code, but just to check the results.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe author decided to contribute all his source code for the benefit of the community. Thanks!\r\nHe just misses the CMakeLists.txt which makes this contribution more challenging to test and use.\r\n\r\n<b>Code Quality:</b>\r\nI discourage using #define. Image dimension and number of arguments could simply be hardcoded since your file format is for 3D images and your application always takes 2 arguments.\r\nSecond, it is a good idea to insert the Update calls into try/catch blocks particularly for readers/writers:\r\n\r\n try\r\n {\r\n reader->Update();\r\n }\r\n catch ( itk::ExceptionObject &err )\r\n {\r\n std::cerr << \\\\\\\\\\\\\\\"Exception caught in reader!\\\\\\\\\\\\\\\" << std::endl;\r\n std::cerr << err << std::endl;\r\n return EXIT_FAILURE;\r\n }\r\n \r\n writer->SetInput( reader->GetOutput() );\r\n writer->SetFileName( argv[2] );\r\n try\r\n {\r\n writer->Write();\r\n }\r\n catch ( itk::ExceptionObject &err )\r\n {\r\n std::cerr << \\\\\\\\\\\\\\\"Exception caught in writer!\\\\\\\\\\\\\\\" << std::endl;\r\n std::cerr << err << std::endl;\r\n return EXIT_FAILURE;\r\n }\r\n\r\n<b>Suggestions for future work:</b>\r\nI would like to see testing of the conversion from/to CUB and other formats (e.g. MetaImage, Analyze, DICOM).\r\nI do understand that some fields may not be propagated.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nCMakeLists.txt with tests, outputTestImage.cub, and outputTestImage in other formats.\r\nMake sure it runs on your platform and other platforms.\r\n\r\n<b>Other comments:</b>\r\nWriting reader/writer classes is of paramount importance and is often overlooked by the community.\r\nIt can be very involved to make it successful on all the variants of the file format (consider DICOM!).\r\nA big piece of work has been achieved in this contribution, and I believe only some touch-ups are necessary to have this code used by many.", "review_id": 374}], "publication_id": 118},
{"reviews": [{"date": "09-21-2006", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<b>Summary:</b>\r\n\r\nThe paper presents the implementation of efficient connectivity framework based on ITK. By including all the recommendations suggested in Gaetan Lehmannâs earlier review, this makes a formidable example for an inclusion into ITK.\r\n\r\n<b>Open Science:</b>\r\nThe full source code, a testing program as well as the test data is provided.\r\n\r\n<b>Reproducibility:</b>\r\nI have not compiled or reproduced the results.\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe work is based on ITK and represents an extension of it.\r\n\r\n<b>Open Source Contributions:</b>\r\nThe author provide a flexible and efficient basic framework for connectivity operators as open source.\r\n\r\n<b>Code Quality:</b>\r\nThe code looks good, well structured and documented.\r\n\r\n<b>Applicability to other problems:</b>\r\nThe framework seems easily adapted and applicable to other connectivity problems. \r\n", "review_id": 393}, {"date": "11-06-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<p><strong>Summary:</strong> This article present a set of new ITK classes designed to integrate digital topology in the toolkit, and a thinning filter implemented with those classes. </p><p><strong>Open Science:</strong> Source code is provided, as well as test data </p><p><strong>Reproducibility:</strong> I reproduced the author work, but with some problem (as reported by the automatic testing system). The author should use a contribution template to avoid those problems </p><p><strong>Use of Open Source Software:</strong> The new classes are fully integrated to the toolkit </p><p><strong>Open Source Contributions:</strong> Eveything is there and already easy to use </p><p><strong>Code Quality:</strong> Code quality is very good and easy to read. However, it does not always follow the ITK coding style (naming and indentation) </p><p><strong>Applicability to other problems:</strong> This contribution provides classes applicable to many problems: directly with the thinning algorithm, and in all transforms which are manipulating the connectivity notion (that&#39;s the case of several of my already publish contributions, and some of my contributions in preparation), and obviously the topology notions </p><p><strong>Suggestions for future work:</strong> </p><ul><li> release the pre condition of the thining. An object should touch the border. I would set a border value to fix that, with a SetBorderInside(bool) for example, or always considere the outside of the image is inside or outside the object. </li><li> let the user specify the connectivity at run time. I can&#39;t see in your code any efficiency reason to keep that as template parameter. </li><li> There are already some filters in ITK which are manipulating connectivity - the reconstruction filters for example, or the connected component one. The connectivity option is limited to the smallest one (6 in 3D) and the largest on (26 in 3D) without the possibility to use an intermediate value. It would by nice to extend their capabilities with your connectivity framework, and so provide FullConnectivity(bool) adapter in the connectivity class. </li><li> let the user choose the ordering image type </li><li> it should be possible to get a Neighborhood from the Connectivity object. That way, an iterator can be used to access the neighbors, instead of offsets </li></ul> I have already done the items below. The modified code is available at&nbsp;http://voxel.jouy.inra.fr/darcsweb/darcsweb.cgi?r=ITKSkeleton;a=summary <ul><li>ordering input should be managed by the itk pipeline, not as an ivar, so the filter can be fully used in a pipeline </li><li>the filter must require the entire input region to produce correct output. Without that, if a small region is requested, the output will not be the same than the same region of the image if the filter have produce all the image </li><li>the filter should provide a progress reporter </li><li>the hierarchical queue does not follow the itk coding style. I have also worked on such a class some weeks ago - it must be a real need in ITK </li><li>the filter should let the user define the value of the pixels which are int the object, instead of considering that 0 pixels are outside </li><li> the header should include the txx file only if ITK_MANUAL_INSTANTIATION is not defined </li><li> copy constructor and operator= should be declared but not implemented, in order to be wrappable </li><li> use a clean code structure to build properly on automatic testing system, and on reviewers systems </li><li> improve queue performance by using a list instead of of a deque (36 s instead of 382 s with you rabbit image on my computer) (nice rabbit by the way) </li><li> provide tests with cmake, so the reproducibility can be easily validated. Tests are also very useful as non rregession tests, hwen implementing new features (the changes above are validated that way) </li></ul><strong>Additional Comments:</strong> The above chapter looks may make the contribution looks like no so good work - that&#39;s really not the case. It&#39;s only easier to say what&#39;s wrong than what is good :-) I thought to implement the a thinning filter based on the same article a few month ago, but give up by lack of time. You&#39;ve done it better than what I should have done, so everything is fine :-)", "review_id": 317}, {"date": "07-23-2007", "author": {"author_id": 286, "author_email": "dan.muel@gmail.com", "author_lastname": "Mueller", "author_firstname": "Dan"}, "content": "<p><strong>Summary:</strong><br /> This paper presents an ITK filter for skeletonization using homotopic thinning.<br /> <br /> <strong>Hypothesis:</strong><br />The author claims the presented filter is faster than the existing ITK method, and works for both 2-D and 3-D images.<br /> <br /> <strong>Evidence:</strong><br />A table of results in given on page 3 of the paper supporting the claim. <br /> </p><p><strong>Open Science:</strong><br />The source code, input data, and baseline result is supplied with the article. <br /> <br /> <strong>Reproducibility:</strong><br />I downloaded, compiled, and ran the work (there were some compilation issues, see below). I have also used the filter in other applications on a variety of 2-D and 3-D images.<br /><br /> <strong>Use of Open Source Software:</strong><br />Extends ITK.<br /> <br /> <strong>Open Source Contributions:</strong><br />The full source code is provided, as well as a test executable. I would suggest using the CMake ADD_TEST functionality and ImageCompare for validating the output matches the baseline image.</p><p> <strong>Code Quality:</strong><br />Most of the code is good. However I did encounter some issues compiling the code using Microsoft Visual Studio 8.0.50727.762:</p><ul><li>itkChamferDistanceTransformImageFilter.txx(180) : Error C2780: &#39;const _Ty &amp;std::min(const _Ty &amp;,const _Ty &amp;,_Pr)&#39; : expects 3 arguments - 2 provided<br /></li><li>itkUnitCubeCCCounter.txx(34) : Warning C4996: &#39;std::copy&#39;: Function call with parameters that may be unsafe - this call relies on the caller to check that the passed values are correct. To disable this warning, use -D_SCL_SECURE_NO_WARNINGS. See documentation on how to use Visual C++ &#39;Checked Iterators&#39; </li></ul><p>I fixed the errors by specifying the template argument for std::min: minimum = std::min(minimum, it.GetPixel(i) + mask[i]);</p><p>There are a number of style considerations I would also suggest:</p><ul><li>Is there a good reason for the itkSkeletonizeImageFilter to be an InPlaceImageFilter? I have found that this causes issues when writing the output of the skeletonize filter to disk: the output must be disconnected before being plugged into a writer object. I think making the filter an ImageToImageFilter would fix this.<br /></li><li>I agree with Ga&euml;tan&#39;s comment regarding the ForegroundConnectivity template: it should be removed (to help with wrapping).</li><li>I agree with Ga&euml;tan&#39;s comment regarding automated border padding: at the moment if the input image (accidentally) touches the edges a segfault is caused (perhaps this is the problem that Ruben described in this review?).</li><li>I like Ivan&#39;s idea to add a template for the itkSkeletonizeImageFilter ordering image: except I would make the default the input image type for sake of ease.</li><li>The txx file include in itkSkeletonizeImageFilter.h should be wrapped with the normal ITK_MANUAL_INSTANTIATION.</li><li>The commenting in the header files does not seem to conform to the standard ITK style.</li><li>The mechanism for setting the weights in itkChamferDistanceTransformImageFilter is not the typical ITK style (in fact it took me quite some time to work out how to set the values). To bring it more in line with the ITK standard, I suggest using a FixedArray typedef similar to that used by the BilateralImageFilter to specify the DomainSigma parameters, or the itkCannyEdgeDetectionImageFilter Variance parameter, etc.</li></ul><p><br /> <strong>Applicability to other problems:</strong><br />The work is useful for a range of applications, including vessel centerline detection.<br /> <br /> <strong>Overall:</strong><br /> A useful filter, with some further work it will make a great addition to ITK. </p>", "review_id": 513}, {"date": "02-21-2007", "author": {"author_id": 164, "author_email": "imacia@vicomtech.org", "author_lastname": "Macia", "author_firstname": "Ivan"}, "content": "<p><strong>Summary:</strong><br />This paper describes an implementation in ITK of some concepts taken from digital topology. It implements a connectivity framework allowing to calculate the topological numbers of a point in a neighborhood and to discriminate simple points. The authors implement a useful algorithm for skeletonization using binary thinning based on these concepts. In my opinion it is a very useful contribution for the toolkit and one I was particularly interested in.<br /> <br /> <strong>Open Science:</strong><br />Source code as well as an example with data is provided that allows reproducibility.<br /> <br /> <strong>Reproducibility:</strong><br />I was able to compile and reproduce the mentioned results. Latest fixes solve most of the initial compilation problems.<br /> <br /> <strong>Use of Open Source Software:</strong><br />The implementation is based on ITK and is itself an extension of the libraries for some features that are not already implemented.<br /><br /> <strong>Open Source Contributions:</strong><br />The provided source code is readily usable as it is, maybe requiring some minor changes/fixes. Main contributions are a framework for connectivity and an implementation of a skeletonization image filter based on binary thinning. More work could be derived by extending/using these concepts.<br /> <br /> <strong>Code Quality:</strong><br />The implementation is good and well structured, separating the different concepts involved into components. <br />I miss some more documentation/comments in some parts on the code that makes it easier to read.<br />Sometimes it does not follow the ITK coding style.</p><p>Additionally I made some fixes/improvements in the code :<br />- The ordering image type should be a template parameter. I have already been in the need of using an image type different from itk::Image<br />- There where some variables/members/methods that were using char/int where they should use unsigned char/unsigned int, for example the neighborhood image buffer and neighborhood sizes.<br />- I had linking problems with the global method factorial() when integrating it into an application. Changed this to a static method. Also reimplemented Factorial() to avoid recursive function calls.<br /><br />My proposed changes are included as an attachment<br /> <br /> <strong>Applicability to other problems:</strong><br />More imaging algorithms based on concepts of digital topology could be implemented using this work. The skeletonization algorithm is very useful for vessel centerline extraction.<br /> <br /> <strong>Suggestions for future work:</strong><br />I miss some more introductory information in the paper. For example, the definition of simple points which is not obvious for non-experts.<br /> <br /> </p>", "review_id": 456}, {"date": "06-24-2007", "author": {"author_id": 620, "author_email": "r.b.schilling@gmail.com", "author_lastname": "Schilling", "author_firstname": "Ruben"}, "content": "<strong>Summary:</strong><br /><div>The authors addressed the lack of a 3D skeletonization filter in ITK. They implemented a homotopic thinning algorithm based on chamfer distance ordered topologically correct pixel removal.</div><div><br /> <strong>Hypothesis:</strong><br />The authors assume the image to be binary and not connected to the image&#39;s border. Their goal is a 1D line of good medial position reflecting the topology of the image.</div><div><br /> <strong>Evidence:</strong><br /></div><div>The authors support their claims by a test input image and the expected resulting image of their algorithm.</div><div><br /> <strong>Open Science:</strong><br />The authors provide enough data, code and information to conduct the experiment.</div><div><br /></div><div> <strong>Reproducibility:</strong></div><div>I reproduced the authors work by downloading, compiling and running their code on the provided image. The image was indeed as reported by the authors.<br /><br /></div><div> <strong>Open Source Contributions:</strong><br />The authors provide their source code. Except for a missing file (IJMacros.txt) everything was in place. After obtaining the missing file from a different place on the internet compilation was fine.<br /> </div><div><br /></div><div><strong>Code Quality:</strong><br />The code runs fine on my Mac OS X box and was nicely readable and structured.</div><div><br /> <strong>Applicability to other problems:</strong><br /></div><div>I didn&#39;t get the authors code to work on any other image except the one provided. Changing file format of the provided file from .hdr/.img to .tif stopped the algorithm from producing output. Adding a second object to the image (just another foreground blob, not connected to the bunny and flat circular 10 pixels radius, not touching the border) stopped also the algorithm from producing output. Using my own binary data (not touching border of the image) let the algorithm crash with a segmentation fault, even for very small image sizes, where memory isn&#39;t an issue. Converting the provided test images to tif and back to hdr resulted in silghtly different output.</div><div><br /> <strong>Suggestions for future work:</strong><br /></div><div>I would suggest, that the code should be made more reliable regarding the described issues.</div><div><br /> <strong>Requests for additional information from authors:</strong><br /></div><div>I found, that the paper was missing enough information about tuning parameters of the algorithm and an instructive description of the algorithm&#39;s parameters. It would be helpful to add those to the paper and/or code comments.</div><div><br /> <strong>Additional Comments:</strong><br /><br /></div>", "review_id": 494}, {"date": "09-27-2006", "author": {"author_id": 500, "author_email": "bipul.das@ge.com", "author_lastname": "Das", "author_firstname": "Bipul"}, "content": "I tried to build it using MSVC 6.0, ITK 2.2 and Cmake 2.2. I have a few questions:\r\n\r\nInitially in the CMake file it tries to include file IJMacros.txt - which could not be found. What should this file be...\r\n\r\nI made some changes to run the cmake part. While trying to build the following errors were found and warnings were found:\r\n\r\n<b> Errors </b>\r\n\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkPoint.h(43) : error C2503: \\\\\\'FixedArray<double,0>\\\\\\' : base classes cannot contain zero-sized arrays</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(141) : see reference to class template instantiation \\\\\\'itk::Point<double,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Utilities\\\\\\\\vxl\\\\\\\\core\\\\\\\\vnl/vnl_matrix_fixed.h(114) : error C2087: \\\\\\'<Unknown>\\\\\\' : missing subscript</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkMatrix.h(164) : see reference to class template instantiation \\\\\\'vnl_matrix_fixed<double,0,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(148) : see reference to class template instantiation \\\\\\'itk::Matrix<double,0,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Utilities\\\\\\\\vxl\\\\\\\\core\\\\\\\\vnl/vnl_matrix_fixed.h(114) : warning C4200: nonstandard extension used : zero-sized array in struct/union</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkMatrix.h(164) : see reference to class template instantiation \\\\\\'vnl_matrix_fixed<double,0,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(148) : see reference to class template instantiation \\\\\\'itk::Matrix<double,0,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkVector.h(59) : error C2503: \\\\\\'FixedArray<double,0>\\\\\\' : base classes cannot contain zero-sized arrays</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(159) : see reference to class template instantiation \\\\\\'itk::Vector<double,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(393) : error C2229: class \\\\\\'itk::ImageBase<0>\\\\\\' has an illegal zero-sized array</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageRegion.h(264) : error C2229: class \\\\\\'itk::ImageRegion<0>\\\\\\' has an illegal zero-sized array</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(395) : see reference to class template instantiation \\\\\\'itk::ImageRegion<0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(396) : error C2229: class \\\\\\'itk::ImageBase<0>\\\\\\' has an illegal zero-sized array</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(397) : error C2229: class \\\\\\'itk::ImageBase<0>\\\\\\' has an illegal zero-sized array</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : error C2503: \\\\\\'ImageBase<0>\\\\\\' : base classes cannot contain zero-sized arrays</b>\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\BackgroundConnectivity.h(16) : error C2143: syntax error : missing \\\\\\',\\\\\\' before \\\\\\'-\\\\\\'</b>\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\BackgroundConnectivity.h(17) : see reference to class template instantiation \\\\\\'itk::BackgroundConnectivity<TConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\BackgroundConnectivity.h(16) : error C2977: \\\\\\'Connectivity\\\\\\' : too many template arguments</b>\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\Connectivity.h(110) : see declaration of \\\\\\'Connectivity\\\\\\'\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\BackgroundConnectivity.h(17) : see reference to class template instantiation \\\\\\'itk::BackgroundConnectivity<TConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\UnitCubeCCCounter.txx(28) : error C2059: syntax error : \\\\\\'\\\\\\'template<\\\\\\'\\\\\\'</b>\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\UnitCubeCCCounter.txx(40) : error C2143: syntax error : missing \\\\\\';\\\\\\' before \\\\\\'{\\\\\\'</b>\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\UnitCubeCCCounter.txx(40) : error C2447: missing function header (old-style formal list?)</b>\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\UnitCubeCCCounter.txx(85) : error C2954: template definitions cannot nest</b>\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\UnitCubeCCCounter.txx(86) : error C2059: syntax error : \\\\\\'\\\\\\'template<\\\\\\'\\\\\\'</b>\r\n<b>C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\UnitCubeCCCounter.txx(108) : fatal error C1903: unable to recover from previous error(s);</b> stopping compilation\r\nError executing cl.exe.stopping compilation\r\nError executing cl.exe.\r\n\r\n\r\n<b> Warnings </b>\r\n\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkOffset.h(183) : warning C4200: nonstandard extension used : zero-sized array in struct/union</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkIndex.h(83) : see reference to class template instantiation \\\\\\'itk::Offset<0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(102) : see reference to class template instantiation \\\\\\'itk::Index<0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkIndex.h(260) : warning C4200: nonstandard extension used : zero-sized array in struct/union</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(102) : see reference to class template instantiation \\\\\\'itk::Index<0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkSize.h(189) : warning C4200: nonstandard extension used : zero-sized array in struct/union</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(111) : see reference to class template instantiation \\\\\\'itk::Size<0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n<b>C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkFixedArray.h(211) : warning C4200: nonstandard extension used : zero-sized array in struct/union</b>\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkPoint.h(43) : see reference to class template instantiation \\\\\\'itk::FixedArray<double,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImageBase.h(141) : see reference to class template instantiation \\\\\\'itk::Point<double,0>\\\\\\' being compiled\r\n C:\\\\\\\\itksoftware\\\\\\\\InsightToolkit-2.4.0\\\\\\\\Code\\\\\\\\Common\\\\\\\\itkImage.h(84) : see reference to class template instantiation \\\\\\'itk::ImageBase<0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(109) : see reference to class template instantiation \\\\\\'itk::Image<unsigned int,0>\\\\\\' being compiled\r\n C:\\\\\\\\Bipul\\\\\\\\DigitalTopology\\\\\\\\ITKSkeleton\\\\\\\\itkSkeletonizeImageFilter.h(114) : see reference to class template instantiation \\\\\\'itk::SkeletonizeImageFilter<TImage,TForegroundConnectivity>\\\\\\' being compiled\r\n", "review_id": 406}], "publication_id": 120},
{"reviews": [{"date": "08-31-2006", "author": {"author_id": 232, "author_email": "millerjv@research.ge.com", "author_lastname": "Miller", "author_firstname": "James"}, "content": "<b>Summary:</b>\r\nThis paper describes an contribution to ITK to generate well composed images. In well composed images, all foreground and background pixels are 4-connected. This simplifies post-processing algorithms.\r\n \r\n<b>Hypothesis:</b>\r\nNon applicable\r\n\r\n<b>Evidence:</b>\r\nExample images of the results are provided. The motivating images in Figure 1 are difficult discern the benefit of well-composed. Perhaps this image can be annotated for the reader.\r\n\r\n<b>Open Science:</b>\r\nThe paper uses ITK and extends itkInplaceImageFilter\r\n\r\n<b>Reproducibility:</b>\r\nCode built without issue\r\n\r\n<b>Use of Open Source Software:</b>\r\nCode uses ITK. \r\n\r\n<b>Open Source Contributions:</b>\r\nSource code provided\r\n\r\n<b>Code Quality:</b>\r\nCode provides separate implementations for 2D and 3D processing. Can these two implementations be combined into one filter? The use of the InPlaceFilter is nice.\r\n\r\n\r\n<b>Applicability to other problems:</b>\r\n\r\n\r\n<b>Suggestions for future work:</b>\r\n\r\n\r\n<b>Requests for additional information from authors:</b>\r\nDetails on the specific algorithms should be provided in the paper. The paper describes the \\\\\\\\\\\\\\\"what\\\\\\\\\\\\\\\" but not the \\\\\\\\\\\\\\\"how\\\\\\\\\\\\\\\". The reader is directed to the references for the \\\\\\\\\\\\\\\"how\\\\\\\\\\\\\\'s\\\\\\\\\\\\\\\".\r\n\r\n<b>Additional Comments:</b>\r\n[This is a free-form field]\r\n\r\n", "review_id": 347}, {"date": "09-22-2006", "author": {"author_id": 168, "author_email": "torsten@synapse.sri.com", "author_lastname": "Rohlfing", "author_firstname": "Torsten"}, "content": "<b>Summary:</b>\r\nThe paper describes the implementation of filters for repairing morphological defects in 2D and 3D binary images.\r\n \r\n<b>Hypothesis:</b>\r\nNot applicable.\r\n\r\n<b>Evidence:</b>\r\n2D and 3D test data and results are provided.\r\n\r\n<b>Open Science:</b>\r\nThe algorithm is implemented in ITK; source code is included. Two test images (one 2d, one 3d) are also included.\r\n\r\n<b>Reproducibility:</b>\r\nCode compiles and runs, but the name of one example file (brain3d.mha) does not match the name coded into the test program (brain3D.mha with capital \\\\\\\"D\\\\\\\").\r\n\r\n<b>Use of Open Source Software:</b>\r\nThe algorithm is implemented using ITK and fits within the ITK design.\r\n\r\n<b>Open Source Contributions:</b>\r\nSource code is provided. The paper does an excellent job of explaining how to use the implemented filter. \r\n\r\n<b>Code Quality:</b>\r\nThe code seems quite well written and the style conforms with ITKs coding style. Documentation is lacking (this is why I am rating 4 out of 5) - many fields in the filter class are undocumented. Critical sections of the actual implementation should also be documented in the txx file.\r\n\r\n<b>Applicability to other problems:</b>\r\nSee Suggestions for future work\r\n\r\n<b>Suggestions for future work:</b>\r\nI am wondering - can these algorithms be extended to accomodate multi-label images? One could of course treat each label separately and then merge the resulting corrected binary images back into a corrected multi-label image. Is there anything in the algorithm that prevents ambiguities in such a merging step (it is not a shortcoming of the algorithm if there isn\\\\\\'t such a property, but it would be immensely useful if it did).\r\n\r\nAlternatively - is it conceivable to truly extend the method to multi-label situations and fixing all labels simultaneously?\r\n\r\nI am asking because bad configurations like the ones described here often result when I combine multiple segmentations of a single image using label voting. We have recently proposed \\\\\\\"shape-based averaging\\\\\\\" based on the Euclidean distance transform (Rohlfing & Maurer, MICCAI 2005; IEEE-TIP paper in press December 2006). But that algorithm is extremely computationally expensive (one signed EDT per label and input image), so a morphological algorithm like the one proposed here might be a good alternative.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nOne of the beautiful aspects of the proposed algorithms is that it seems to be completely parameter-free. So the description is naturally quite complete.\r\n\r\n<b>Additional Comments:</b>\r\nThis is an extremely well-written paper. Complete yet compact, to the point, and very carefully illustrated. Excellent work, and a pleasure to read!\r\n\r\n", "review_id": 395}], "publication_id": 121},
{"reviews": [], "publication_id": 122},
{"reviews": [{"date": "10-12-2006", "author": {"author_id": null, "author_email": null, "author_lastname": null, "author_firstname": null}, "content": "<b>Summary:</b>\r\nThe authors implement a parallelized 3-D version of Maurer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'s signed distance transform algorithm. This is compared with the existing Maurer distance \r\ntransform.\r\n \r\n<b>Hypothesis:</b>\r\nNA\r\n\r\n<b>Evidence:</b>\r\nParallelization for compatible algorithms should obviously execute much faster. The authors do an excellent job of demonstrating this by not only comparing times \r\nwith the existing Maurer ITK filter in the paper but also creating a test \u0003executable in which the number of threads can be selected and the algorithm can be timed. \r\n\r\n<b>Open Science:</b>\r\nSince this is an ITK filter, the source code and paper all adhere to the expectations of open science. \r\n\r\n<b>Reproducibility:</b>\r\nI was able to download the authors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' work, run it, and reproduce the results they achieved. \r\n\r\n<b>Use of Open Source Software:</b>\r\nITK is used.\r\n\r\n<b>Open Source Contributions:</b>\r\nUsing the code was simple as the explanation was clear and implemented within the ITK framework.\r\n\r\n<b>Code Quality:</b>\r\nSeems to be ITK conforming. Did the authors pass the code through the KWSYS for checking code conformability with ITK standards?\r\n\r\n<b>Applicability to other problems:</b>\r\nThe signed distance transform has widespread applicability. Optimizing for speed is clearly advantageous.\r\n\r\n<b>Suggestions for future work:</b>\r\n*Please* extend the method to n-D (hence the four star rating).\r\n\r\n<b>Requests for additional information from authors:</b>\r\nThe only recommendation for additional information is that the authors should include 2-D slices of the 3-D images on which they ran their tests.\r\n\r\n<b>Additional Comments:</b>\r\n\r\n", "review_id": 412}, {"date": "09-17-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<b>Summary:</b>\r\nThe author presents a new parallel implementation of the SignedMaurerDistanceMapImageFilter, and show an important increase of performance on SMP computers\r\n \r\n<b>Evidence:</b>\r\nThe author show some figures to prove the performance gain with several processors, and the linear complexity of the algorithm\r\n\r\n<b>Open Science:</b>\r\nSource code is provided, but some programs are missing to reproduce the results shown in the paper\r\n\r\n<b>Reproducibility:</b>\r\nI was not able to build the project. The PROJECT_NAME() macro is called with a wrong number of arguments, and some files (itkMaurerSignedDistanceTransformImageFilter.h) seems to not has been package in the archive.\r\nAlso, no tests are provided (with ADD_TEST()) to easily validate the filter, and the program used to get the execution time is not provided.\r\n\r\n\r\n<b>Use of Open Source Software:</b>\r\nITK, ITK, ITK\r\n\r\n<b>Open Source Contributions:</b>\r\nSource code is provide, as well as instruction oabout how to use it and examples\r\n\r\n<b>Code Quality:</b>\r\nCode quality seems quite good, but a quick look show several problems:\r\n<ul><li> the use of exit() in the code instead of throwing an exception\r\n<li>display error message to std::err make the error invisible to everyone use the program without running it from a terminal\r\n<li> the limitation to dimension 3 while nothing seems to limit the algorithm to this dimension make the filter hardly acceptable for ITK, where dimension independance is a main feature\r\n<li>the filter doesn\\\\\\'t use the standard itk threading system\r\n</ul>\r\n\r\n<b>Applicability to other problems:</b>\r\nAs the current Maurer distance transform, this filter may be used in many cases. The parallel implementation will give important increase of performance on SMP computers - computers which are more and more common with the democratisation of dual core processors\r\n\r\n<b>Suggestions for future work:</b>\r\n<ul>\r\n<li>fix the build\r\n<li>implement the filter for any dimension\r\n<li>detail in the article why the standard ITK threading method can\\\\\\'t be used, and how it is implemented in the filter\r\n<li>provide tests with ADD_TEST()\r\n<li>provide the program used to measure the threading performance\r\n<li>use the current Maurer filter name: the user should be able to replace the current filter by the new one in its ITK sources without problem. The result must be the same, only the implementation is different.\r\n</ul>\r\n\r\n<b>Additional Comments:</b>\r\nThreading support is going to be an important feature in the near future with the dual core processors. That\\\\\\'s nice to see some contributions of parallel algorithms.\r\n", "review_id": 387}], "publication_id": 123},
{"reviews": [{"date": "09-17-2006", "author": {"author_id": 286, "author_email": "dan.muel@gmail.com", "author_lastname": "Mueller", "author_firstname": "Dan"}, "content": "<b>Summary:</b>\r\nThis paper presents a reworking of ITK\\'s mathematical morphology filters. The work is motivated by a number of factors including convenience, completeness, and performance. As of revision 1, this is a stub article only - the source code contains the developmental versions of all the additional filters, however only the FlatStructuringElement is addressed in the paper. As such, this review focusses on the FlatStructuringElement issues only.\r\n\r\n<b>Open Science:</b>\r\nThis contribution conforms to Open Science by providing all source code, tests, and images.\r\n\r\n<b>Reproducibility:</b>\r\nI compiled the entire project on WinXP SP2, using MSVC8.0, CMake 2.4.2. I encountered a number of compilation issues:\r\n\r\n1. Project testSE: itkFlatStructuringElement.txx: line 512: <b>ambiguous call to pow()</b>. Microsoft Visual Studio 8.0 on WinXP can not resolve the first argument if it is an int - it must be explicitly cast to a double. eg. \\'unsigned int facets = 8 * (int)pow(4, iterations);\\' becomes \\'unsigned int facets = 8 * (int)pow(4.0, iterations);\\'\r\n\r\n2. Project kernelShape: itkFlatStructuringELement.h: line 67: <b>error C2064: term does not evaluate to a function taking 0 arguments</b>. This one is a little beyond my experience: I looked <a href=http://msdn2.microsoft.com/en-us/library/z72c1dfd.aspx>here</a> for some more info, but it didn\\'t really help. To temporarily resolve this issue in order to continue reviewing, I removed the default argument values and changed all the references to FromImage and GetImage to specifically provide the values (not a very good long term solution - the default parameters are nice! If anyone has any suggestions for getting this to work with MSVS8.0 on WinXP I am willing to test it out).\r\n\r\n3. There are <b>lots</b> of warnings: <b>warning C4804 : unsafe use of type bool in operation</b>. (BTW Gaetan, I have also noticed these warnings when compiling WrapITK). This results from using comparison operations on bools (seeing that the itk::Neighborhood has TPixel=bool). These warnings may scare/confuse some users, so it might be wise to add the following pragma statement somewhere: \\' #pragma warning( disable : 4804) \\'. For sake of ease I have added it to ImageToImageFilter.h in my working copy, but this is probably not the best place for it... Probably better is the header file of each morphological filter .. ?\r\n\r\n<b>Use of Open Source Software:</b>\r\nUses ITK.\r\n\r\n<b>Code Quality:</b>\r\nExcellent code quality. I like lots of comments, and itkFlatStructuringElement.txx has plenty! \r\n\r\nJust a few minor issues:\r\n1. While the guts of the code is very well commented, the actual header (which users will look to for useage instructions/documentation) is lacking. I feel you should add/enhance the comments for:\r\nBox: eg. \\\" An easy access method for creating a box (2D) or cube (3D) structuring element. This method supports n-D dimensions. \\\"\r\nBall: eg. \\\" An easy access method for creating a circle (2D) or spherical (3D) structuring element. \\\"\r\nPoly: eg. \\\" An easy access method for creating a polygon structuring element. Note that for 3D structuring elements, only the following number of edges are supported: 12, 14, 20, 32. \\\"\r\nFromImage: eg. \\\" Creates an arbitrary structuring element from the given image. \\\"\r\n\r\n2. It is probably worthwhile to comment the Decomposable property in itkFlatStructuringElement.h (just to let users know they don\\'t need to worry too much about it - eg. \\\" This is an internal property to specify if the current structuring element is decomposable. Decomposable structuring elements can be implemented using more efficient/faster algorithms. \\\"). Also to conform to ITK standards maybe use itkGetConstMacro(Decomposable, bool);\r\n\r\n3. (This is a bit of a personal preference but) I like to see any papers which the class implements or was influenced by in the class documentation in the header (ie. include the reference to \\\"Radial Decomposition of Discs and Spheres\\\" - CVGIP: Graphical Models and Image Processing in the header).\r\n\r\n<b>Applicability to other problems:</b>\r\nMathematical morphology has wide application and the enhancements proposed in this article make using morphological filters in ITK more convenient and computationally more efficient.\r\n\r\n<b>Requests for additional information from authors:</b>\r\nIs there a reason that you defined M_PI in itkFlatStructuringElement.txx and didn\\'t use the Utilities/vxl/core/vnl/vnl_math.h version (vnl_math::pi) ? \r\n\r\n<b>Additional Comments:</b>\r\nBTW: I like the images/StrelFromImage.png picture!\r\n\r\n", "review_id": 389}], "publication_id": 124},
{"reviews": [{"date": "11-03-2006", "author": {"author_id": null, "author_email": null, "author_lastname": null, "author_firstname": null}, "content": "<strong>Summary:</strong><br /><div>The author presents a simple, yet useful filter for swapping image halves across dimensions.Â  Such a filter is useful for visualizing low frequency components of the Fourier transform at the center of the output image.Â  Many readers will recognize similar functionality offered by the &#39;fftshift&#39; function in Matlab.</div><div><br /> <strong>Evidence:</strong><br /> </div><div>The author provides two images to demonstrate functionality as well as the output images.</div><div><br /> <strong>Open Science:</strong><br /> </div><div>The author&#39;s submission adheres to the standards of open science (e.g. source code transparency, input images with corresponding output images).Â </div><div> <br /> <strong>Reproducibility:</strong><br /> I did reproduce the work of the authors in addition to testing the filter with two of my own 2-D and 3-D images.Â  Fortunately, the filter was simple enough to determine usage.Â  However, it would be helpful to have a usage print-out in the test code itself.Â  In addition, although the filter is indeed simple, it would also be helpful for further explanation of the included figures (e.g. the author simply refers to &quot;the figure below&quot; in discussing the SetInverse() function).Â Â </div><div><br /></div><div><strong>Use of Open Source Software:</strong><br />The filter constitutes an extension of ITK.</div><div><br /> <strong>Open Source Contributions:</strong><br /></div><div>The author provides the source code.</div><div><br /> <strong>Code Quality:</strong><br />Code quality is good.</div><div><br /> <strong>Suggestions for future work:</strong><br /></div><div>No suggestions.</div><div><br /> <strong>Requests for additional information from authors:</strong><br />None.<br /><br /></div>", "review_id": 426}, {"date": "11-01-2006", "author": {"author_id": 81, "author_email": "jakub.bican@matfyz.cz", "author_lastname": "Bican", "author_firstname": "Jakub"}, "content": "<p><strong>Summary:</strong><br />fftshift is a common operation to visualise fourier-transformed image. This contribution presents a new filter that performs this operation. </p><p><br /> <strong>Hypothesis:</strong><br />N/A<br /> <br /> <strong>Evidence:</strong><br />Author states that this is a common operation which is missing in ITK - this is obviously true. </p><p><br /> <strong>Open Science:</strong><br />Do the authors provide the source code of the programs used in their experiments? <strong>YES<br /></strong>Do the authors provide the input images that they used? <strong>YES<br /></strong>Or are those images publicly available? <strong>N/A<br /></strong>Do the authors provide the output images that they show in the paper? <strong>YES</strong><br />Do the authors provide enough details for you to be able to replicate their work? <strong>YES</strong></p><p> <br /> <strong>Reproducibility:</strong><br /> Did you reproduce the authors&rsquo; work? <strong>YES</strong><br /> Did you download their code? Did you compile it? Did you run it? <strong>YES/YES/YES</strong><br /> Did you managed to get the same results that they reported? <strong>YES</strong><br /> Were there information missing from the paper, that was necessary for you to reproduce the work? <strong>NO</strong><br />Suggest improvements that will make easier for future readers to reproduce this work. <strong>not necessary</strong><br /><br /> <strong>Use of Open Source Software:</strong><br />ITK/CMake</p><p><br /> <strong>Open Source Contributions:</strong><br /> Do the author&rsquo;s provide their source code? <strong>YES<br /></strong>Is it in a form that is usable? <strong>YES<br /></strong>Do they describe clearly how to use of the code? <strong>YES<br /></strong>How long did it take you to use that code? <strong>few seconds</strong> </p><p> <br /> <strong>Code Quality:</strong><br />Was the code easy to read? <strong>YES<br /></strong>Did they use a modern coding style? <strong>YES<br /></strong>Did they rely on non-portable mechanism? <strong>NO<br /></strong>Was it suitable for multiple-platforms? <strong>YES</strong></p><p> <br /> <strong>Applicability to other problems:</strong><br />N/A<br /> <br /> <strong>Suggestions for future work &amp; comments:</strong><br />I tried to validate the output - i executed the test code on BrainProtonDensitySliceBorder20.png image from ITK examples data set and then tried to compare the results (forward and inverse) with results of matlab fftshift function.</p><p>I discovered, that the <strong>forward</strong> run (3. parameter==0 on commandline) of this code does what does the <strong>ifftshift</strong> function of matlab and the <strong>inverse</strong> run (3. parameter==1) has the same result as <strong>fftshift</strong> function.</p><p>I suppose to author to check if i am true and possibly switch the forward/inverse behavior to let the functionality match with the matlab.</p>", "review_id": 425}, {"date": "12-05-2006", "author": {"author_id": 523, "author_email": "pierre.seroul@gmail.com", "author_lastname": "Seroul", "author_firstname": "Pierre"}, "content": "<p><strong>Summary:</strong><br />Similarly to the fftshift and ifftshift functions of Matlab, this filter swaps the &quot;half-spaces&quot; of the input image along each dimension.<br /> <br /> <strong>Evidence:</strong><br />The author provides two input images and their corresponding outputs using or not the &quot;inverse&quot; option.<br /> <br /> <strong>Open Science:</strong><br />The author provides the source code and an example to reproduce his experiments. He also provides the images.<br /><br /> <strong>Reproducibility:</strong><br />I compiled the code using CMake 2.4 and Visual C++ 2005 Express on Windows XP SP2, there is no error or warning. I ran it with different types of image supported by ITK (png, jpg, tiff, gif, 24-bit bitmap) and it works great.<br />The results are easily reproducible with the information from the paper.<br /><br /> <strong>Use of Open Source Software:</strong><br />The authors use ITK.<br /><br /> <strong>Open Source Contributions:</strong><br />The author provides his source code and describes clearly how to use it.<br /><br /> <strong>Code Quality:</strong><br />The code is easy to read and all the necessary comments are presents.<br /><br /> <strong>Requests for additional information from authors:</strong><br />Maybe the author could shortly describe how the filter puts the zero-frequency component in the center of the image (swapping parts of the image) in the pdf file. </p>", "review_id": 441}], "publication_id": 125},
{"reviews": [], "publication_id": 126},
{"reviews": [{"date": "10-31-2006", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<strong>Summary:</strong><br /> The author present a new filter to combine several binary image in a single labeled image. <strong>Open Science:</strong><br /> The source code is provided, as well as the input images, but not the result image. It is easy to reproduce the example. <strong>Reproducibility:</strong><br /> I have downloaded, compile without problem. The test program can&#39;t run as it is: the ${CMAKE_SOURCE_DIR} string in images/testfiles is not expanded when read by the test program. Even by replacing manually the string above by the full path, I failed to get the expected output: the image is all black. <strong>Use of Open Source Software:</strong><br /> fully ITK <strong>Open Source Contributions:</strong><br /> The source code provided is designed to be reused, and is provided as a contribution to ITK <strong>Code Quality:</strong><br /> The code does not fully follow the ITK coding style (indentation, brackets, ...) - a minor issue - and doesn&#39;t use the pipeline architecture of ITK - this time, a major issue. <strong>Applicability to other problems:</strong><br /> It seem to be a quite common need to combine the result of different segmentations procedures in a labeled image. This code may be reused in many cases. <strong>Suggestions for future work:</strong><br /><ul><li> use the ITK pipeline architecture. You can avoid doing most of the work by implementing your class as a subclass of NaryFunctorImageFilter. </li><li> provide the output image </li><li> fix the test. You should test the output image with ImageCompare </li><li> implement the collision case </li><li> perhaps call it NaryBinaryImageToLabelImageFilter ? </li></ul><strong>Additional Comments:</strong><br /> The problems above looks like small beginner&#39;s mistakes. Please contact me if you need some help to fix the problems above. I&#39;d be pleased to help&nbsp;:-) ", "review_id": 424}], "publication_id": 127},
{"reviews": [{"date": "11-14-2006", "author": {"author_id": 511, "author_email": "jordi.inglada@cnes.fr", "author_lastname": "Inglada", "author_firstname": "Jordi"}, "content": "<p><strong>Summary:</strong><br />The problem addressed is the one of providing an easy access to complex valued images. Helper classes for conversion between cartesian and polar complex representations are given.<br /> <br /> <strong>Hypothesis:</strong><br />Non Applicable</p><p><br /> <strong>Evidence:</strong><br />Non Applicable<br /> <br /> <strong>Open Science:</strong><br />Source code is given.</p><p> <strong>Reproducibility:</strong><br />I was able to successfully compile and run the code.</p><p><strong>Use of Open Source Software:</strong><br />ITK is used.</p><p><br /> <strong>Open Source Contributions:</strong><br />Source code is available.</p><p><br /> <strong>Code Quality:</strong><br />Seems to follow the ITK guidelines.<br /> <br /> <strong>Applicability to other problems:</strong><br />Very interesting for other image processing fields where comples images are used (radar images in remote sensing, for instance).</p><p> <strong>Suggestions for future work:</strong><br />Helper classes for filter design in the Fourier domain would be useful. Time-frequency analysis for complex data (short-time Fourier transform, Wigner-Ville and other transforms from the Cohen&#39;s class could be easily implemented) as well as Doppler analysis functionnalities would be useful for complex valued images. </p><p>&nbsp;</p><p><br /> <strong>Requests for additional information from authors:</strong></p><p>A more detailed description of the source code would be appreciated. The paper text is only ine page long! </p><p> <strong>Additional Comments:</strong><br />None.<br /> <br /> </p>", "review_id": 434}, {"date": "12-11-2006", "author": {"author_id": 410, "author_email": "vpage@univ-ag.fr", "author_lastname": "Vincent", "author_firstname": "Page"}, "content": "<p><strong>Summary:</strong><br />It s not a paper. The author implements a Complex to Complex FFT algorithms and some associated filters for the Insight Library.</p><p>As I have not been able to make/cmake the code, I guess that this review is of poor help.</p><br /><p><br /> <strong>Open Science:</strong></p><p>Sure It is open science !</p><p>&nbsp;</p><p><strong>Reproducibility:</strong><br /> I was not able to compile ... I spend 4 hours to re-compile the whole ITK with respect to the procedure of the README file, and then discovered that It&#39;s been of no help...I tried many other compilations, but no results either. Maybe I missed something but I guess that I would have done a better work as a reviewer if :</p><p>- the install part (compilation) was more detailed.</p><p>- a test procedure would be welcome ?</p><p>- I guess it is possible to compile only the new parts (and test them). There might be a standard procedure for this ... </p><p>&nbsp;</p>", "review_id": 443}, {"date": "11-07-2006", "author": {"author_id": 81, "author_email": "jakub.bican@matfyz.cz", "author_lastname": "Bican", "author_firstname": "Jakub"}, "content": "<p><strong>Summary:</strong><br />While Real-Complex and Complex-Real FFT filters are already present in the ITK, the general Complex-Complex filter is missing. This contribution brings such class along with two classes to compose a complex image from real and imaginary or modulus and phase components.<br /> <br /><strong>Evidence:</strong><br />Complex-Complex FFT is useful transform and corresponding filters are missing in ITK<br /> <br /> <strong>Open Science:</strong><br />This submission includes source codes and very simple example code, but with no testing data. I did not compile or execute the example as it does not comply with IJ submission style and requires overwriting parts of my local ITK installation.</p><p><strong>Reproducibility:</strong><br />I suggest adjusting the submission configuration to the IJ Testing Environment and add some tests and test images.</p><p><strong>Use of Open Source Software:</strong><br />These filters should be an extension of ITK.<br /> <br /> <strong>Open Source Contributions:</strong><br />The source code is provided but i found some problems that has to be fixed before the code will be widely usable.<br /> <br /> <strong>Code Quality:</strong><br />Code looks good.</p><p><strong>Applicability to other problems:</strong><br />N/A</p><p><strong>Suggestions for future work and comments:</strong></p><p>FFTComplexToComplexImageFilter</p><ul><li>FFT Direction should be rather a class &quot;property&quot; than a template parameter</li><li>complex to complex FFT is ALWAYS &quot;FullMatrix&quot; - halving of size in first dimension is a property of real to complex (and inverse) FFTs (due to so called Hermitian Redundancy) - see for example FFTW documentation for more details.</li><li>I recommend implementing customized New() method to this base class to enable configuration-based instantiation (see &quot;factories for FFTW filters - update&quot; discussion in Insight-users mailing list)</li></ul><p>FFTWComplexToComplexImageFilter</p><ul><li>I believe, that the current implementation - the way it is handling USE_FFTWD and USE_FFTWF constants and input pixel types - is not very functionable. I think it will work if only one of these constants is defined - if both are (which is not a very rare case), it may fail during compilation. But may be i am wrong in this, as i did not compile the code and i still have some gaps in generic programming:). BUT i highly recommend completely refactoring this class to use (possibly extended) FFTWProxy class as e.g. FFTWRealToComplexConjugateClass does. </li></ul><p><br /><strong>Final sigh</strong>: the optimal way would be to have one FFT filter that will be able to perform all types of FFT transforms (real-complex, complex-real, complex-complex) depending on the input and output image types and Direction property (only in case of complex-complex, as the direction is fully determined by the input and output types in case of &quot;real&quot; FFTs) - so you can focus in this way when refactoring the classes :-) (but of course - having simple complex-complex filter as you are proposing is OK too!) </p><p>&nbsp;</p>", "review_id": 428}, {"date": "11-17-2006", "author": {"author_id": 150, "author_email": "norman-k-williams@uiowa.edu", "author_lastname": "Williams", "author_firstname": "Kent"}, "content": "<p><strong>Summary:</strong><br /> Proposes adding ComplexToComplex FFT operations to ITK</p><p><br /> <strong>Hypothesis:</strong><br /> Author hypothesizes that adding ComplexToComplex FFT filters to ITK would be a good thing.</p><p> <strong>Evidence:</strong><br />Source Code</p><p><br /> <strong>Open Science:</strong></p><p>Freely available source code... </p><p><strong>Reproducibility:</strong></p><p>I downloaded the code and read the paper, such as it was. It&#39;s more like an abstract for a paper than an actual paper. The code being proposed for inclusion in ITK is very specific and concise, but a brief description of the new classes introduced, and why they have the class signature they do would be useful. </p><p><strong>Use of Open Source Software:</strong></p><p>As far as I can tell, completely open. </p><p> <strong>Open Source Contributions:</strong><br />Source Code is included and is nominally useful and mostly correct.</p><p><strong>Code Quality:</strong><br />Suggestions: This code was derived by editing the existing FFT/FFTW real-to-complex and complex-to-real source code. That origional code has changed slightly since the author appropriated it to produce this new set of classes. In order to be compatible with the current FFTW it&#39;s necessary to make copies of the input data, since it gets scribbled on by the fftwX_plan function. Also, the current FFTW/FFT code in Code/Algorithms allocates buffers and preserves the plan memory, so you can instantiate a filter, and re-use it without re-generating the plan. This is a big performance win. </p><p><strong>Applicability to other problems:</strong><br />Generally applicable to FFT based image processing, in cases where Complex image data is the input. This includes use in a pipeline that requires more than one FFT/IFFT operation in an ITK Pipeline, as the intermediate image results can remain in complex numbers. </p><p> <strong>Suggestions for future work:</strong><br /> Revisit the real-to-complex and complex-to-real FFTW filters and incorporate the changes detailed above. Provide some &#39;real world&#39; examples, implementing at least one common use case for FFT in Image processing. </p><p> <strong>Requests for additional information from authors:</strong><br /></p><p><strong>Additional Comments:</strong><br />It&#39;s suggested that the source code provided be copied into the Insight source tree for building and testing. For the purposes of a journal submission, a standalone project that can be built using an already-installed ITK would be a better choice. If the code passes review it can be copied into the Insight source tree one time. </p>", "review_id": 437}], "publication_id": 128},
{"reviews": [], "publication_id": 129},
{"reviews": [], "publication_id": 130},
{"reviews": [{"date": "07-10-2008", "author": {"author_id": 918, "author_email": "adzyubak@gmail.com", "author_lastname": "Dzyubak", "author_firstname": "Oleksandr"}, "content": "<p><strong>Summary:</strong><br /> The author provides a new ITK filter for the automatic image segmentation. The filter is fast and suitable for the dominant background pixel environment.<br /> <br /> <strong>Evidence:</strong><br /> The author provides the source along with input/output images thus the work could easily be validated.</p><p> <br /> <strong>Open Science:</strong><br /> The work follows the Open Science spirit. The author does provide the both source code and images.<br /> <br /> <strong>Reproducibility:</strong><br /> The reviewer was easily able to reproduce the authors&#39; work. After downloading the code, the compilation process went without any problems and the reviewer did not experienced any problems with running the executable either. It just worked as it was supposed to.<br /> <br /> <strong>Use of Open Source Software:</strong><br /> The author did use Open Source Software and the code was contributed as the Open Source package too.<br /> <br /> <strong>Open Source Contributions:</strong><br /> The author does provide the code in the form that allows to easy compile and use it. Since this technique falls into the automatic family, the only time the reviewer spent is for downloading and compiling. Afterwards it just worked.</p><p> <br /> <strong>Code Quality:</strong><br /> The author provides the source code which easy to read. The reviewer used this code on Linux (Debian, Etch and Lenny) and UNIX(FreeBSD 6.3) platforms with gcc 3.4.6, gcc 4.1.2, and gcc 4.2.3 and did not experience any problems. The code runs very fast. On a laptop with Debian-Etch, P4 1.7GHz CPU, and 2GB, using as much as 20 iterations, it takes about one minute to process the 565x440x100 Int16 image. The code follows a modern coding style and the ITK rules so the reviewer would recommend this submission to be included to the ITK lib. </p><p> <br /> <strong>Applicability to other problems:</strong><br />Since the filter is automatic, very fast, and does not require too much hardware resources, it can be used to routinely process sets of large similar images in the environment with dominant background pixels. Examples could be porous material or tubular (scanned alone) studies.<br /><br /> <br /> <strong>Additional Comments:</strong><br /> The author provides a utility which could be used for the initial input parameter evaluation that is very handy. After the input parameters for a particular image set is found, it could be hard coded into a program which afterwards makes the code running fully automated over this set of images.</p>", "review_id": 701}, {"date": "11-14-2006", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<p><strong>Summary:</strong><br />The author has implemented a method for thresholding images which contain mostly background.&nbsp; The premise is that a user can not look at the histogram in the usual sense (i.e. searching for one or more modes), because the histogram that consists mostly of background doesn&#39;t fit that profile.&nbsp; This iteratively changes the threshold to try and find a better segmentation.<br /><strong>&nbsp;</strong></p><p><strong>Hypothesis:</strong><br />Not Applicable</p><p><br /><strong>Evidence:</strong><br />No evidence of utility is provided.&nbsp; In fact, this is my only issue. I appreciate the simplicity of the submission, but there is no reference to the method and its applications. I am not proposing that the&nbsp;method be validated for a particular application in this submission, but a little more time (and a reference or two) needs to be added to give background on the method.</p><p><br /><strong>Open Science:</strong><br />All good</p><p><br /><strong>Reproducibility:</strong><br />It is a fully deterministic algorithm and should be easy to reproduce from the code.&nbsp; The text doesn&#39;t provide enough detail to reproduce the method.</p><p><br /><strong>Use of Open Source Software:</strong><br />ITK</p><p><br /><strong>Open Source Contributions:</strong><br />Usable</p><p><br /><strong>Code Quality:</strong><br />Fine</p><p><br /><strong>Applicability to other problems:</strong><br />Probably</p><p><br /><strong>Suggestions for future work:</strong></p><p><br /><strong>Requests for additional information from authors:</strong><br />Please add the references and theoretical disc ussion.</p><p><br /><strong>Additional Comments:</strong></p><p>&nbsp;</p>", "review_id": 435}], "publication_id": 132},
{"reviews": [], "publication_id": 133},
{"reviews": [], "publication_id": 134},
{"reviews": [], "publication_id": 137},
{"reviews": [], "publication_id": 138},
{"reviews": [], "publication_id": 139},
{"reviews": [], "publication_id": 140},
{"reviews": [], "publication_id": 141},
{"reviews": [], "publication_id": 142},
{"reviews": [{"date": "02-07-2008", "author": {"author_id": 171, "author_email": "rupert.brooks@gmail.com", "author_lastname": "Brooks", "author_firstname": "Rupert"}, "content": "<p><strong>Summary:</strong><br />The paper describes a class that supports the composition of transforms for the image resampling task. It does not support the registration task. It can handle an arbitrarily long chain of transforms.</p><p><strong>Evidence:</strong><br />A program is provided to demonstrate the class. However, no input or expected output was provided. </p><p><strong>Open Science:</strong><br />The paper adheres to the principles of open science.</p><p> <strong>Reproducibility:</strong><br />I compiled and ran the code without difficulty. In order to test it, i had to modify the code slightly to register the transforms that i used in my input file with the transform factory. I tried some simple test cases and it worked. I only tried in 2D, as the example program is written for that case. </p><p> <strong>Use of Open Source Software:</strong><br />The authors use ITK and CMake</p><p> <strong>Open Source Contributions:</strong></p><p>The contribution is open source.</p><p><strong>Code Quality:</strong><br />The class is somewhat incomplete. Get/Set parameters should be provided, at a minimum. The Get Jacobian method is flawed. No testing code was provided.</p><p> <br /> <strong>Applicability to other problems:</strong><br />This has wide applicability as compound transforms arise frequently in image processing. Unfortunately, the class is somewhat incomplete, since it does not support the registration framework, or get/set parameters. This limits its usefulness as is.</p><p><strong>Suggestions for future work:</strong><br />Future work could clearly be to combine this with the other paper on this topic, the combination transform. It would be very nice to handle the Jacobian and parameters properly so that it could be used in the registration framework. </p>", "review_id": 641}, {"date": "02-27-2008", "author": {"author_id": 762, "author_email": "tomash.kazmar@seznam.cz", "author_lastname": "Kazmar", "author_firstname": "Tomas"}, "content": "<p><strong>Summary:</strong><br />Composition of transformations. ITK still does not have any unified means of<br />transformation composition (or adition), the author tries to fill in this hole.<br /><br /><strong>Hypothesis:</strong><br />Non Applicable<br /><br /><strong>Evidence:</strong><br />Non Applicable<br /><br /><strong>Open Science:</strong><br />All source code and details needed are provided.<br /><br /><strong>Reproducibility:</strong><br />I have compiled and run the code. It would be fine if there were test images<br />and transform files prepared from the author to simplify the first testing.<br /><br /><strong>Use of Open Source Software:</strong><br />Only ITK is used.<br /><br /><strong>Open Source Contributions:</strong><br />With my setup of ITK (only an ITK build) it was impossible to configure the<br />project. Provided CMakeLists.txt uses a LOADPACKAGE macro from IJMacros.txt<br />which fails to include UseITK.cmake correctly. This is caused by the fact<br />it tries to include ITK_INCLUDE_DIR which points to non-existing directory<br />and not ITK_USE_FILE. To compile remove first part of the<br />IF(${Package}_INCLUDE_DIR) block.<br /><br /><strong>Code Quality:</strong><br />Source code is clear and simple as it should be. The only error, as pointed out<br />by another reviewer, is that GetJacobian() implementation is incorrect.<br /><br /><strong>Applicability to other problems:</strong><br />An improved version of this class could be used for many tasks as well as any normal transform.<br /><br /><strong>Suggestions for future work:</strong><br />This class lacks methods to enable using it with registration which is a major<br />drawback. Jacobian computation must be corrected and methods to access to<br />parameters added.<br /><br />I think the way this class stores transforms (a list of transforms) is better<br />than in another IJ entry CombineTransform (a pair of transforms). Maybe a<br />AddTransforms(ListType) method can be added to simplify the usage with<br />TransformReader.<br /><br /><strong>Requests for additional information from authors:</strong><br />None.<br /><br /><strong>Additional Comments:</strong><br />As suggested in itk-users mailing list, a merge of SerialTransform and<br />CombineTransform classes that removes shortcommings of both CombineTransform<br />and SerialTransform would be ideal.<br /><br />An option to specify which parameters are fixed or not, and therefore which can<br />be optimized would be useful.</p>", "review_id": 646}, {"date": "02-14-2007", "author": {"author_id": 551, "author_email": "s.klein@erasmusmc.nl", "author_lastname": "Klein", "author_firstname": "Stefan"}, "content": "<p><strong>Summary:</strong><br />The paper describes&nbsp;a class to combine Transforms by means of composition. This is useful. The transform is not meant&nbsp;to&nbsp;be used in the registration framework, as a transform that is optimised.&nbsp;It&nbsp;can be used&nbsp;to resample&nbsp;an image for example. </p><p>This is my first review for the Insight Journal. I apologise if it doesn&#39;t conform to the standards/rules of reviews.</p><p><strong>Hypothesis:</strong><br />Non Applicable</p><p><strong>Evidence:</strong><br />Non Applicable<br /><br /><strong>Open Science:</strong><br />Non Applicable</p><p><strong>Reproducibility:</strong><br />I did not try to compile or run the code</p><p><strong>Use of Open Source Software:</strong><br />ITK</p><p><strong>Open Source Contributions:</strong><br />All necessary code is provided, along with a clear example of usage.</p><p>The paper has quite some overlap with another paper (coauthored by me), 2006-January-June, Combining Transforms in ITK, which&nbsp;describes the CombinationTransform. The advantage of the&nbsp;CombinationTransform is that it supports the registration framework (it implements the Get/SetParameters method) and that it also supports Addition of transforms, instead of Composition. The SerialTransform is however more easy in use, since it accepts more than two&nbsp;transforms. With the CombinationTransform you can set one InitialTransform, which could be again a CombinationTransform; so you need to set the transforms recursively. In the SerialTransform there is simply a list of transforms.</p><p><strong>Code Quality:</strong><br />The code is easy to read. I personally do not like that all function implementations are included the header. I have a few comments:</p><p>- The class provides a method to add transforms to the transform list, but not to clean the transform list. A kind of Initialize() method would be useful.</p><p>- GetInverse could be implemented.</p><p>- The m_TransformList is declared as&nbsp;&quot;private&quot;. I would suggest making it protected, which would allow inheriting classes to provide additional methods to set/get the transforms, or implement&nbsp;the Set/GetParameters,&nbsp;or GetInverse() methods.</p><p>- The implementation of GetJacobian is incorrect. It seems that the author had the &quot;spatial jacobian&quot; in mind. dT/dx, instead of the derivative with respect to the transform parameters, which it should be. Like this it would probably even result in errors, since at line 137-140 the m_Jacobian element (dim,dim) is accessed, while the size of the m_Jacobian is initialised as (dim,0) in the itk::Transform::constructor. Since the Set/GetParameters are not supported by this class, the GetJacobian is useless, I think.</p><p><br /><strong>Applicability to other problems:</strong><br />Non Applicable</p><p><strong>Suggestions for future work:</strong><br />Combining the CombinationTransform and the SerialTransform in one class that has the advantages of both.</p><p><strong>Requests for additional information from authors:</strong><br />none</p><p><strong>Additional Comments:</strong><br />none</p><p>&nbsp;</p>", "review_id": 457}], "publication_id": 143},
{"reviews": [], "publication_id": 144},
{"reviews": [], "publication_id": 145},
{"reviews": [], "publication_id": 146},
{"reviews": [], "publication_id": 147},
{"reviews": [{"date": "08-27-2007", "author": {"author_id": 310, "author_email": "mathieu.malaterre@gmail.com", "author_lastname": "Malaterre", "author_firstname": "Mathieu"}, "content": "<p><strong>Summary:</strong><br />How to user ITK when dealing with 4D dataset<br /> <br /> <strong>Reproducibility:</strong><br /> [Did you reproduce the authors&#39; work?</p><p>yes<br /> Did you download their code? Did you compile it? Did you run it?</p><p>Compilation went fine on linux debian/gcc 4.2 (some warnings). It did run fine.</p><p><br /> Did you managed to get the same results that they reported?</p><p>I did get the exact same results</p><p> Were there information missing from the paper, that was necessary for you to reproduce the work? Suggest improvements that will make easier for future readers to reproduce this work.</p><p>Paper is cristal clear.</p><p> <br /> <strong>Open Source Contributions:</strong><br />Author did provide the source code. It is fairly easy to read.</p><p> <br /> <strong>Code Quality:</strong><br />The code is simple and fairly well written.</p><p>What need to be done for inclusion in ITK:</p><p>- Add concept checking (Input image is 4D, output is 3D)</p><p>- The filter is describe as being multithreaded in the documentation, but implement GenerateData in the txx file (single threaded version). The filter needs to be rewritten to implement the correct threaded version. This is highly important for such massive amount of data (4D dataset).</p><p> - Fix all the warnings</p><p><br /> <strong>Applicability to other problems:</strong><br />The filter is very generic and can be used in multiple situation involving most actual data extraction from 4D dataset.<br /> <br /> <strong>Suggestions for future work:</strong></p><p>See code quality</p><p><br /> <strong>Additional Comments:</strong><br />I would highly urge the community to push this filter in ITK for the next release. </p><p>&nbsp;</p><p>The document also adress a current issue in ITK to deal with 4D dataset and DICOM. Most manufacturer are providing 4D dataset for MR as a set of 2D images. Unfortunately ITK ImageSeriesReader are only able to reader N into N+1 image. Whereas we would need a N into N+2 ImageSeriesReader.&nbsp;</p><p>&nbsp;</p>", "review_id": 538}], "publication_id": 148},
{"reviews": [], "publication_id": 149},
{"reviews": [], "publication_id": 150},
{"reviews": [{"date": "12-13-2007", "author": {"author_id": 723, "author_email": "gareth.price@physics.cr.man.ac.uk", "author_lastname": "Price", "author_firstname": "Gareth"}, "content": "<strong>Summary:</strong><br /> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\">The author has developed an extension of WrapITK that enables the generation of .NET wrappers for ITK classes via CMake. The wrapped classes can then be directly called from CLR languages. C# examples are included in the source code and discussed in the paper.</p> <strong>Hypothesis:</strong><br /> <p class=\\\"MsoNormal\\\">Non applicable.</p> <br /> <strong>Evidence:</strong><br /> <p class=\\\"MsoNormal\\\">The author supplies all source code for the build of the wrappers as well as source code for the C# examples that are quoted in the paper.</p> <strong>Open Science:</strong><br /> <p class=\\\"MsoNormal\\\">As stated above, all source code is provided, including examples. The images used in the examples are also included in the code bundle.</p> <strong>Reproducibility:</strong><br /> <p class=\\\"MsoNormal\\\">Rather than use the binaries provided, I built the wrappers using CMake (v2.4 patch 7) and Visual Studio 2005 (v2.0.50727 SP1), following the instructions in Section 3.2 of the paper. I managed to build the managed libraries but in my case I needed to include two extra (small) steps in the process before successful compilation. Following step 7 (opening the ManagedITK.sln solution) and before step 8 (building) I also needed to:</p> <p><em>7a. Resolve #using Dependencies:</em> The #using compiler directive needs to be told where the ManagedITK.Common.dll is. Point this to the correct directory by way of the property pages Project-&gt;Properties then Configuration Properties-&gt;C/C++-&gt;General and fill in the Resolve #using References field.</p> <p><em>7b. Set the include directory:</em> The location of the include directories are set relatively. These need to be set explicitly (e.g. C:\\\\\\\\ITK\\\\\\\\Utilities\\\\\\\\vxl\\\\\\\\core\\\\\\\\vnl instead of \\\\\\\\Utilities..). This can be set in the property pages (see 7a above) Configuration Properties-&gt;C/C++-&gt;General-&gt;Additional Include Directories.</p> <p>With regard to the examples, without any alteration they all built OK, however, when run they failed to load the ManagedITK libraries and failed. I do not write in C# and I think that this is a problem that could be easily solved given a little more experience of the language. Writing in C++/CLI, the examples, which are clearly explained in the paper, are easily converted and I have had no problems in using ManagedITK from this environment.<br /><br /> <strong>Use of Open Source Software:</strong></p><p>The author produces .NET wrappers for ITK using CMake.<br /> <br /> <strong>Open Source Contributions:</strong><br /> </p><p class=\\\"MsoNormal\\\">All source code is provided, as are binaries. The build process is well documented in the paper and required only minor modifications in my case (see Reproducibility section above).</p><strong>Code Quality:</strong><br /><p class=\\\"MsoNormal\\\">The examples provided are well documented both in the paper and throughout the source and concisely summarize the use of the wrapped classes.</p> <p class=\\\"MsoNormal\\\">I am not experienced in the use of WrapITK, or particularly so with CMake, and so don&rsquo;t feel qualified to comment on the coding relating to these aspects of the project. However, it is important to note that as a non-expert, I was able to create the wrappers from the instructions provided with little hassle (see Reproducibility above).</p> <p><strong>Applicability to other problems:</strong><br /> </p><p class=\\\"MsoNormal\\\">I feel that a well developed and validated .NET version of ITK would be very welcome. Although there will inevitably be, as acknowledged by the author in the paper, performance loss when developing applications that require managed to native transitions, the ability to rapidly develop GUI applications is very appealing. The author also includes, in Section 2, a list of the pros and cons of using managed over native code in order to enable informed choice of programming language.</p><strong>Suggestions for future work:</strong><br /><p class=\\\"MsoNormal\\\">In order to get the most from managed ITK, I feel that it is important to be able to interface smoothly and efficiently to managed VTK. Indeed the author points out that this may be used in Section 5 - FAQ. To this end it would be useful for the interface classes ImageToVTKImageFilter and vtkImageToImageFilter to be included in the wrapping.</p> <p>It would be nice if all of the ITK functionality were to be available in the managed environment (in Section 2 under the list of disadvantages the author lists those object not supported). Other issues are also highlighted in the paper by the author for future attention (e.g. location of the managed/native interface to allow for optimised iterative performance).<br /><br /> <strong>Requests for additional information from authors:</strong><br /> </p><p class=\\\"MsoNormal\\\">I think that a very useful addition to the project would be an expanded explanation of the wrapping procedure (at the moment in the FAQs under &ldquo;How do I wrap an external project&rdquo;). It would be nice if the structure of the CMake files and the effect of the various parameters therein were explicitly stated. </p> <p>Obviously the greater the knowledge of WrapITK and CMake the reader posses, the more sense this section will make. However, a detailed walk through of the wrapping of a class would, I feel, make the process much more accessible to the non-expert reader.<br /><br /> <strong>Additional Comments:<br /></strong><br />N/A<br /> <br /> </p>", "review_id": 631}], "publication_id": 151},
{"reviews": [], "publication_id": 152},
{"reviews": [], "publication_id": 153},
{"reviews": [{"date": "09-26-2007", "author": {"author_id": 168, "author_email": "torsten@synapse.sri.com", "author_lastname": "Rohlfing", "author_firstname": "Torsten"}, "content": "<p><strong>Summary:</strong><br />This submission provides an implementation of a diffeomorphic nonrigid demons registration algorithm. It comes with a stand-alone command line tool that provides many useful options and is fit for production use.<br /> </p><p><strong>Evidence:</strong><br />The authors provide test images.<br /> </p><p><strong>Open Science:</strong><br />Source code and test data are provided.<br /> </p><p><strong>Reproducibility:</strong><br />I have not tested the tool with the data provided by the authors. I have, however, run extensive tests on my own data in a longitudinal deformation-based morphometry study. I find the core algorithm to be very efficient and about as accurate as the original demons algorithm. I was also able to confirm that the produced transformations are essentially diffeomorphic. There occasionally&nbsp; appear to be small fractions of pixels with negative Jacobians, but this seems mostly connected to almost-folding input deformation fields that I sometimes provide to the algorithm.<br /><br /> <strong>Use of Open Source Software:</strong><br />Uses ITK.<br /> <br /> <strong>Open Source Contributions:</strong><br />Source code is provided. Compiles successfully out of the box using current CVS version of ITK.</p><p> <strong>Code Quality:</strong><br />The code quality is excellent. The code appears to conform with ITK coding style and is virtually fully documented. The bundled command line tool provides options for different update rules, multi-resolution registration, initial deformation fields, and intensity histogram normalization.</p><p> <strong>Applicability to other problems:</strong><br />n/a<br /> <br /> <strong>Suggestions for future work:</strong><br />n/a<br /> <br /> <strong>Requests for additional information from authors:</strong><br />n/a<br /> <br /> <strong>Additional Comments:</strong><br />I would strongly advocate adding this contribution to ITK as soon as possible. The nonrigid registrations in the toolkit are a little outdated right now and could really use some newer algorithms. In particular diffeomorphic registration has become a hot topic recently, and it would be great to have a diffeomorphic registration algorithm available in ITK, in particular one that is as efficient as this one. I would also advocate including the command line tool that comes with the software in the ITK source tree. </p><p>&nbsp;</p>", "review_id": 491}, {"date": "09-11-2007", "author": {"author_id": 368, "author_email": "cleary@georgetown.edu", "author_lastname": "Cleary", "author_firstname": "Kevin"}, "content": "<span><strong><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Summary:</span></strong><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br />In this paper a modified version of Thirion&rsquo;s Demons Registration algorithm is presented.As authors mention this is a companion paper to the paper </span><font face=\\\"Times New Roman\\\"><span style=\\\"font-size: 11pt\\\">&ldquo;Non-parametric diffeomorphic image registration with the demons algorithm&rdquo; published in MICCAI 2007 with the purpose of sharing the source code with the community. Instead of presenting in detail the algorithm they insist more on the ITK implementation issues.To understand the method and to see the evaluation of the algorithm the reader has to read also the initial paper.</span></font><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><br /><strong>Hypothesis:</strong><br /></span><span style=\\\"font-size: 10pt; font-family: CMR10\\\"><font face=\\\"Times New Roman\\\">Lie group structure on diffeomorphic transformations<span>&nbsp; </span>can be used in combination with some optimization tools on Lie groups to derive our diffeomorphic image registration algorithm.</font></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><br /><strong>Evidence:</strong><br />They provide the source code with only one 128x128 two examples 2D example.I couldn&rsquo;t execute the code on Visual Studio 8.0 because the file </span><span style=\\\"color: maroon; font-family: &#39;Courier New&#39;\\\"><font size=\\\"2\\\">getopt.h</font></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"> was missing.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoPlainText\\\"><br /><strong>Open Science:</strong><br />They provide the full source code based on ITK and they provide one data set.The actual paper contain no images only general description of the algorithm and details on ITK implementation.The original MICCAI paper contains images and results based on different data that is not available with this source code.</p><br /><strong>Reproducibility:</strong><br />Did not run on Microsoft Visual Studio 8.0<br /><br /><strong>Use of Open Source Software:</strong><br />Their implementation is based on ITK.Actualy they are also one of the important contributors of the Demons registration in ITK.This algorithm is only an extension to the current ITK framework</span></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><strong>Open Source Contributions:</strong><br />The code is well written and it contains reasonable comments inside the code</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><strong>Code Quality:</strong><br />Seems it doesn&rsquo;t compile on Visual Studio 8.0 because of an utility file:</span><span style=\\\"color: maroon; font-family: &#39;Courier New&#39;\\\"><font size=\\\"2\\\"> getopt.h</font></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"> </span><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoPlainText\\\"><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">The files are following ITK coding style and it is easy to read<br /><br /><strong>Applicability to other problems:</strong><br /><br /><strong>Suggestions for future work:</strong><br /><br /><strong>Requests for additional information from authors:</strong><br /><br /><strong>Additional Comments:</strong></span></p><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">This review was written by Teo Popa in our laboratory and posted by Kevin Cleary.</span>", "review_id": 561}], "publication_id": 154},
{"reviews": [{"date": "09-11-2007", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<p>&nbsp;</p><p><strong>Summary:</strong></p><p>This paper contributes a filter that generates a Wavelet decomposition of a function defined on the unit sphere, and a filter that recompose a function from a set of wavelet coefficients<br /> </p><p> <strong>Open Science:</strong></p><p>This paper seems to be a great example of Open Science.</p><p>The material needed for replicating the work seems to be provided by the athors.</p><p>However, compilation problems and run time error made a bit harder to verify whether the material provided was complete or not.<br />After the compilation error were dealt with, it was possible to use the material easily and to verify the results presented by the authors. </p><p> <br /><br /> <strong>Reproducibility:</strong></p><p>I was able to compile the code without mayor problem.</p><p>Only had to fix three warning due to lack of explicit casting from double to int and unsigned long:</p><p>The changes were made in the following lines: </p><p>itkSWaveletSource.txx:308: unsigned long nOfVerts = static_cast( 10.0 * pow(4, i ) + 2 ); // for icosahedron.<br />itkSWaveletSource.txx:309: unsigned long nOfNewVerts = static_cast( 10.0 * pow(4,i+1) + 2 ); // for icosahedron.<br />itkSWaveletSource.txx:841: int resolution = static_cast( 1 + floor(log((nOriVerts-2)/10)/log(4)) );</p><p>I was surprised to find that four of the five tests were commented out in the CMakeLists.txt file.</p><p>&nbsp;</p><p>The only enabled test crashes at run time with the following message:</p><p> testing task 5:<br /> step 1.1 we have a scalar function defined on the vertexes of the finest mesh. Here we just use the z-coordinates as the function.<br /> step 1.2 Do a wavelet transform of the function and we get wavelet coefficients.<br /> step 1.3 Do a wavelet inverse transform from the coefficients to reconstruct the original function.<br /> step 1.4 Compare the original functin with the reconstructed function to show the fedelity of the transform.<br /> terminate called after throwing an instance of &#39;std::bad_alloc&#39;<br /> what(): St9bad_alloc<br /> zsh: abort ./itkSWaveletTest5</p><p>When enabling the other tests, they failed to compile.</p><p>IJ-Spherical_Wavelet_ITK_Filter.1/itkSWaveletTest/itkSWaveletTest.cxx:146: error: expected unqualified-id before &lsquo;else&rsquo;<br />IJ-Spherical_Wavelet_ITK_Filter.1/itkSWaveletTest/itkSWaveletTest.cxx:150: error: expected declaration before &lsquo;}&rsquo; token<br />IJ-Spherical_Wavelet_ITK_Filter.1/itkSWaveletTest/itkSWaveletSource.txx: In member function &lsquo;void itk::SWaveletSource::SetWaveletCoefficientAtScale(int, int, double) [with TOutputMesh = itk::Mesh &gt;]&rsquo;:</p><p>The error seemed to arise from a copy/paste mistake.</p><p>After fixing it, the code compiled fine.</p><p>&nbsp;</p><p>---</p><p>It was pretty easy to reproduce the results of Figure 2, following the clear instructions on page 6 of the paper.</p><p>The visualization of each one of the different sphere resolutions matched the images in Figure 2.</p><p> -- </p><p> The paper fails to mention that the code of section 2.3 is available in the test</p><p>itkSWaveletTest2.cxx </p><p>This test prints out the reconstruction error for the level of resolution provided by the in the command line.</p><p>The errors reported are indeed in the range of 10^-6, as the paper indicates:</p><p>Resolution Error </p><p> 1 ==&gt; 1.11022e-16<br /> 2 ==&gt; 2.18535e-19<br /> 3 ==&gt; 2.22045e-16<br /> 4 ==&gt; 1.11022e-16<br /> 5 ==&gt; 3.33067e-16<br /> 6 ==&gt; 3.33067e-16<br /> </p><p>&nbsp;---</p><p>&nbsp;In section 2.4 It should probably state that the corresponding source code is in the example</p><p>&nbsp;itkSWaveletTest.cxx</p><p>&nbsp;That being, said,</p><p>by running this example I got the following files:</p><p>&nbsp;reconstructedFnKWVisuChanged.txt<br />reconstructedFnKWVisu.txt<br />reconstructedFn.txt<br />ScalingFnKWVisu.txt</p><p>but couldn&#39;t load them in KWMeshVisu because this appication expects files with extension .meta</p><p>or .vtk.&nbsp; Simply renaming the files to change the extension didn&#39;t allowed me to load the files.</p><p>&nbsp;It would have been useful to have simple instructions on how to load the files in KWMeshVisu.</p><p>I had to add to the code the following line:</p><p>mySphereMeshSource-&gt;WriteMeshToMetaFile(&quot;Mesh.meta&quot;,n);</p><p>To save the Mesh itself into a file, and then be able to use KWMeshVisu.</p><p>From KWMeshVisu I loaded the &quot;Mesh.meta&quot; file as&nbsp; a mesh, and then loaded&nbsp; the files as 1D scalar properties</p><p>reconstructedFnKWVisuChanged.txt<br />reconstructedFnKWVisu.txt<br />reconstructedFn.txt<br />ScalingFnKWVisu.txt<br />WaveletFnKWVisu.txt</p><p>&nbsp;</p><p>&nbsp;The paper fails to mention that the mesh files are along with the source code in a meta directory.</p><p>&nbsp;The CMakeLists.txt file could have been formated for making the different figures a test by using the ADD_TEST command. In that way these different usage details could have been provided explicitly.</p><p>&nbsp;</p><p>----&nbsp;</p><p>&nbsp;In section 3, the authors refer to a &quot;filteringShape.cxx&quot; file that is not included with the contribution. </p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p> <strong>Use of Open Source Software:</strong></p><ul><li>The authors used the Insight Toolkit (ITK), <br /></li><li>The Visualization Toolkit (VTK) <br /></li><li>and suggested the use of a previous IJ paper (KWVisu) for visualizing the mesh results: http://insight-journal.org/dspace/handle/1926/220</li></ul><p>&nbsp;</p><p> <strong>Open Source Contributions:</strong></p><p>The authors provide their source code, and the paper provide examples on how to use it.</p><p>Unfortunately only one of the examples is enabled for compilation. </p><p>&nbsp;</p><p><strong>Code Quality:</strong><br /> [If the authors provided their source code: Was the code easy to read? Did they use a modern coding style? Did they rely on non-portable mechanism? Was it suitable for multiple-platforms?]<br /> <br /> <strong>Applicability to other problems:</strong></p><p> [Do you find that the authors methods can be applied to other image analysis problems? Suggest other disciplines or even other specific projects that could take advantage of this work]<br /> <br /> <strong>Suggestions for future work:</strong><br /> [Suggest to authors future directions for improving their methods, or other domains from which they could learn technique that could help them advance in their research.]<br /> <br /> <strong>Requests for additional information from authors:</strong><br /> [Did you find that information was missing from the paper? Maybe parameters for running the tests? Maybe some images were missing? Would you like to get more details on how the diagrams, or plots were generated?]<br /> <br /> <strong>Additional Comments:</strong><br /> [This is a free-form field]<br /> <br /> </p>", "review_id": 554}, {"date": "07-26-2007", "author": {"author_id": 322, "author_email": "agouaillard@gmail.com", "author_lastname": "Gouaillard", "author_firstname": "Alexandre"}, "content": "<strong>Summary:</strong><br /><p>This paper is an implementation of the original spherical wavelet paper by Swelden. The main goal is to be able to do analysis of (genus 0 = parameterizable on the sphere) shapes. It is becoming a standard approach when coupled with the spherical parameterization for brain surface analysis for example.<br /> <br /> <strong>Hypothesis:<br /></strong><br /><br /><br /> <strong>Evidence:</strong><br /><br /> <strong>Open Science:</strong><br />The paper is clear and explain with sufficient detail the implementation. The implementation seems to be as close as possible to the paper.</p><p><strong>Reproducibility:</strong><br />I downloaded the code, and comfigure it with for the following configuration:<br />cmake 2.4.6, Win32 on top of win64 (XP) MSVC++ 2005 (32bits).</p><p>I needed to apply the following minor changes for the code to compile:<br />itkSWaveletSource.txx:308,309<br />&lt; unsigned long nOfVerts = 10*pow(4,i) + 2; // for icosahedron.<br />&lt; unsigned long nOfNewVerts = 10*pow(4,i+1) + 2; // for icosahedron.<br />---<br />&gt; unsigned long nOfVerts = 10*pow(4.0,(int)i) + 2; // for icosahedron.<br />&gt; unsigned long nOfNewVerts = 10*pow(4.0,(int)i+1) + 2; // for icosahedron.<br />itkSWaveletSource.txx:841<br />&lt; int resolution = 1 + floor(log((nOriVerts-2)/10)/log(4));<br />---<br />&gt; int resolution = 1 + floor(log((nOriVerts-2.0)/10.0)/log(4.0));</p><p>Thedefault example did not work. It seems to exhaust the memory trying to read a file:<br />itkSWaveletTest5.cxx:60 getScalarFn(&quot;x10.txt&quot;, oriF);<br />itkSWaveletTest5.cxx:99 scalarFn.push_back(a);<br />[...]<br />Unhandled exception at 0x7d4e2366 in itkSWaveletTest5.exe: Microsoft C++ exception: std::bad_alloc at memory location 0x0139fb6c..</p><p>It came from my building in a separate tree. The example assumes that you are running it at the sme level as the files. Moreover, the getScalarFn that reads from disk does not check if the file was found and is open before it tries to read from it.<br />Here are the corresponding fixes:<br /> :60,61:<br />getScalarFn(&quot;../x10.txt&quot;, oriF);<br />mySphereMeshSource-&gt;SetScalarFunctionWithSphere( &quot;../para10.meta&quot;, oriF);</p><p>:92,105:<br />void getScalarFn(char* scalarFileName, std::vector&lt; double &gt;&amp; scalarFn)<br />{<br />&nbsp; std::ifstream f(scalarFileName);<br />&nbsp; if( f.fail( ) )<br />&nbsp;&nbsp;&nbsp; {<br />&nbsp;&nbsp;&nbsp; // print an error here<br />&nbsp;&nbsp;&nbsp; exit( EXIT_FAILURE );<br />&nbsp;&nbsp;&nbsp; }<br />&nbsp; double a;<br />&nbsp; while(!f.eof())<br />&nbsp;&nbsp;&nbsp; {<br />&nbsp;&nbsp;&nbsp; f&gt;&gt;a;<br />&nbsp;&nbsp;&nbsp; scalarFn.push_back(a);<br />&nbsp;&nbsp;&nbsp; }</p><p><strong>Use of Open Source Software:</strong><br />The filter is written on top of ITK.</p><p> <strong>Open Source Contributions:</strong><br />The paper is clear and explain with sufficient detail the implementation.</p><p><strong>Code Quality:</strong><br />As for the design, I love the work on the wavelet coefficients. Being able to access both the mesh and the corresponding wavelet at any level of decomposition is a great idea. It open the way to a lot of applications (compression, watermarking, any filtering, ...).</p><p>The code is not yet up to ITK standard: there seems to be a lot of commented out code. the debug and warning macro are not used (cerr is used instead) and it seems to have be written using arrays first. Some parts have been rewritten using stl (vector) but some parts still used arrays. Testing it through the web interface of KWStyle could help the authors enhance the style greatly (http://66.194.253.24/KWStyle/).</p><p>The types are hard coded, and ,as the author themselves admit, templating it depending on the mesh traits or on other arithmetic types would be great.</p><p>The code is written on top of itk::Mesh and thus must deal with a lot of shortcomings. The authors reimplement a pointToCell array and assume orientability, orientation consistency as well as 2-manifoldness. I&#39;m pretty sure the code would break if you use as input a sphere of which one triangle or more would be flipped inside-out. It would also be nice to check if the mesh is triangular first. I would recommand, if the author had the time, to rewrite it on top of an itkQuadEdgeMesh. One itkMeshToMeshFilter enforcing the orientation would still be need though. </p><p>It would be nice to have the subdivision part separated from the wavelet feature. We could think of a general 1 to 4 subdivision filter (abstract, topology only) with a set of functions implementing the geometrical behavior (new point function of old point + mask). That open the way to subdivision filters in ITK, as well as predictive filtering for wavelet compression, lazy wavelets and so on. </p><p><strong>Applicability to other problems:</strong><br />There is the direct problem the authors are addressing: (brain surface) shape analysis, but having access to the wavelet and to the inverse transform, you can think about almost any kind of filtering in wavelet space including:<br />- denoising (wavelet coefficient thresholding)<br />- compression,<br />- watermarking,<br />- optimization of active surface algorithms,<br />You can see those two pages for ideas:<br />http://www.creatis.insa-lyon.fr/~agouaillard/Research.htm<br />http://www.creatis.insa-lyon.fr/~valette/publis.htm </p><p><strong>Suggestions for future work:<br /></strong>- write a test suite to enforce the expected behavior, it would help reviewers make some experiments with the code and even add fonctionalities.<br />- template over meshtraits / arithmetic types.<br /> - rewrite on top of of QEMesh (much easier to code, much easier to maintain, faster)<br />- separate subdivision from wavelet<br />- would pluggable wavelet functions be too hard to code (I sincerely have no idea) ?<br /><br /> <strong>Requests for additional information from authors:</strong><br />I loved the paper.</p><p> <strong>Additional Comments:</strong><br />i&#39;d like to help the authors fix the problems, and even implement some of my recommendations.</p>", "review_id": 515}], "publication_id": 155},
{"reviews": [{"date": "09-02-2007", "author": {"author_id": 610, "author_email": "urschler@icg.tu-graz.ac.at", "author_lastname": "Urschler", "author_firstname": "Martin"}, "content": "<p><strong>Summary:</strong><br />In this paper a nonlinear image registration algorithm is described which uses a block matching strategy. The algorithm uses an entropy based similarity measure, i.e. it is suitable for inter-modality registration. The authors claim that the scheme is very fast due to the avoidance of an optimization step. Results are presented for registering a synthetically transformed 2D image of a person. <br /> <br /> <strong>Hypothesis:</strong><br /> </p><p> The authors claim that a nonlinear registration algorithm based on block matching is a very efficient way for registration. In their opinion many standard algorithms which require optimization of a certain kind are prone to difficult choices of parameter settings, lead to large run-times due to the optimization and are hard to parallelize. Further, they claim that methods based on so-called differential similarity measures (the second group of approaches for nonlinear registration) can be fast and accurate but in practice are complex to implement for inter-modality similarity measures, require a large number of iterations, require derivatives whose computation leads to smoothing and have problems with boundaries.</p><p> Starting from these problems and due to the fact that the MPEG standard performs block matching as well the authors propose that block matching is a well-suited nonlinear registration method. They claim that block matching is simple to formulate and implement, is numerically stable, easy to parallelize (i.e. suitable for hardware implementation), is robust against noise and requires only few parameters. </p><p><br /> <strong>Evidence:</strong></p><p>The authors categorization of nonlinear registration into global optimization, differential similarity measures and block matching schemes is in my opinion not very useful. To use the term global optimization in the context of nonlinear registration is dangerous. IMHO there are no reported global optimization techniques, since the parameter space of the nonlinear registration problem is far to large for that. All of the reported algorithms are local optimization based and require good initializations and pyramid schemes to work and to reach a local optimum as registration result. Further, to me it is not quite clear what is meant by methods based on differential similarity measures. If this is the Demons-like approach or the B-spline based approach, then they can also be categorized as optimization-based, since their formulation also seeks for a local optimum over a certain parameterization of the space of unknowns. </p><p> The claim that nonlinear registration algorithms are hard to parallelize is contradicted by the implementations of the algorithms in ITK and by another contribution of this workshop from Aylward et al. The speed differences could not be reproduced by the author of this review. Although the performance of the fast block matching scheme is a lot faster than e.g. B-spline, its run-time is similar to Demons on real-world 3D medical volumes. This fact can be seen from our own evaluation of the method in the evaluation paper we submitted to this workshop (Urschler et al). Last, the authors criticize standard algorithms for requiring derivatives leading to smoothing. Without knowing the exact details of the block matching scheme, I think that there are also some implicit assumptions in each block matching that lead to an implicit smoothing of the data. </p><p>It would be very useful if this paper would explain a little more of the details of the block matching scheme and if there would be a better explanation of the parameters that were used. </p><p><br /> <strong>Open Science:</strong><br /> </p><p>Source Code of their method and the output of their algorithm on the test image are provided for comparison. It would be easily possible to replicate the authors claims if the code would build.</p><p><br /> <strong>Reproducibility:</strong></p><p>I tried to reproduce the authors work directly under Windows using MSVC 8 compiler in the free edition. However, I didn&#39;t manage to compile the code since it has a hard-coded requirement to use ITK 2.8.1. I&#39;m using the current release of ITK (3.2) and didn&#39;t try to fix this problem. I suggest that this flaw to require exactly ITK2.8.1 should be replaced by requiring AT LEAST ITK 2.8 or higher! </p><p>So the direct reproduction of the algorithm&#39;s performance on the example 2d image was not possible. However, I took the code and put it into the evaluation framework which was contributed to this same workshop in Urschler et al. There the results for intra-modality registration using several synthetic data sets and a number of comparison measures on real-world 3D medical volumes are presented. The results are not very promising as can be seen from the numbers and the visual outcome. I understand that this contribution is an early work in progress. Note, that I used the same parameters as in the authors source code. It is also perhaps important to note that I am solely providing intra-modality data while the contribution claims to be an inter-modality algorithm due to the entropy based similarity measure. I do not see why it should not work on intra-modality data, however, this might be a possible problem and might not have been tested yet by the authors. I invite the authors to look at my wrapper class around their source code and check if I made any coding mistake. Further, they can reproduce my evaluation and perhaps fine-tune their algorithm to perform better on the 3D intra-modality data. </p><p><br /> <strong>Use of Open Source Software:</strong><br />Not Applicable<br /> </p><p><strong>Open Source Contributions:</strong><br />The source code is provided and easy to use as it is - if you plug it out of the contributed package (ITK 2.8 restriction). </p><p>&nbsp;</p><p><strong>Code Quality:</strong></p><p>The coding style of ITK is supported, the code is working under Windows MSVC 8 and Linux gcc 4.1 (64 bit). The authors claim in the paper that some refactoring is necessary to split the main class into modules. </p><p> <br /> <strong>Applicability to other problems:</strong></p><p>A working code could be applied to any nonlinear registration problem. </p><p><br /> <strong>Suggestions for future work:</strong></p><p>For future work a more thorough preparation of the related work might be interesting. Also there was a publication by Bostjan Likar and Franjo Pernus in 2001 in Image and Vision Computing (A hierarchical approach to elastic registration based on mutual information) who have shown a block matching related nonlinear registration scheme which would be interesting to compare to. Some of the claims that lead to the implementation do not sound convincing to me. Further work is necessary in the implementation of the algorithm and in testing it on real-world medical applications. </p><p>&nbsp;</p><p> <strong>Requests for additional information from authors:</strong><br />As I already mentioned a more detailed explanation of the algorithm and the parameters would be useful. Although one could look it up in the mentioned additional papers, it would be good to be a little more self-contained here. </p><p> <br /> <strong>Additional Comments:</strong></p><p>Fast block matching is an interesting direction however in this contribution its derivation and its advantages are not yet presented very well. Further, some additional evaluation of our own does not yet show the claimed key contributions. This might be an issue due to the work-in-progress state of the paper, however, the authors have yet to prove that. </p>", "review_id": 545}, {"date": "09-07-2007", "author": {"author_id": 197, "author_email": "richard.beare@ieee.org", "author_lastname": "Beare", "author_firstname": "Richard"}, "content": "<p><strong>Summary:</strong><br />The authors describe some implementation details of a block matching, mutual information, based scheme for non linear registration. Theoretical details of the scheme are not covered.<br /> <br /> <strong>Additional Comments:</strong><br />The previous reviewer has done a thorough job, and I agree with most of the comments. This paper would be much more useful if the theoretical aspects of the method and details of the deformation field were included. Evidence of applicability ot 3D images as well as images with more serious initial non-registration (i.e some form of rotation and translation rather than local distortion) would be more convincing.</p><p>Most significantly though the survey of previous related literature isn&#39;t thorough. The use of block matching in mpeg was noted, although I&#39;m not convinced it is particularly relevant since the aim in that application is compression. Block matching using MI and other metrics has been presented before - in particular:</p><p> S. Ourselin, A. Roche, G. Subsol, X. Pennec, and N. Ayache. <strong>Reconstructing a 3D Structure from Serial Histological Sections</strong>. <em>Image and Vision Computing</em>, 19(1-2):25--31 , January 2001. </p><p> S. Ourselin, C. Sattonnet, A. Roche, and G. Subsol. <strong>Automatic alignement of histological sections for 3D reconstruction and analysis</strong>. <em>Analytical Cellular Pathology</em>, 18(3):123, 1999 . </p><p>There is also a degree of similarity to the non linear registration of mni_autoreg (which isn&#39;t MI based)<br /> </p><p> DL Collins, CJ Holmes, TM Peters and AC Evans, <strong>Automatic 3D model-based neuro-anatomical segmentation</strong><em><strong>. </strong>Human Brain Mapping</em>, 3(3) p 190-208, 1995<br /> <br /> </p><p><strong>Conclusion:&nbsp;</strong></p><p>I think there are a number of deficiencies in the paper that need to be corrected. However the development of classes that support alternative registration approaches is very welcome. One of the reasons why block based schemes haven&#39;t received much attention in the registration field is the lack of publicly available implementations. Hopefully this code will be the start of such a set of classes.</p>", "review_id": 547}, {"date": "09-12-2007", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<p><strong>Summary:</strong><br />This paper presents an implementation of a block-matching registration algorithm suitable for performing deformable registration.<br /> </p><p>This contribution offers a great alternative to those involved in deformable-registration, and in particular those who have concerns with the computation time that these registration involved</p><p><br /> <strong>Hypothesis:</strong><br />N/A</p><p><br /> <strong>Evidence:</strong><br />N/A</p><p>&nbsp;</p><p><strong>Open Science:</strong></p><p>The paper is a good example of Open Science practices.</p><p>The authors provide all the material needed for reproducing their work:</p><ul><li>source code</li><li>input image data</li><li>tests and parameters<br /></li></ul><p> The paper clearly describes the principles of the method, has appropriate references to previous publications, and provide a clear the examples illustrating the result of the method.<br /><br /><br /> <strong>Reproducibility:</strong></p><p>It was easy to reproduce the work of the authors, thanks to the organized material they provided.</p><p>After downloading the code, only two changes were necessary (for me):</p><ol><li> Remove from their CMakeLists.txt file the requirement for ITK 2.8 (the code actually works fine with today&#39;s ITK CVS version - Sept 12 2007)</li><li>Comment out a concept check in itkVectorDivideImageFilter.<br /></li></ol><p>After these two changes, the code compiled fine.</p><p>The authors organized examples in Ctest, making it very easy to replicate their results.</p><p>By following the command that they configured in their test, it was straight forward to run the code with variations of the parameters<strong>.</strong></p><p><strong>Use of Open Source Software:</strong></p><p>The authors used the Insight Toolkit version 2.8, but the code still works fine with ITK CVS (Sept 12 2007).</p><p>They provide comments about improvements that could be made in existing ITK classes that they were using. Their source code contribution includes the modified version of these classes. <br /><br /> <br /> <strong>Open Source Contributions:</strong></p><p>The authors provided their source code.</p><p>The code was usable (after very minor modifications). </p><p>It took me 15 minutes to reproduce the work that the authors describe in the paper.<br /><br /> <br /> <strong>Code Quality:</strong></p><p>The code is well organized. They provide the a class that computes the registration. These class follow the ITK Coding style for the most part. Some editing will be needed to make it pass the KWStyle checking.</p><p>The use of NaN as part of the algorithm is a bit worrisome, since it is hard to anticipate how this will work on different platforms.</p><p> <br /> <strong>Applicability to other problems:</strong></p><p>The authors work can be applied to a wide range of problems.</p><p>Indeed their contribution should probably be split in to two or three different objects. In particular code that manages block-matching could be separated from the code that computes the Mutual Information metric. The authors are aware of this possibility and address it as an item for future work.</p><p> <br /> <strong>Suggestions for future work:</strong></p><p>Splitting the class into a block-matching manager and a selectable image metric will extend the range of problems where this code could be used.</p><p>Performing a comparison with other methods would have been interesting, but just form the anecdotal point of view. Since a fair comparison will require to demonstrate that the corrections performed by multiple algorithms are equivalent, and we know that the variety of parameter values that can be when executing a deformable registration method make difficult to establish what combination of parameters in method A should be equivalent to what other combination of parameters in method B. </p><p><br /> <strong>Requests for additional information from authors:</strong></p><p>It would have been interesting to run the algorithms for a variety of combinations of parameters.</p><p>Once you have the ADD_TESTS lines in your CMakeLists.txt file, exploring variations of the parameters is relatively easy.</p><p>For example, to play with the values of regularization and to show how they affect the final result.</p><p>It would have been interesting too to write out the deformation field. (to a metaimage for example), so it can be viewed with applications such as ParaView.</p><p>&nbsp;</p><p> <strong>Additional Comments:</strong></p><p>The file itkVectorDivideImageFilter.h line 179 has a concept check for &quot;OutputVectorDivisionOperatorCheck&quot;. The terms of this concept check don&#39;t seem to be defined. The lines of this concept check were commented out in order to be able to compile the code.</p><p> It is likely that the authors were developing and testing thei code using an ITK build where the concept checking was turned off. (CMake option).</p><p>&nbsp;</p><p> ----</p><p> Minor comment : Your files have TABS in some lines. You may want to set your editor to use 2 spaces instead of tabs.</p><p>&nbsp;</p>", "review_id": 565}], "publication_id": 156},
{"reviews": [{"date": "07-31-2007", "author": {"author_id": 322, "author_email": "agouaillard@gmail.com", "author_lastname": "Gouaillard", "author_firstname": "Alexandre"}, "content": "<p><strong>Summary:</strong><br />This paper introduce a database of MRI scans of the heart along with segmentations made both by experts and by the authors 4D watershed algorithm (described in a different paper).<br /> <br /> <strong>Hypothesis:</strong><br />Non Applicable<br /> <br /> <strong>Evidence:</strong><br />Non Applicable<br /> <br /> <strong>Open Science:</strong><br />Tha original datasets, along with the segmented results and source code are available from the authors&#39; webpage mentioned in the paper.<br /> <br /> <strong>Reproducibility:</strong><br />Non Applicable<br /> <br /> <strong>Use of Open Source Software:</strong><br />I did not check the code as it is not the purpose of this paper. <br /> <br /> <strong>Open Source Contributions:</strong><br /> See above.<br /><br /><strong>Code Quality:</strong><br />Non Applicable<br /> <br /> <strong>Applicability to other problems:</strong><br />I guess that availability of the data along with the segmented results is a good step toward Open Source, allowing others to try their algorithms against the same dataset and compare their results directly.<br /> <br /> <strong>Suggestions for future work:</strong><br />Authors could suggest users to upload their results and make a database of algorithms and their results on that kind of datasets. That kind of database becomes more and more interesting as the number of comparable results grows. </p><p> <strong>Requests for additional information from authors:</strong><br />Did you try anything else than linear interpolation to extend your neighborhood in time?<br />In your illustration of the results, the shapes seems pretty smooth. Smoothing the surfaces is known to have side effect (shrinking, modifying the spatial position of some points resulting in anatomical inconcsistency when several disconnected shapes are represented). Did you have such problem? If yes, how did you deal with them?</p><p> <strong>Additional Comments:</strong><br />This is off topic here but I feel like the algorithm paper lacks of illustrations.<br />Having data/src code/additional papers in a different location make the review difficult. I would suggest that the authors upload more material on IJ, or make a big tarball accessible from their webpage, instead of 4 to 5 different files. </p>", "review_id": 517}, {"date": "09-02-2007", "author": {"author_id": 610, "author_email": "urschler@icg.tu-graz.ac.at", "author_lastname": "Urschler", "author_firstname": "Martin"}, "content": "<p><strong>Summary:</strong><br />This paper presents an open-science segmentation evaluation database accompanied by evaluation criteria and two manual and an automatic reference segmentations for comparison. The segmentation is dedicated to cardiac MR images showing the left ventricle in 4D (3D+time). <br /> <br /> <strong>Hypothesis:</strong><br />NA<br /> <br /> <strong>Evidence:</strong><br />NA<br /> <br /> <strong>Open Science:</strong><br />The paper is an excellent example for the power of open-science. Unfortunately the link to download all contributed material does not work at the time of this writing, so this review will solely be based on looking at the paper (which I took from the MIDAS &amp; Kitware collection using the papers DSpace handle) and on the presented material on the accompanying webpage.<br /> <br /> <strong>Reproducibility:</strong><br />I did not reproduce the mentioned experiments or download any code.<br /> <br /> <strong>Use of Open Source Software:</strong><br />NA<br /> <br /> <strong>Open Source Contributions:</strong><br />As already mentioned I was not able to use any provided code.<br /> <br /> <strong>Code Quality:</strong><br />NA<br /> <br /> <strong>Applicability to other problems:</strong><br />The basic idea of providing evaluation databases and criteria along with some results from other methods for comparison is in the review authors opinion (and I dare to say also in the opinion of many more people in the medical imaging community) an extremely important one. Successes from other disciplines like computer vision (stereo reconstruction, multi-view 3D reconstruction -&gt; Middlebury) or pattern recognition (face recognition databases) prove this importance despite the additional legal, ethical and of course commercial problems such an effort has in the medical community. <br /> <br /> <strong>Suggestions for future work:</strong><br /> The only suggestion I currently can think of is to contribute this web-site to the list of open-science databases proposed in the workshop paper of Holms et al (Data, data everywhere). </p><p><br /> <br /> <strong>Additional Comments:</strong></p><p>Overall this paper is an important open-science contribution and IMHO should definitely be accepted for the workshop to further discuss its ideas. It is very well and clearly written, shows a good over-view of the related work, although there are some segmentation evaluation efforts like e.g. the VALMET project (Gerig et al @ MICCAI 2001) or Fenster and Chu (Evaluation of Segmentation Algorithms for Medical Imaging, IEEE-EMBS 2005) which could also be mentioned. One can of course think about the advantages and drawbacks of a watershed type segmentation to get the automatic results, but this is not the main point of this contribution. Overall very promising and I am looking forward to discussions at the workshop. </p>", "review_id": 546}, {"date": "09-11-2007", "author": {"author_id": 368, "author_email": "cleary@georgetown.edu", "author_lastname": "Cleary", "author_firstname": "Kevin"}, "content": "<p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Summary</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">Assessment of cardiac cine images is a challenging task.<span>&nbsp; </span>A standard reference database of images will improve evaluation of methods for these types of images.<span>&nbsp; </span>The authors provide a valuable open database both manual/automatic segmentation references.</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Hypothesis</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">n/a</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Evidence</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\">The paper is less about evidence to prove a hypothesis than description of a database and segmentation methods.<span>&nbsp; </span>The choice of methods used for comparing manual and automatic segmentation seems appropriate, although other methods could have been used as well.<span>&nbsp; </span></font></font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Open Science</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">In general the methods and approach are easy to follow.<span>&nbsp; </span>However, more detail could be provided on the following</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">a)<span>&nbsp; </span>How many slices can be acquired per heartbeat?<span>&nbsp; </span>Is slice mismatch a major problem (they refer to manually adjusting misaligned slices) or only present in very few cases?</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">b) How exactly is the oversampling achieved?<span>&nbsp; </span>Is the final resolution of the volume after oversampling 256x160x?? slices?</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">c) If manual segmentation is not available for every time step, how many time steps is it available for?</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">The section on comparing EF and MM calculations is very confusing due to the use of the abbreviation &ldquo;resp.&rdquo; which I take to mean &ldquo;respectively&rdquo;.<span>&nbsp; </span>This should be rewritten, and perhaps a table included to make it more clear.</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Reproducibility</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">I did not reproduce the work.</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Use of Open Source Software</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">Only Analyze is mentioned in the paper, which is not open source.</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Open Source Contributions</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">n/a</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Code Quality</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">n/a</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Applicability to other problems</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">The creation of standard databases such as this is very applicable to many problems in medical imaging, and the authors are to be commended for this effort.<span>&nbsp; </span>It seems likely that this database of images will be useful to other investigators, even more so if it can be added to in the future.</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Requests for additional information from authors</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">In the conclusion:<span>&nbsp; </span>I do not understand how 216 LV slices convert into 4752 &ldquo;borders&rdquo; of endocardium and epicardium.<span>&nbsp; </span>What exactly is a border in this context, and why are there so many of them?<span>&nbsp; </span>Does it really produce statistical or population diversity?</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">This work is significant by itself and does not need to be artificially inflated through the use of such obtuse terms.</font></p><font face=\\\"Times New Roman\\\" size=\\\"3\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"3\\\"><font face=\\\"Times New Roman\\\"><u>Additional Comments</u>:</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"3\\\">This review was written by Kenneth Wong in our lab and submitted by Kevin Cleary.</font></p>", "review_id": 563}, {"date": "07-04-2007", "author": {"author_id": 445, "author_email": "marfGm@gmail.com", "author_lastname": "Rodriguez-Florido", "author_firstname": "Miguel Angel"}, "content": "<p><strong>Summary:</strong><br /> This work describe a database of cine-MR images (3D+t) of the left ventricular of the heart. The paper presents the acquisition, the segmentation methodologies used, and the validation of the results, comparing automatic software-based segmentation with manual. The database is public an available on the web.<br /> <strong>Hypothesis:</strong><br />NA </p><p><strong>Evidence:</strong><br />This is a very empirical work that does not suppose any opinion. </p><p> <strong>Open Science:</strong><br /> This work is a great contribution to Open Science. It provides a clinical valued database very useful for other researchers. They describe their methods and provide the software-based tools that they have used. The results can be replicated. </p><p><strong>Reproducibility:</strong><br /> Although I haven&#39;t reproduced the authors work, they explain in their paper how to do it. The database is public and their results can be used for similar research lines. </p><p> <strong>Use of Open Source Software:</strong><br />For manual segmentation they use Analyze Software, but they don&#39;t say anything in the text about the kind of license for the software tools/scripts that they provide in the web site. I haven&#39;t downloaded this software, and I don&#39;t know if the code has a license warning or file.</p><p><strong>Open Source Contributions:</strong><br />NA</p><p><strong>Code Quality:</strong><br />NA<br /> </p><p><strong>Applicability to other problems:</strong><br />This open clinically-validated database is useful for all researchers that work with various cardiomyopathies. </p><p><strong>Suggestions for future work:</strong><br />NA <br /> </p><p><strong>Requests for additional information from authors:</strong><br />No comments on this item </p><p><strong>Additional Comments:</strong><br />Nice work and nice proposal: &quot;such work is only possible if cardiologists and computer scientists are working together in close partnership&quot;.</p><p>&nbsp;</p>", "review_id": 498}], "publication_id": 157},
{"reviews": [{"date": "09-12-2007", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<p><strong>Summary:</strong></p><p>This paper describes the implementation of a class for measuring surface to surface distance.</p><p>The paper provides the source code, input data, and easy-to-run examples. <br /> <br /> <strong>Hypothesis:</strong></p><p>Not quite applicable.</p><p>The paper mention the implicit hypothesis that the radial distance has certain advantages with respect to the closest distance and normal distance. However such comparison is not the real focus of the paper. Instead, the paper describes the implementation of the radial distance, and that&#39;s in my opinion perfectly fine. </p><p><br /> <strong>Evidence:</strong></p><p>The authors provide a tool that readers can easily use to compute distances between surfaces, and by that mean, eventually compare results against other surface distance definitions. </p><p> <br /> <strong>Open Science:</strong></p><p>The paper follows very well the fundamental principles of Open Science. </p><p>The authors provide all the material required for replicating their work: source code, input data, output data, and examples on how to use the code. </p><p>The paper clearly describes the fundamentals of their implementation.</p><p>In particular it was nice to see the organization of the paper into : </p><ul><li>Motivation </li><li>Mathematical principles </li><li>User&#39;s guide (how to use the code) </li></ul><p>The paper is concise, clear and goes to the point.</p><p>This is really the kind of easy-to-use contribution that will prove to be useful to the community. </p><p><br /> <strong>Reproducibility:</strong></p><p>The authors provided all the elements required to easily reproduce the work that they describe in the paper.</p><ul><li>Source code</li><li>Input data</li><li>Source code examples <br /></li><li>Output data<br /></li></ul><p>The only thing that may have been desirable to have is a way of computing the error, or difference between two distance files. But this is more for the convenience of whoever (...me in this case...) is trying to numerically verify the results of when replicating the work. A quick &quot;string text&quot; comparison of the provided output files against the output files that I got when running the provided tests indicate that the numerical values are very close.</p><p>It was very easy to rerun the code. The authors did a great job on facilitating the reproducibility of the code.</p><p>I couldn&#39;t reproduce Figure 2 with KWMeshVisu , where the inner and outer surfaces are shown using transparency. Not a big deal, I guess the figure was generated with a vtk script. </p><p>When attempting to do it using ParaView, it seems that the topology of the mesh is not well constructed. Although it looks fine when loaded with KWMeshVisu. </p><p>I especulate that it is probably due to an end-of-line conversion. </p><p> I&#39;m running the the code on Debian Linux, compiling with Gcc 4.1 in Release mode. </p><p><br /> <br /> <strong>Use of Open Source Software:</strong></p><p> The authors used the Visualization Toolkit VTK, and they also took advantage of a previous submission to the Insight Journal (KWMeshVisu)</p><p> <br /><br /> <br /> <strong>Open Source Contributions:</strong></p><p>The authors provide the source code of the class that computes the distances, and source code for the associated example. </p><p>It compiled and run without any problem. It tooke me just about 10 minutes to build it an run one of the examples. </p><p>&nbsp;</p><p> <strong>Code Quality:</strong></p><p>The code is nicely organized</p><p>The code is clear and easy to read. </p><p>The class that implements the distance measurement is easy to use. </p><p>It is however doing a little bit too much, since presumably if this class gets introduced into VTK (and it should), the functionalities of writing the distance files should be removed, and the class will be reduced to a filter that computes scalar properties on a surface, given two input surfaces.</p>The coding style would have to be reviewed according to VTK guidelines.<br /><br />There is no reason to believe that the code couldn&#39;t be portable among many platforms.<br /><p> <br /> <strong>Applicability to other problems:</strong></p><p>Measuring distances between surfaces is an important tool for many applications. In particular for comparing image segmentation results and therefore for validation studies.&nbsp;</p><p>The authors provide us with an easy to use hammer, that will prove to be very useful in any&nbsp; image analysis toolkit. </p><p> <br /> <strong>Suggestions for future work:</strong></p><p>The work is pretty compact and useful in its current form.</p><p>It could be interesting to&nbsp; use variations of this class for driving a deformable-surface segmentation method, but that&#39;s probably too far from the interest of the authors. (or not ?)</p><p>As a compact task for a course project, it will be nice to create an ITK version of this filter. For example based on the recently added QuadEdgeMesh.&nbsp;</p><p><br /> <br /> <strong>Requests for additional information from authors:</strong></p><p>The radial distance is critically dependent of the choice of center of polar coordinates. </p><p>The authors missed to elaborate a bit more on how important that choice is, and how they computed the center. </p><p>The class provide the option of using precomputed directions, but surprisingly it doesn&#39;t allow the user to provide a customized center. </p><p>Such option will be very easy to add. </p><p>This extra option is important because in many anatomical structure, the centroid of the surface, is not necessarily the best center of polar coordinates for describing the surface. For example if I had a section of the femur condyle and I&#39;m interested in measuring cartilage thickness, I should use the center of the (almost spherical) condyle joint, as opposed to the centroid of the points that happen to be in the section of surface that I have.</p><p>Fortunately, the code modifications are minimal. It is probably enough to add an enum mode for selecting between using a user-provided center or computing a center from the master surface.<br /><br /><br /> <br /> <strong>Additional Comments:</strong><br /> </p><p>Great paper !.</p><p>&nbsp;It is refreshing to finally get to perform real &quot;peer-reviews&quot; by actually being able to replicate the work that is described in a paper. </p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 569}], "publication_id": 158},
{"reviews": [{"date": "09-12-2007", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<p><strong>Summary:</strong></p><p>This paper describes nArray, and open source library for manipulating N-Dimensional arrays, and compares it usage with equivalent operations in N-Dimensional images in ITK. </p><p> <br /> <strong>Hypothesis:</strong><br /> </p><p>N/A<br /> <br /> <strong>Evidence:</strong><br /> </p><p>N/A</p><p><br /> <strong>Open Science:</strong></p><p>The paper fully complies with the requirements of Open Science. The authors provide their source code and detailed instructions (in the form of well configured tests) on how to run the same benchmarks that are presented in the paper.</p><p><br /> <strong>Reproducibility:</strong></p><p>It was straight forward to reproduce the work that the authors describe in their paper.</p><p>The source code of the library was provided with the paper, along with the source code of the benchmarks that compared nArray performance against ITK.</p><p>It was very easy to configure, build and run the code.</p><p>I build it on Debian Linux, in a dual processon Xeon 2.4GHz, 3Gb RAM, build with gcc 4.1, for Release </p><p>&nbsp;</p><p>Given that the machine I used is different from what the authors used, the actual numerical output of the Benchmarks are different from what appears in the paper. </p><p>&nbsp;However, this simply highlight how important is that benchmark comparisons have to be performed by providing readers the means of repeating the benchmark on their own local environment. </p><p>The authors did a great job of organizing and configuring the benchmark test s in such a way that they are almost trivial to execute. </p><p>The outputs in my system are:</p><ul><li>ImageAdd_ITK_Benchmark Window Extract 21032 Sum 18100 WindowsExtract and sum 39119 <br /></li><li>ImageAdd_nArray_Benchmark SumOf time 7488 operator + time 14076</li><li>Subarray_ITK_Benchmark Fill time 416537 Window time 10926 Slice time 478 Permute time 231274<br /></li><li>Subarray_nArray_Benchmark Fill time&nbsp; 360814&nbsp; Window time 5225&nbsp; Slice time 214&nbsp; Permute time 192745<br /></li></ul><p> It wasn&#39;t obvious how to map these numbers into the corresponding cells of the Table 3, in page 13 of the paper.... </p><p>&nbsp;</p><p>The benchmark conclusions are a bit misleading in the abstract and the conclusions sections. Specially given that several of the comparison showed that nArray methods are faster in some cases and slower in some other cases.&nbsp; In any case, the advantage of the paper is that the source code for both ITK and nArray is available, and the authors made the benchmarks available for inspections to the readers. This makes possible to verify how the code performs in other platform combinations.&nbsp;</p><p><br /> <strong>Use of Open Source Software:</strong></p><p>The authors used ITK as a reference to compare the performance of nArray.</p><p>nArray was also configured using CMake&nbsp;</p><p> <br /> <strong>Open Source Contributions:</strong></p><p>The authors provide the source code of nArray and distribute it under a thoughtful license. </p><p>The code is very well organized, and it was straight forward to use. <br /><br /> <br /> <strong>Code Quality:</strong></p><p><br />The source code is very well written. It uses a consistent coding style. The coding style is different from ITK&#39;s but that&#39;s not a concern given that nArray is a library and if used from ITK it will probably be included in the Utilities directory and then its functionalities will be invoked from there. </p><p>I build the code only in Linux, so I didn&#39;t verified the portability of the code. However the authors present results for Linux and Windows, and from the structure of the code there are no reasons to believe that it couldn&#39;t be widely portable. </p><p> <br /> <strong>Applicability to other problems:</strong></p><p>Since the nArray library provide such a fundamental functionality of storage, data access and basic data processing there is an endless list of applications for it. </p><p>It is certainly worth to explore mechanisms for integrating this library with ITK, whether by making easy for users to use simultaneously ITK images and nArrays, for example via ImageAdaptors, or via specialized version of the nArray___Ref classes that could actually point to an ITK image allocated buffer.<br /><br /> <br /> <strong>Suggestions for future work:</strong></p><p>Exploring combinations of ITK and nArray are probably the most interesting next step. This will make possible for application developers to take advantage of nArray qualities in certain operations of their applications, while using ITK for other operations, and in this way get the best of each world. This could be implemented as</p><ul><li>An itkImage-like class that reuses the memory allocated by an nArray, maskarading the nArray iterations as an itkPixelContainer</li><li>An nArray___Ref class that connects to an ITK image buffer instead of an actual memory block allocated by an nArray class.</li></ul><p> <br /> <strong>Requests for additional information from authors:</strong></p><p>I missed from the paper some comments regarding the impact of multi-threading. Specially considering the fact that one of the machines used by the authors is a dual processor, and that the AddImageFilter in ITK is multi-threaded. We assume that the nArray algorithms are multi-threaded, but there is no explicit mention of it in the paper. If nArray, is not multi-threader, then the timing reported are even more impressive, since it will mean that (at least in one platform) their speed more that doubled ITK performance.</p><p>A quick grepping on the source code of the authors seem to indicate that no multi-threading is being used in nArray. If that&#39;s the case, the results of the benchmark must be re-analized under this light, and,.... it also becomes interesting to consider multi-threading nArray, in order to get even better performance.</p><p><br /> <strong>Additional Comments:</strong></p><p>It will be very interesting, and very useful to the ITK community to explore mechanisms for bringing the advantages of nArray into ITK. </p><p>Several mechanisms come to mind</p><ul><li>Creating specialized ITK filters whose internal implementation uses nArray</li><li>Studying the internal implementation of nArray and compare it to ITK image iterators, to improve the implementation of the ITK iterators. Such improvements will then automatically improve the performance of ITK filters since almost all of them are based on image iterators.</li><li>Making easy to combine ITK images and nArray via ImageAdaptors (or nArray adaptors), so that an existing nArray could be accessed as an ITK image, or an ITK image be access like an nArray. Both options seem to be perfectly feasible. </li></ul>", "review_id": 568}, {"date": "09-11-2007", "author": {"author_id": 669, "author_email": "zuhars@gmail.com", "author_lastname": "Zuhars", "author_firstname": "Joel"}, "content": "<p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Summary:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">The authors describe a multidimensional array package that both has a uniform interface across all levels of dimensionality for ease of usability, and is comparable or superior in performance to existing packages, such as ITK. This was done using a templated interface approach and some novel implementation techniques.<br /><span>&nbsp;</span><br /><strong>Evidence:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">Table 1 provides a sampling of the API, and discussions on nArray engines and iterators, plus the associated code samples, illustrate key aspects of the API usage and support the notion that the interface is generally easy to use.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">I would have liked to see a more complete treatment of the API in the paper, rather than referring to the package itself for more details, and more specific examples of how the API is superior to ITK, given that the ease of use improvement was one of the primary goals.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">Section 4 details the performance benchmarking strategy versus ITK, provides references to the source code used, identifies the two system configurations used, and provides the numerical performance results along with a results analysis.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">The performance results and analysis supported the claim that the package is at least comparable to ITK, but I would have liked to see that done more conclusively, given that this was a primary goal of the work. Although it can be exceptionally difficult or impossible to hunt down the root causes for the wide variability in performance in such packages, a serious effort in this regard, including platform specific optimizations, if necessary, could possibly take this package to the level of a standard.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Open Science:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">A link to the CISST Software Package is provided in the references. I assumed it would be straightforward to locate and compile the nArray library from the package, but did not do so myself. References to the source code used for benchmarking are provided in the text. I assumed these are located in the CISST Software Package.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Reproducibility:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">I have not attempted to reproduce the author&rsquo;s work.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Use of Open Source Software:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">The authors directly compared their work to ITK.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Open Source Contributions:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">The authors provide links to their source code. I did not see a reference to the applicable licenses for the code, which would be an improvement if added.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Code Quality:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">The code is clearly suitable for multi-platform use. The implementation discussion leads one to assume that the code is of excellent quality, in particular, the appropriate use of templates, and the stated accomplishment of conformance with STL&rsquo;s specification for a random access iterator.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Applicability to other problems:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">The authors are attempting to improve on a fundamental aspect of image analysis programming. This work would be applicable to a wide variety of problems, not limited to the image analysis domain.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Suggestions for future work:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">See evidence section.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">Also, it was not clear if the recursive function in section 3.3 was actual code from the package or presented to support the explanation only. If it represents the actual code, I would be interested in seeing if any performance difference can be derived by using a much less elegant non-recursive version, since use of recursion in such cases can be inefficient.</span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\"><strong>Additional Comments:</strong></span></p><p><span style=\\\\\\\"font-size: 9pt; color: black; font-family: Verdana\\\\\\\">In general, I felt as though this has the potential to be a valuable contribution to the field, and that the ITK implementation could indeed be improved through the use of the described methods. The paper, however, seemed to lose focus from its objectives somewhat, in that it shifts to detailing the novelties of the implementation, rather than proving out it&rsquo;s goals, which seemed the more appropriate use of the reader&rsquo;s time at this level. The implementation details were, of course, also very interesting.</span></p><p>&nbsp;</p>", "review_id": 560}], "publication_id": 159},
{"reviews": [{"date": "07-18-2007", "author": {"author_id": 286, "author_email": "dan.muel@gmail.com", "author_lastname": "Mueller", "author_firstname": "Dan"}, "content": "<p><strong>Summary:</strong><br />This paper presents a set of ITK classes for efficient kernel-based filters. The authors provide source-code and results for various mechanisms including: separable filters, histogram-based kernels, and decomposition of morphological structuring elements. The results indicate the newly-implemented methods are faster than the basic approaches currently implemented in ITK (with some constraints, as discussed in the paper).<br /> <br /> <strong>Hypothesis:</strong><br />The efficient implementations are faster (with some constraints) than the existing ITK implementations.<br /> <br /> <strong>Evidence:</strong><br />Section 7 of the paper displays graphs of different algorithm performance and the Appendix lists the results in tabular format. The code used to generate the graphs and text file output is provided with the article.<br /> <br /> <strong>Open Science:</strong><br />The authors provide the input images, source code, and results used in their experiments.<br /> <br /> <strong>Reproducibility:</strong><br />I have downloaded, compiled, and run parts of the work. I did not run the performance analysis code, but I have used some of the filters in my own application (mostly the morphological filters) and anecdotal evidence suggest the speed-ups are valid.<br /><br />I did have some trouble compiling the code: the compiler I used (Microsoft Visual Studio 8.0.50727.762) complained about an ambiguous call to overloaded function &#39;pow&#39; in itkFlatStructuringElement. This was fixed by casting the base to double, eg.<br /><br /> unsigned int facets = 8 * (int)pow((double)4, iterations);<br /> <br /> <strong>Use of Open Source Software:</strong><br />The work extends ITK.<br /> <br /> <strong>Open Source Contributions:</strong><br />The full source-code is provided.<br /> <br /> <strong>Code Quality:</strong><br />The code quality is good and matches ITK standards. However, some of the documentation needs further work:</p><ul><li>The \\\\\\\\brief for itkSeparableImageFilter could be improved, eg. &quot;A filter for performing kernel operations using decomposition&quot; instead of &quot;A separable filter for filter which are using kernel&quot;, similar for itkSeparableRadiusImageFilter</li><li>itkAnchorCloseImageFilter and itkAnchorOpenImageFilter classes have no documentation</li><li>The documentation for the static constructors in itkFlatStructuringElement need work before integration into the toolkit, these methods are important and should be well documented for users</li><li>The documentation in itkMovingHistogramDilateImageFilter and itkMovingHistogramErodeImageFilter erronously refers to MorphologicalGradient <br /></li></ul><p>On the plus side, the documentation for itkMovingHistogramImageFilter (and others) is excellent!</p><p>I dislike the static const int declarations of the algorithm type, mainly because it is declared 4 separate times: itkGrayscaleMorphologicalOpeningImageFilter, itkGrayscaleMorphologicalClosingImageFilter, itkGrayscaleDilateImageFilter, and itkGrayscaleErodeImageFilter. Can the algorithm type be declared once in a header file? Also, ITK seems to favour enum types (see: itkRegularStepGradientDescentBaseOptimizer), should it be an enum?<br /> </p><p>I also stumbled across a bug / problem with itkSeparableImageFilter.txx: the output is not correctly grafted. The following line needs to be added above the update for the last filter:</p><p>m_Filters[TInputImage::ImageDimension - 1]-&gt;GraftOutput( this-&gt;GetOutput() );&nbsp;</p><p><strong>Applicability to other problems:</strong><br />The work is applicable to a wide of range of image processing problems, not only in the medical domain.<br /> <br /> <strong>Suggestions for future work:</strong></p><ul><li>Addition of the Annulus operator (see attachment) and Cross operator to itkFlatStructuringElement</li><li>The itkSeparableImageFilter and itkMaskedSeparableImageFilter classes were of particular interest to me, but I was disappointed to find no morphological operations utilising these (at least that I could find) and no comparisons of speeds for Box structuring elements of basic, histogram, anchor, and <em>separable </em>approaches. I have implemented separable dilation and erosion using the basic approach (see attachment). A moving histogram approach could also be implemented. Perhaps these classes can be added in the darcs repository / toolkit?</li></ul><p><strong>Overall:</strong><br />A comprehensive article which discusses a number of very useful filters (many of which I have already started using). Thanks!</p><p>&nbsp;</p>", "review_id": 503}, {"date": "09-11-2007", "author": {"author_id": 368, "author_email": "cleary@georgetown.edu", "author_lastname": "Cleary", "author_firstname": "Kevin"}, "content": "<span><strong>Summary:<br /></strong></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">This paper reviews background theory for a number of approaches to kernel based filtering, which are all well established in the literature. They can significantly reduce complexity and execution time. The authors implemented them in ITK and evaluated their performance.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><strong>Hypothesis:<br /></strong>Non Applicable<br /><br /><strong>Evidence:</strong></span><em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"></span></em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">This paper reviews the published approaches and introduces their implementation in ITK. It has no new idea. However, it shows how efficient the implemented algorithms are by presenting the measured execution time with an increasing kernel size.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><br /><strong>Open Science:</strong></span><em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"></span></em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Yes, they provide the source code and the images through a web site.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Yes, they provide enough details.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">The code is written as a part of ITK.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><strong>Reproducibility:</strong></span><em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"></span></em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">No</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"> I did not reproduce the work.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><strong>Use of Open Source Software:</strong></span><em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"></span></em><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Yes, they did. Their code itself is a part of ITK.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">No, they don&rsquo;t describe them.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Yes, they provide advice. They tell us that availablity of filtering algorithm can make much simpler approaches to many problems practical.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><br /><strong>Open Source Contributions:<br /></strong></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Yes, they provide the source code through a web site.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><br /></span><span><strong>Requests for additional information from authors:<br /></strong></span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\">Table captions are a little confusing. More details are necessary.</span><span style=\\\"font-size: 9pt; color: black; font-family: &#39;Verdana&#39;,&#39;sans-serif&#39;\\\"><br /><strong>Additional Comments:</strong></span><span style=\\\"font-size: 10.5pt; font-family: Consolas\\\"></span> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"2\\\">In addition to the answers to the above questions, it might be useful to the reader if a coarse-to-fine review was provided that starts with (a) the overall recommendation of the reviewer to the community (e.g., &quot;Download this!&quot; or &quot;Has great potential, but needs some additional work&quot; or &quot;Work is interesting, but not (yet?) appropriate for the open-source community for the following general reasons...&quot;), (b) General comments on the technology involved, (c) General comments on the contribution (introduction, background, method description, evaluations, followed by (d) Detailed comments on the contribution (grammar, spelling, data formats). </font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"2\\\">(a) I recommend to download this to the community.</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"2\\\">(b) None</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"2\\\">(c) The authors implemented the efficient kernel filtering algorithms in ITK. Even though the algorithms are already published and not new, the implementation in ITK may be helpful for other image processing projects.</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"2\\\">(d) Some grammatical mistakes</font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"2\\\"><font face=\\\"Times New Roman\\\"><span>&nbsp;&nbsp; </span>i) Page 8: The filters discusses in this article </font><span style=\\\"font-family: Wingdings\\\"><span>&agrave;</span></span><font face=\\\"Times New Roman\\\"> The filters discussed in this article</font></font></p><p style=\\\"margin: 0in 0in 0pt; text-indent: 15pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"2\\\"><font face=\\\"Times New Roman\\\">ii) Caption of figure 7 : with and increasing number fo threads </font><span style=\\\"font-family: Wingdings\\\"><span>&agrave;</span></span><font face=\\\"Times New Roman\\\"> with increasing number of threads</font></font></p><p style=\\\"margin: 0in 0in 0pt; text-indent: 15pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"2\\\"><font face=\\\"Times New Roman\\\">iii) Caption of figure 9 : for and increasing </font><span style=\\\"font-family: Wingdings\\\"><span>&agrave;</span></span><font face=\\\"Times New Roman\\\"> for increasing</font></font></p><p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font size=\\\"2\\\"><font face=\\\"Times New Roman\\\"><span>&nbsp;&nbsp; </span>iv) Table 10 : size </font><span style=\\\"font-family: Wingdings\\\"><span>&agrave;</span></span><font face=\\\"Times New Roman\\\"> thread</font></font></p><font face=\\\"Times New Roman\\\" size=\\\"2\\\">&nbsp;</font> <p style=\\\"margin: 0in 0in 0pt\\\" class=\\\"MsoNormal\\\"><font face=\\\"Times New Roman\\\" size=\\\"2\\\">This review was written by Min Cho and submitted by Kevin Cleary.</font></p><font face=\\\"Times New Roman\\\" size=\\\"2\\\">&nbsp;</font>", "review_id": 564}], "publication_id": 160},
{"reviews": [], "publication_id": 161},
{"reviews": [{"date": "09-01-2007", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<p><strong>Summary:</strong><br />The authors describe the tools that they have built for volume rendering heart data.&nbsp; The details include segmentation and rendering.&nbsp; All of the necessary processing steps are described along with how to built the code.</p><p><br /><strong>Hypothesis:</strong><br />Not Applicable</p><p><br /><strong>Evidence:</strong><br />The authors include, in great detail, the process to create segmented volumes and render them.&nbsp; There is ample support also from the nice references provided.<br /><br /><strong>Open Science:</strong><br />This is completely open science.&nbsp; Both the source code and data are provided.</p><p><strong>Reproducibility:</strong><br />I admit that I did not compile the code.&nbsp; I did look at it and found there is not actually any code in it because it makes great use of other packages, so most&nbsp;of the files are cmake files for compiling existing tools.<br /><br /><strong>Use of Open Source Software:</strong><br />[Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]<br /><br /><strong>Open Source Contributions:</strong><br />From my perspective, the primary contribution is&nbsp;the form and detail of the paper -- it is a nice template for others who would like to write a case study.&nbsp; Having access to the code is also valuable.<br /><br /><strong>Code Quality:</strong><br />Unevaluated</p><p><br /><strong>Applicability to other problems:</strong><br />At this point, I think it is probably applicable, but that has not yet been shown.&nbsp; The specific algorithms are tuned for the application.&nbsp;</p><p><strong>Suggestions for future work:</strong><br />More rendering examples and analysis will be beneficial.&nbsp; I also think that this can be used to show the value of visualization to the clinician which requires a study all by itself.</p><p>&nbsp;</p>", "review_id": 543}], "publication_id": 162},
{"reviews": [], "publication_id": 163},
{"reviews": [], "publication_id": 164},
{"reviews": [], "publication_id": 165},
{"reviews": [], "publication_id": 166},
{"reviews": [], "publication_id": 167},
{"reviews": [{"date": "04-26-2008", "author": {"author_id": 164, "author_email": "imacia@vicomtech.org", "author_lastname": "Macia", "author_firstname": "Ivan"}, "content": "<p><strong>Summary:</strong><br />The paper describes a method to specify a transform given the center point of a section, the section normal and the output size. Then it incorporates this transformation into a filter in order to obtain a 2D section image from a 3D image.<br /> <br /> <strong>Hypothesis:</strong><br /> Not applicable.<br /> <br /> <strong>Evidence:</strong><br />The author demonstrates the efficiency of the method by providing some examples and tests with synthetic and real data.<br /> <br /> <strong>Open Science:</strong><br /> </p><p>The work adheres to the concept of Open Science. Source code, test images and images shown in the paper are provided. </p><p><strong>Reproducibility:</strong><br /> </p><p>I managed to compile the source code and run the tests. Results were reproduced without problem as some tests with parameters were available. <br /> <br /> <strong>Use of Open Source Software:</strong></p><p>The implementation uses and extends ITK. </p><p><strong>Open Source Contributions:</strong></p><p>Source code is provided and its usage is straightforward.</p><p><strong>Code Quality:</strong><br /> </p><p>In my opinion it is better to create a LookUpTransform that inherits from Rigid3DTransform instead of using initializer. I did this and incorporated some other changes (see attachment). These include:</p><p>- LookAtTransformInitializer changed to LookAtTransform that inherits Rigid3DTransform.</p><p>- m_Image is no longer a member as it is unnecessary just to specify output spacing. This spacing is incorporated as argument to the call SetPlane().</p><p>- The output spacing does not need to be the same as the input image spacing. Changed this (see previous).</p><p>- The template parameter for the transform is the 2D image, not the 3D image. This makes more sense in my opinion.</p><p> With respects to the tests, there is no usage information for command line as in ITK examples.</p><p> <br /> <strong>Applicability to other problems:</strong></p><p>The method can be applied to any problem that requires the extraction of a section given its center and normal. </p><p> <strong>Suggestions for future work:</strong><br /> </p><p>None. </p><p><strong>Requests for additional information from authors:</strong></p><p>None. </p><p> <strong>Additional Comments:</strong></p><p>There is an error in the figure description. It says first and second row where it should say first and second column. </p>", "review_id": 654}], "publication_id": 168},
{"reviews": [], "publication_id": 169},
{"reviews": [{"date": "09-10-2007", "author": {"author_id": 643, "author_email": "danielle.pace@kitware.com", "author_lastname": "Pace", "author_firstname": "Danielle"}, "content": "<p><strong>Summary:<br /></strong>An image-based approach to systems biology allows both cell lineage trees and quantitative molecular data to be gathered over time and at cellular resolution.&nbsp; This paper describes GoFigure, a software package for the image processing of four-dimensional in toto images with the overall goal of extracting these two types of data.&nbsp; In particular, the development of zebrafish embryos will be studied at the cellular level in order to discover more about the genetic circuits underlying embryogenesis.&nbsp; Although still in progess, once completed this project will be an excellent contribution to the open source community in systems biology, as a very large collection of molecular data (the &quot;Digital Fish&quot;) and GoFigure itself will be released in an open source fashion.<br /><br /><strong>Hypothesis:<br /></strong>The overall hypothesis is that an image-based approach to systems biology yields accurate and reliable molecular and cell lineage data.&nbsp; Although no hard&nbsp;evidence to support this is provided per se, the rationale behind their approach is extensively discussed and in my opinion makes a lot of sense.<br /><br /><strong>Evidence:<br /></strong>1)&nbsp; The advantages of an image-based approach to systems biology over more traditional molecular approaches are clear and convincing.&nbsp; 2) The authors claim that &quot;computers have a notoriously difficult time (spotting cells in microscopic images)&quot; but do not reference previous (presumably unsuccessful attempts) by themselves or others to solve this problem. 3) The authors claim that &quot;we cannot predict how when and where a protein will be expressed, we cannot predict how a protein will fold and function once it is translated, and we cannot predict the interaction between expressed proteins that allow them to form functional genetic circuits&quot; without mentioning previous bioinformatics work on subcellular localization, protein folding and reverse engineering of genetic networks.&nbsp; Although a thorough overview of systems biology is obviously not necessary in this paper, the wording of this part of the introduction would likely make the newcomer falsely think that these problems have never been attempted before. <br /><br /><strong>Open Science:<br /></strong>Although the authors&nbsp;mention that the GoFigure software package and their data will be released in an open-source&nbsp;manner, no code, code documentation, images or data&nbsp;are provided with this submission.<br /><br /><strong>Reproducibility:<br /></strong>I could not reproduce the authors&#39; work because no source code was provided.<br /><br /><strong>Use of Open Source Software:<br /></strong>The authors use VTK and ITK for visualization and segmentation, as well as CMake and CPack.&nbsp; The authors also mention their plans to use a KWStyle GUI and perhaps Qt in the future.<br /><br /><strong>Open Source Contributions:<br /></strong>Once again, no source code is provided in this submission.<br /><br /><strong>Code Quality:<br /></strong>Not applicable.<br /><br /><strong>Applicability to other problems:<br /></strong>Once the authors develop a faster segmentation algorithm, it can presumably be used for segmentation in other large datasets.<br /><br /><strong>Suggestions for future work:<br /></strong>Not sure if this will help, but work&nbsp;by Abolmaesumi and Sirouspour on segmentation in medical images (particularly segmentation of the prostate in ultrasound images) may apply here - their algorithm is fast because it requires no numerical optimization.&nbsp; See &quot;Segmentation of prostate contours from ultrasound images&quot;, Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing 2004, vol 3 pp 517-520, 2004; &quot;Ultrasound image segmentation using an interacting multiple-model probabilistic data association filter&quot;, Proceedings of the SPIE, vol 5370 pp 484-493, 2004; and &quot;An interacting multiple model probabilistic data association filter for cavity boundary extraction from ultrasound images&quot;, IEEE Transactions on Medical Imaging, vol 23(6) pp 772-782, 2004.<br /><br /><strong>Requests for additional information from authors:<br /></strong>1) The authors do not mention how molecular data (such as that from YFPs) is extracted from the in toto images - this presumably involves segmentation as well as further quantification.&nbsp; Has any of this work been done, or does it fall under future work? 2) Neither the segmentation algorithms nor the propagation algorithms used have been described in any detail - I am interested in what has been attempted so far.&nbsp; 3) How is the accuracy of the current segmentation algorithm quantified?&nbsp; The paper says that it is &quot;quite accurate&quot; but I would like to know how this has been determined.&nbsp; Also, the paper mentions that the current segmentation algorithm is slow - how much time does it take?&nbsp; 5)&nbsp; Although the advantages of incorporating use interaction into GoFigure are clear, I wonder how this works in practice.&nbsp; If the number of cells across space and time is as large as it seems to be, how much time does the user have to spend looking for false negatives and false positives?&nbsp; 6) More references on both in toto imaging and imaging for systems biology are needed so that the newcomer can see how this work fits into the rest of the field and how it is unique.<br /><br /><strong>Additional Comments:<br /></strong>1) The writing / English of this paper should be improved, particularly in Section 3.&nbsp; 2) Overall this is an excellent project - I&#39;m sure that plenty of systems biologists will be eager to get their hands on your software and data once it is released.&nbsp; Great work so far!</p><div>Score justification:<br /></div><p>1)&nbsp; (2 points) Does the paper follow the standards of open-science by including the relevant code, data, and parameters needed to replicate the work described in the paper? Can the work be duplicated? How well does the work (when appropriate) build upon (instead of duplicating) existing open-source efforts? </p><p>0 stars (because no code or data was provided in this submission)</p><p>2)&nbsp; (1 point) Does the work address a (knowledge or software-based) need within the community? Where do you see it having the most impact?</p><p>1 star - an open source&nbsp;software package for image-based systems biology is needed so that the difficult image processing work involved is not duplicated by researchers and so that biologists not explicitly trained in computer science can use the package and the associated data in their own work.</p><p>3)&nbsp; (1 point) How well is the work described in the paper? Is sufficient background material provided in the paper itself, or easily located using pointers in the paper? </p><p>1 star - the work is adequately described, and the background material is especially detailed.</p><p>4)&nbsp; (1 point) Can you name one or two research projects that you think would benefit from the use of this work?</p><p>1 star - the data provided by this work could definitely be used by bioinformaticians interested in reverse engineering of genetic networks, both to extract the underlying genetic circuits in zebrafish embryogenesis and as a test dataset to compare various reverse engineering algorithms.</p>", "review_id": 556}, {"date": "09-10-2007", "author": {"author_id": 197, "author_email": "richard.beare@ieee.org", "author_lastname": "Beare", "author_firstname": "Richard"}, "content": "<p><strong>Summary:</strong><br />This paper is an overview of the Digital Fish Project. There is discussion of plans for automated segmentation work and mention of a framework to support the project, but minimal details. Some data has been made available in response to another reviewer. </p><p> <strong>Open Science:</strong><br />At present there is nothing computational to review, although the paper states that code will be made public. <br /> <br /> <strong>Additional Comments:</strong><br /> </p><p>The project background is really interesting - it is a great example of how computational data analysis tools, such as image analysis, are changing the way in which some life sciences research is carried out. I&#39;d recommend that the paper concentrate on this aspect, with emphasis on the scale and complexity of the problem. If suitable datasets can be made available with this paper then perhaps we will see part of the solution developed by the ITK community. </p> <p>There is minimal technical content in the paper in its current form, with disussion limited to high level concepts - &quot;tracks&quot;, &quot;lineages&quot; etc, and a couple of viewer screenshots. It reads like a marketing piece in places. </p> <p>I&#39;d like to see the tools become cross platform.</p>", "review_id": 557}, {"date": "09-13-2007", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<p><strong>Summary:</strong><br />This paper is an excellent introductory text on the motivations for the field of systems biology and the process of in toto imaging as well as for the software architecture and GUI design for a system for processing 4D microscopy images.</p><p>Systems biology is concerned with imaging and quantifying the interactions between cell behavior and molecular circuits, particularly during embryogenesis.</p><p>In toto imaging in this test is concerned with 3D imaging (confocal microscopy or 2-photon fluorescence microscopy) to track tissue and organ development at the cellular and protein level over time.</p><p>The software and interface must support mosaicing, displaying, segmenting, and editing the segmentations from those massive 4D images.</p><p>The paper represents work-in-progress such that the software is not yet available.</p><p>Response from the author to a previous review shows that the data is available online at:<br /><a href=\\\"%5C%22%5C%22../midas/view_collection.php?collectionid=37%5C%22%5C%22\\\">http://www.insight-journal.org/midas/view_collection.php?collectionid=37</a> </p><p>(With Version 2 of this paper - authors now provide links to data, code, binaries, and more!!!)</p><p><strong>Hypothesis:</strong><br />Cellular segmentation in 4D images is a grand challenge in systems biology and the GoFigure software will help non-computer-scientists generate effective cell segmentations from massive datasets in a timely manner.</p><p> <strong>Evidence:</strong><br />The initial implementation is somewhat limited but lessons were learned and will be addressed in the upcoming release.</p><p>Lessons learned include:</p><p>1) Hand editing tools are needed for when segmentations fail - and segmentations will fail.<br />The GoFigure software provides means for adding and deleting cell segmentations - it is surprising that they do not provide merging and splitting tools for when cell segmentations are inaccurate.</p><p>2) Large data can be effectively handled via tailored views - it is sufficient to provide 2D views that scroll over time or in 3D - there is no need to attempt complex graphical representations of 4D data. </p><p>3) Initial attempt at segmentation was done on 2D images - future versions will be in 3D and possibly in 4D; incorporating heuristics as well as higher dimensional information. 2D image segmentations were inaccurate and time consuming. </p><p><strong>Open Science:</strong><br />The paper is work-in-progress. The paper has not been updated to mention the availability of data, and the software remains unavailable.</p><p>The licensing terms of the software has not been identified. Additionally, it is limited to running on Windows at this time because of the use of MFC.</p><p>The authors are congratulated for making their data freely available. </p><p><strong>Reproducibility:</strong><br />Waiting for code release. Additionally, the paper is written at a higher level - more of an introductory text than a how-to text.<br /> <br /> <strong>Use of Open Source Software:</strong><br />Software uses ITK and VTK.</p><p><br /> <strong>Open Source Contributions:</strong><br />The license for the code is not given.</p><p>The data has been posted using a by-attribution license! </p><p> <strong>Applicability to other problems:</strong><br />This software way be generally applicable when 4D data needs to be quantified. The use of ITK suggests that other segmentations could be incorporated into the software. Also, the backend mysql database for managing images and analysis results should be generally useful. This software could evolve into a very useful toolkit.<br /><br /><strong>Suggestions for future work:</strong><br />1) Release the source</p><p>2) Go cross-platform</p><p>3) Release more data</p><p>4) Ensure mysql can handle the large images (some groups prefer PGSQL for large images).</p><p>5) Provide demonstrations and how-to text</p><p>6) Fix the spelling, grammar, and punctuation in the paper, particularly in the second half of the text. </p>", "review_id": 555}, {"date": "09-01-2007", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<p><strong>Summary:</strong><br />The authors describe the Digital Fish project which involves the acquisition of in toto images of zebrafish and the development of the GoFigure software tools.&nbsp; In toto imaging is detailed along with the purpose of the project.&nbsp;The authors state that the project is an open source project with both the images and data available to other researchers.</p><p><br /><strong>Evidence:</strong><br />The authors provide a clear description of the methods and an introduction to the GoFigure software.&nbsp; While the authors state that the project is Open Source, I was unable to find an licensing information about either the software or data.</p><p><br /><strong>Open Science:</strong><br />The authors purport that the work is open source; however, I was unable to verify this.&nbsp; The software</p><p><br /><strong>Reproducibility:</strong><br />I was unable to evaluate the software or data.&nbsp; There is no reference in the paper to how to obtain the software or data.&nbsp; I was able to find the na-mic wiki page (<a href=\\\"http://wiki.na-mic.org/Wiki/index.php/NA-MIC_NCBC_Collaboration:3D+t_Cells_Lineage:GoFigure\\\">http://wiki.na-mic.org/Wiki/index.php/NA-MIC_NCBC_Collaboration:3D+t_Cells_Lineage:GoFigure</a>) for GoFigure.&nbsp; The software is available, but only in binary form.&nbsp; It sounds like the next version should be completely open.&nbsp; I was unable to find the data.&nbsp; There is a webpage on the CIT website, but it requires a username and password.</p><p><br /><strong>Use of Open Source Software:</strong><br />The&nbsp; next version of the software should be written with the various software tools provided by na-mic.</p><p><br /><strong>Open Source Contributions:</strong><br />If completed and released, this will provide an excellent open platform for analyzing confocal images.&nbsp; The data will be very useful for developing new processing algorithms as well.</p><p><br /><strong>Code Quality:</strong><br />Unable to evaluate.&nbsp; </p><p><br /><strong>Applicability to other problems:</strong><br />As stated above, it will hopefully be applicable to other confocal imaging projects.</p><p><br /><strong>Suggestions for future work:</strong><br />None</p><p><br /><strong>Requests for additional information from authors:</strong><br />No information is currently provided on obtaining either the software or data.&nbsp; There is also no licensing information.&nbsp; The text would benefit, at a minimum, from the reference to the na-mic wiki page.</p><p><br /><strong>Additional Comments:</strong><br />There are several typos in the text, particularly near the end.&nbsp; I suggest that authors edit the text one more time.</p>", "review_id": 542}, {"date": "09-14-2007", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<p><strong>Summary:<br /></strong><br />The authors describe the The Digital Fish Project, which involve the in vivo imaging of full Zebra fish embryos using a 2 photon confocal microscope, and the GoFigure software, used to segment the cells and the nuclei, track them over the time, visualize the acquired images, ...<br /> </p><p><strong>Open Science:<br /></strong><br />The paper, the data and the software are licensed with an open source license. </p><p> <br /> <strong>Reproducibility:</strong></p><p>GoFigure is currently usable only on the windows OS, an OS I&#39;m not used to using. I haven&#39;t built the code.&nbsp;</p><p>&nbsp;<strong>Use of Open Source Software:<br /></strong><br />Yes. ITK, VTK and CMake are used. The authors are also planning to use KWWidgets. </p><p> <br /> <strong>Open Source Contributions:<br /></strong><br />Yes. The source code is fully available with subversion. </p><p> <br /> <strong>Code Quality:<br /></strong><br />The code seem well structured and documented (That&#39;s also the Ohoh point of view http://www.ohloh.net/projects/8464?p=GoFigure). </p><p> <br /> <strong>Applicability to other problems:</strong></p><p>In toto imaging is one of the most interesting thing to study the embryogenesis. This software, as well as the biological methods used, will be very useful to study the embryogenesis in other species. We can also imagine using it to study the differenciation of the cells in some particular tissues. </p><p><br /> <strong>Requests for additional information from authors:</strong></p><p>What image format comes from your microscope? It is usualy a bit difficult to read proprietary format of the biggest confocal manufacturers, and if a new reader have been developed, in may be one other good thing to reuse from this project.</p><p> Confocal imaging usually have an extinction of the signal when the depth increase. Don&#39;t you have that phenomenon in your images? If yes, have you leave correct it? How?</p><p>You say the image are noisy. How are you denoising them? </p><p> Finall, you say that &quot;the amount of the expression marker in each cell can then be quantitated&quot;. However, from my own experience, quantitation is very difficult in confocal images, because it is highly dependent of several factors (gain and offset of the detector, transparency of the object and/or the medium, depth extinction, photo blitching, ...). Can you say more about what you want to measure, and how you will do that ?</p><p><strong>Additional Comments:<br /></strong><br />A very promising project - I will follow it closely!</p><p>&nbsp;</p>", "review_id": 571}], "publication_id": 170},
{"reviews": [{"date": "09-10-2007", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<p><strong>Summary:</strong><br />This paper very clearly presents tutorials for building a LEGO-based robot and phantom for teaching and exploring the basics of image-guided robotic control for needle biospies. Also included is software for a C++ interface to the robot.</p><p>This project builds upon the LEGO Mindstorm robot and the NXT++ library for controlling that robot. The tutorials and papers also refer to a 3D Slicer v3 module for IGT.</p><p>The paper also includes an excellent evaluation of the accuracy of the robot given repeated applications of the tutorial script. </p><p>&nbsp;</p><p><strong>Methods:</strong><br />The instructions for building the phantom is outstanding. I am confident that if I had the LEGO pieces, then I could build it.</p><p>The tutorials are extremely well written and illustrated. They seem to be viable for a wide range of ages and backgrounds. These tutorials exceed the standard for open-source teaching materials. Basic and advanced tutorials are presented.</p><p>The instructions for building the robot seem to be missing.</p><p>The instructions for accessing (i.e., the code for) the Slicer 3D module are missing. A Google search does not reveal the &quot;Lego Module&quot; for Slicer. As a result, the basic and advanced tutorials cannot be replicated. </p><p>The robot control software included with the tutorial is a modified version of the NXT++ library.<br />1) The authors have ported the NXT++ library to 64-bit linux systems which is important for IGT research/environments<br />2) The NXT++ library is GPL licensed and therefore the included code is GPL licensed, however those licensing terms are never given in the code.<br />3) The code claims to be copyrighted by the Insight Software Consortium - but it is not. A legitimate copyright needs to be declared.</p><p>&nbsp;</p><p><strong>Results:</strong><br />Once the missing pieces are provided (LEGO-pun intended), this tutorial will be the highlight of many high-school, college, graduate, and perhaps even medical school courses. </p><p>As the authors point out, the focus of the tutorials is not robot building, but instead it is on IGT theory (planning, calibration, registration, and control). The concepts of error measurement presented in the paper are also excellent companionS to the how-to nature of the tutorials. When those topics are to be discussed in a classroom, the tutorials discussed provide a unique hands-on / real-world method for conveying the key concepts.</p><p>&nbsp;</p><p><strong>Conclusion</strong>:</p><p>The material provided sets a high standard for the presentation and evaluation of tutorial materials in a field (IGT) that desperately needs broadly useful educational materials. Furthermore, the use of LEGOs makes the tutorials cost effective and &quot;friendly&quot; to make IGT more accessible.</p><p>The absence of two key pieces (robot building instructions and the Slicer module) inhibit the actual use of the tutorial material, but hopefully the authors can quickly correct this oversight. </p>", "review_id": 551}, {"date": "10-02-2007", "author": {"author_id": 445, "author_email": "marfGm@gmail.com", "author_lastname": "Rodriguez-Florido", "author_firstname": "Miguel Angel"}, "content": "<p><strong>Summary:</strong><br />This paper presents a good system to teach technical students in the medical image computing area. They present a low cost robotic system that is driven by the open source software Slicer. Although, at this moment, they don&#39;t provide the user guide to build the robot, and the CT dataset of the phantom, they explain how they use it and how to use it.<br /> <strong>Open Science:</strong><br />This is an example of Open Science because they present a system that uses open source software and they describe a low cost robotic system, that could be bought for any research group. However is very important to add the guide to build the system and the CT dataset of the phantom<br /><strong>Reproducibility:</strong><br />I would like to reproduce the results, but although I&#39;m going to buy the LEGO system, I need the user guide to build the robot. I could be great to have the CT dataset of the phantom too.&nbsp;<br /><strong>Use of Open Source Software:</strong><br />They use open source software (Slicer) and they provide the software associated to the LEGO system. It could be great to provide the VTK Slicer module (at least at the svn slicer site) to reproduce the system.<br /><strong>Open Source Contributions:</strong><br />They provide some code, but it would be great to provide the VTK Slicer module.&nbsp;<br /><strong>Code Quality:</strong><br />It is well commented.<br /><strong>Applicability to other problems:</strong><br />How we are using slicer for medical students education, we would like to use this system. At this moment, we need the VTK Slicer module and the CT dataset of the phantom.<br /> <strong>Requests for additional information from authors:</strong><br />I&#39;ve read that authors are providing the user guide to build the robotic system. Also, we need the VTK Slicer module and perhaps the CT dataset. We would like to use it for education and teaching.&nbsp;<br /><strong>Additional Comments:</strong><br />Nice work.</p><p>&nbsp;</p>", "review_id": 586}, {"date": "01-18-2008", "author": {"author_id": 643, "author_email": "danielle.pace@kitware.com", "author_lastname": "Pace", "author_firstname": "Danielle"}, "content": "<p>Please note that this submission contains documents (including source code, documentation, tutorial slides, etc) that were up-to-date as of October 2007.</p><p>Continuted improvements and updates to this project will be maintained on the NA-MIC wiki at:</p><p><a href=\\\"http://wiki.na-mic.org/Wiki/index.php/LEGO_IGT_and_Medical_Robotics_Tutorial\\\">http://wiki.na-mic.org/Wiki/index.php/LEGO_IGT_and_Medical_Robotics_Tutorial</a></p><p>and will not be reflected on this page.&nbsp; Please refer to the website above for the most current files.</p><p>-Danielle Pace</p><p>&nbsp;</p>", "review_id": 636}, {"date": "09-06-2007", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<p><strong>&nbsp;Update:</strong></p><p>The authors have provided an outstanding contribution with this work.&nbsp; The revision includes everything that one would need to implement the tutorial.</p><p><strong>&nbsp;</strong><strong>Summary:</strong><br />The authors propose the use of the LEGO mindstorm and 3D&nbsp;slicer for teaching some of the concepts of Image-guided Therapy.&nbsp; The paper describes the LEGO system and some results from their initial experience.</p><p><br /><strong>Hypothesis:</strong><br />N/A</p><p><br /><strong>Evidence:</strong><br />The description of the LEGO system is reasonable, and the results suggest that it may be a viable teaching tool.</p><p><br /><strong>Open Science:</strong><br />This appears to be open science.&nbsp; The tools used are open.&nbsp; The LEGO system costs money, but as the authors point out, it is reasonable.&nbsp; There is great potential for teach with this tool.</p><p>&nbsp;</p><p><strong>Reproducibility:</strong><br />RESOLVED:&nbsp; While the authors provide some code for combining the LEGO system with 3D slice, the suggested teaching information is not available.&nbsp; Specifically, the authors, show a 3D robot but do not provide the design for it.&nbsp; The authors also talk about a phantom but do not provide the design.&nbsp; I cannot, at this point even with the LEGO system, recreate the system.</p><p><strong>Use of Open Source Software:</strong><br />All of the software described is open including the open interface to the LEGO system.&nbsp; The LEGO system does cost some money, but anyone can get it and it seems that the price is not outrageous.&nbsp; The potential applications of the LEGO system are great.</p><p><strong>Open Source Contributions:</strong><br />The main contribution should be the design of the phantom and robot for use in training along with the source code. This is unfortunately missing.</p><p><strong>Code Quality:</strong><br />The provided code is appropriately documented.</p><p><strong>Applicability to other problems:</strong><br />Once a person invests in the system, there are endless training possibilities.</p><p><strong>Suggestions for future work:</strong><br />RESOLVED: I think that a more detail curriculum with several lessons is warranted.</p><p><br /><strong>Requests for additional information from authors:</strong><br />RESOLVED: I fully recognize the great potential of this work, but request that the authors provide a description of how to build the phantom and robot as well as the proposed tutorial.&nbsp; I would like to use this for teaching.</p><p><br /><strong>Additional Comments:</strong><br />RESOLVED: Again, this is a great teaching tool.&nbsp; I commend the authors, but I don&#39;t have enough information to use it for teaching right now.</p>", "review_id": 544}], "publication_id": 171},
{"reviews": [{"date": "02-18-2008", "author": {"author_id": 171, "author_email": "rupert.brooks@gmail.com", "author_lastname": "Brooks", "author_firstname": "Rupert"}, "content": "<strong>Summary:</strong><br />The authors propose to speed up the implementation of ITKs registration framework both through code optmizations and multithreading. ITKs registration framework is - or perhaps I should say was - regrettably slow. This paper is an excellent and much needed contribution. <br /><br />If imitation is the sincerest form of flattery, the authors should know that I am planning to reimplement much of my own work using the ideas and framework presented here.<br /><br /><strong>Evidence:</strong><br />The majority of the evidence presented is in the form of timing comparisons on two machines. Unfortunately, there are several different speed up methods at work here. It is difficult to discern from the evidence, which code changes are more important. In my reproduction of the work (see below) I noted that there are speedups of both the metric evaluations, and the metric initialization. This is of course good, but this might merit separate analysis.<br /><br /><strong>Open Science:</strong><br />The work adheres to the principles of open science. However - the work was somewhat difficult to reproduce. Recently the code was added to the ITK CVS, which made access to it much easier. However, it was added in such a way that an ITKCVS build seems to either use these classes, or the original versions, but not both. At least, it appears this way - in all honesty i did not try to build them from the Review directory, but came up with my own way. Details follow below. <br /><br /><strong>Reproducibility:</strong><br />I got the code working in nearly its original form. Very significant speedup was immediately apparent, plus of course the new capability of multithreading. As this is a new framework for (mainly) the ITK registration metrics, i implemented some of my own work in this framework. This was not possible to do easily from the document - it was only possible after carefully reading the code.<br /><br />A careful testing approach is essential for any large code optimization project like this. The approach described in the paper seems good. However, I did not reproduce it. The current set up in the ITK CVS seems to preclude testing the old against the new versions of metrics unless one is willing to build two concurrent ITK installs. Even then, how one could write a single program to run one metric, then the other and compare their output was not obvious. I did it my own way see below.<br /><br /><strong>Use of Open Source Software / Open Source Contributions:</strong><br />It is a contribution to the open source ITK project.<br /><br /><strong>Code Quality:</strong><br />The code is of high quality. However, there are three design criticisms that i might make<br />1. A not insignificant part of the speed is due to using memset instead of the Fill() methods. Perhaps the Fill methods should be recoded to use memset instead? Then the speed benefit would appear everywhere that uses them.<br /><br />2. The code for the threaded GetValue and GetValueAndDerivative methods is complex and highly repetitive. As we all know, repetitive code is hard to maintain. I think that the repetition could be reduced somewhat. In particular, i found it possible to compress both the Transform point methods into one. I found other ways of reducing the amount of repeated code in my re-implementation by using a recursive including scheme, but this did make it a bit more difficult to understand. <br /><br />3. The caching of the bspline parameters does give a significant speedup, but at the cost of a MASSIVE use of memory. For any interesting size 3D image, and even many 2D images, it is completely impossible to run this on a 32-bit system. I think there should be a switch to turn this on or off. Yes it runs slower, but its still useful to run it on 32-bit systems on medium size images.<br /><br />Requests for additional information from authors:<br />I think that additional documentation is needed. Not all the modified classes are described, or even listed, in the text. <br />In particular, i found the way the multithreading is actually implemented, and what a user must implement to reproduce their own metric, would benefit from a written thorough explanation. I had to read the code - very carefully - to figure it out.<br /><br />It would also be interesting to have a list of what is different about all the optimized classes. Some independent testing might be valuable. For example, how much of the speed up is due to the interpolator, and how much to the metric? What is the optimized resample filter, it is not discussed in the text.<br /><br />It seems to me that the efficiency of these methods is highly reliant on inlining, especially of the ThreadProcessSample function. This would be interesting to explore. If inlineing is not vital, function pointers could be used, which could simplify the code, i think. On the other hand, if inlining is important, perhaps the transform point method (also called for every pixel) could be inlined. <br /><br />I was curious about the authors thoughts of existing shared memory parallelization methods, in particular openMP, as a way of getting quick multithread gains for low coding effort. This was more a vague thought, than a specific request. Clearly many of the compilers on which ITK is built do not support openMP, so it may not have universal applicability.<br /><br /><strong>Additional Comments:</strong><br /><br /><em>How I reproduced (some of) the work.</em><br /><br />I was using the version in the ITK CVS as of Feb 6, 2008. The rest of the code besides the review directory was ITK 3.4. The optimized classes are intended to replace the nonoptimized classes of the same name - therefore building both alongside each other is difficult. I first renamed all the optimized classes to have the prefix &quot;opt&quot; on their names. I then made the OptImageToImageMetric a subclass of ImageToImageMetric - this way i could plug it into existing code.<br /><br />I trusted the optimized interpolators, so i just began using them directly.<br /><br />I evaluated the metrics a number of times with the old metric implementation, and the new metric implementation, and compared the results. The mean squares metric is numerically identical to the old one. The MI metric is numerically very similar, but not identical. Both optimized metrics are MUCH faster, running single threaded. This is not due to the interpolators - during this test both metrics were using the same interpolators. The metric code itself is significantly more efficient.<br /><br />Running multithreaded, contrary to what is described in the text, I actually found further performance increases (although not even close to linear) running more threads than cores. Specifically 3 threads on a two core machine was noticably better than two. This was a Windows XP 32bit machine, compiler Visual C++ 2003. Its probably some quirk of windows.<br /><br />I did not evaluate the oriented image gradient fix - i have my own way of doing this, discussed elsewhere.<br /><br />I did not evaluate the optimized resample image filter.<br /><br />As a further evaluation of the work, I reimplemented one of my own metrics copying most of the ideas from this framework. I found that it was not too difficult to do, but does require a careful reading of the code - more documentation would have been helpful. The study of the code probably took me a days work. The implementation about 4 hours, and theres still a bug or two to track down. Nevertheless, i conclude that the framework is usable and general and strikes a reasonable balance between efficiency and intelligibility. As mentioned, I did find that the code might be difficult to maintain, due to repetition.<br /><br /><em>Things that may be bugs or errors:</em><br /><br />In the paper (p. 4) it says that the base itkTransform class was modified for thread safety. However, in the ITK CVS Review versions, there is no modified version of itkTransformBase. Furthermore, the classes seem to achieve thread safety by making multiple copies of the transform.<br />------<br />In Figure three, supposedly the old method is being compared to the new method. In the text it is claimed the new method is 6 times faster when run single threaded (probably true, based on my experience). However, the graph starts at 1. I dont think it graphs the right thing.<br />-------<br />in itkOptImageToImageMetric.txx<br /><br /> // If user provided a mask over the Moving image<br /> if ( m_MovingImageMask )<br /> {<br /> // Check if mapped point is within the support region of the moving image<br /> // mask<br /> sampleOk = m_MovingImageMask-&gt;IsInside( mappedPoint );<br /> }<br /> else<br /> {<br /> // Check if mapped point inside image buffer<br /> sampleOk = m_Interpolator-&gt;IsInsideBuffer( mappedPoint );<br /> }<br /> <br />I think that being inside the moving image mask does not guarantee that the point is inside the valid region of the moving image. I think both tests should be done.<br />-------<br />There is a minor inconsistency in that the stub for ThreadPostProcess is placed in the header, and the stubs for the other two are in the .txx<br />-------<br /><br /> <br /> ", "review_id": 644}, {"date": "09-12-2007", "author": {"author_id": 20, "author_email": "holmes.david3@mayo.edu", "author_lastname": "Holmes", "author_firstname": "David"}, "content": "<p><strong>Summary:</strong><br />The authors describe the optimization of the ITK registration framework for multi-processor systems.&nbsp; This includes some code optimization, making everything thread-safe, and threading several of the processing steps.&nbsp; The authors are targeting various transforms, metrics, interpolators, and solvers.</p><p><strong>Hypothesis:</strong><br />The hypothesis is that multi-threading will improve the computational performance of the ITK registration code.</p><p><br /><strong>Evidence:</strong><br />The authors have implemented and tested the code on several platforms.&nbsp; They present the results for two of the systems that they ran on.&nbsp; The results are consistent with expectations.<br /><br /><strong>Open Science:</strong><br />In true ITK form, the work is completely open.<br /><br /><strong>Reproducibility:</strong><br />I have to admit that I have not had a chance to download and run the code.&nbsp;<br /><br /><strong>Use of Open Source Software:</strong><br />The method was implemented in ITK.&nbsp; There was some use of BWHITK which I would guess is also available if I went looking for it.&nbsp; Valgrind was used for profiling which is open.&nbsp; Unfortunately, neither vtune nor ltprof are open source.&nbsp;<br /><br /><strong>Open Source Contributions:</strong><br />Great contribution<br /><br /><strong>Code Quality:</strong><br />Not evaluated<br /><br /><strong>Applicability to other problems:</strong><br />Well, this is the first of my two little issues.&nbsp; It is not about the work, which is incredible valuable, but about the details of the paper.&nbsp; One of the most important contributions here is that the authors have expended the energy to optimize multi-threading across platforms.&nbsp; This is the most &quot;applicable&quot; component of the work.&nbsp; Unfortunately, there is only one paragraph on the optimization process in which the authors state &quot;certain changes and parameterizations could improve performance on one platform and degrade performance on others....&quot;&nbsp; There are no details about the difference by platform or proposed explanations why this is.&nbsp; If someone is looking to develop cross-platform code that is multi-threaded, they might look to this article and find it lacking in that detail.&nbsp; If this has been previously explained, then I would simply suggest including a reference.<br /><br /><strong>Suggestions for future work:</strong><br />Speed is one of the major issues with optimized software, and the authors have addressed this issue very well.&nbsp; The other issue -- which can be at direct odds with the speed -- is the use of memory.&nbsp; Algorithms which require large amounts of memory are either slower or require machines with gobs (sorry for the technical jargon) of memory -- like 128 GB.&nbsp; In addition, making thread-safe code will result in more memory usage.&nbsp; This issue has not been discussed; it will be valuable to run this same set of tests and report the memory usage as the threads go up.</p><p><br /><strong>Requests for additional information from authors:</strong><br />Only the in the two areas noted above.<br /><br /><strong>Additional Comments:</strong><br />Congratulations on moving in this direction.&nbsp; Optimization is such an important process to make usable software particularly given the magnitude of the problems in medical imaging.</p>", "review_id": 566}, {"date": "09-13-2007", "author": {"author_id": 322, "author_email": "agouaillard@gmail.com", "author_lastname": "Gouaillard", "author_firstname": "Alexandre"}, "content": "<p><strong>Summary:</strong><br /> this paper report the first results of a multithreaded implementation of the ITK registration framework. Dedicated metrics and test environment has been developed to compare the new implementation with the previous one on different plateforms, with different environments and depending on the number of thread used.<br /> <br /> <strong>Hypothesis:</strong><br /> * multicore/multi cpu are ubiquitous or about to be (85% of intel CPU are currently at least dual core).<br /> * using all the core/cpu should improve the performances<br /> * the improvment should happen across plateform and OSes.&nbsp;</p><p><strong>Evidence:</strong><br /> The speed comparison depending on the number of thread have been plotted and illustrate the gain. Example are multiple and show clearly that users will gain from using the new implementation, whatever filter/metric/oprtimizer they use in the registration framework and whatever plateform they are working on. That was the main target of the work, and we can say: Work well done!<br /> Note: It seems that part of the gain was made from code optimisation and not multihreading. <br /> </p><p>It seems that using more threads is interesting as long as the number of threads is not greater than the number of cores/CPU. If the number of thread is higher, we see the performance decrease. It would be nice to have the filters decide ow many thread they want to use automatically. It does not seems to be consistent enough across platforms or threading implementation to be able to do so. Another point not discussed on the paper but discussed intensively on the itk-develloper mailin glist is that it depends on the multithreading implementation: does the filter creates and destroy threads, or does it access a pool of shared threads? This question is under investigation.</p><p>One very interesting part of the work is the implementation of the cross-platform multithreading testing and benchmarking tool. Mixing BatchMake and CMake seems to provide good results. It would be interesting in the future to use this tool for other multithreading implementations (the Mesh part of ITK would be my first target, but I&#39;m kind of biased). The authors also experiment a lot with different profiling tools and timing tools, I think many users would be interested in knowing which tools they used (they mention valgrind, but I suppose they mean cachegrind), what kind of experiment they did and what ther conclusion were about the pros and the cons of each tools. That is outside the scope of this paper, but that would make a great wiki page. <br /> </p><p><strong>Open Science:</strong><br />In ITK spirit, the author provide the code under BSD and the IJ article under CC. The code should be integrated in ITK post 3.4 release. It must be noted that modification of this magnitude can not be integrated in ITK at once. The quality process, that insure that the code is stable on an almost daily basis prevent that from happening.&nbsp; </p><p><strong>Reproducibility:</strong><br /> Checking out an older version of ITK, i could compile it and run a basic test. The amount of work needed to reproduce the result was such that I did not even try. Teh current version does not compile, but it should be only a matter of weeks before it is available in the CVS version of ITK.<br /> <br /> <strong>Use of Open Source Software:</strong><br />ITK</p><p> <strong>Open Source Contributions:</strong><br />integration in ITK in progress.</p><p><strong>Code Quality:</strong><br />Master Luis checked it, it should be good. Test are provided. Along the main line of work , the authors took the time to profile the application and found many improvements, not only on speed, but also on combinaitions of filters/metrics/optimizers that had never been tested together before and happened not to work along well. I guess a complete matrix test using all the possible combinations is being developped right now. It should find a lot of potential bugs an improve the overall quality of the registration framework. Thank you for that. </p><p><strong>Applicability to other problems:</strong><br />the multithreading test framework could be reused for other part of ITK, or for any multithreaded code that use CMake, I guess.<br /> A little report on the timing and profiling tools would be of interest.<br /> <br /><br /> <strong>Suggestions for future work:</strong><br />* threading implementation and other issues are being investigated and (intensely) discussed right now.<br /> * better and more complete registration framework tests are being developed.<br /> </p><p>It would be interesting to have results on realy big cases (zebrafish datasets ...) to check if you really have much better improvement in this case as you are expecting. In that case, it would also make the thread pool model more interesting. </p><p>You report that threads and associated items (mutex) implementation on SunOS were especially slow, and I noticed that the SunOS machine used for your test were using sunOS 5.8. It so happen that the SUN threading library is known to be horribly slow, untill sun decided to completely rewrite it. The new library was shipped separatly one year after the release of sunOS 5.8, so your machine might not have it installed. With the current OpenSolaris (or the latest release of 5.10) you should have much better results. I was wondering, out of pure curiosity, what the results would be on one of their &quot;Niagara&quot; box which is optimized for multithreading operations.<br /> <br /><br /> <strong>Requests for additional information from authors:</strong><br />It&#39;s a work on progress. I wil ljust wait for the results. Everything is really interesting indeed.<strong><br /> </strong></p>", "review_id": 570}, {"date": "09-11-2007", "author": {"author_id": 168, "author_email": "torsten@synapse.sri.com", "author_lastname": "Rohlfing", "author_firstname": "Torsten"}, "content": "<p>As the paper itself is labeled &quot;work in progress&quot; in more than one place, I will write a review that I would also consider work in progress. I won&#39;t try to get all details right, I won&#39;t try hard to get things to work, and I won&#39;t try not to step on anybody&#39;s toes by sounding like a smartass. I&#39;ll save all these for later when both the paper and this review converge towards their final forms.</p><p><strong>Observations regarding the software:</strong></p><p> 1. I cannot build the software due to linker errors:</p><pre><p>Linking CXX executable ../../bin/AlignRigidAffine<br />CMakeFiles/AlignRigidAffine.dir/AlignRigidAffineTest.o: In function `main&#39;:<br />AlignRigidAffineTest.cxx:(.text+0x3487): undefined reference to `itk::Optimizer::SetScales(itk::Array const&amp;)&#39;<br />AlignRigidAffineTest.cxx:(.text+0x3843): undefined reference to `itk::Optimizer::SetScales(itk::Array const&amp;)&#39;</p><p>.... [ more errors ] ... </p></pre> <p>I am running Fedora 7 on x86_84 using gcc 4.1.2 and today&#39;s CVS checkout of ITK (August 31, 2007).</p><p><strong>Observations regarding the paper:</strong></p><p>1. The paper listed for citation [Rohlfing, 2003] in the paper is very likely the wrong one. The correct one should probably be T. Rohlfing and C. R. Maurer, Jr., &ldquo;Nonrigid image registration in shared-memory multiprocessor environments with application to brains, breasts, and bees,&rdquo; <em>IEEE Transactions on Information Technology in Biomedicine</em>, vol. 7, no. 1, pp. 16-25, 2003.</p><p><strong>Observations regarding the techniques: </strong></p><p>1. I am very concerned by the use of sparse image sampling in nonrigid registration. I do not trust probabilistic sampling schemes for local deformations, and I doubt it is necessary when the algorithm is otherwise optimized.</p><p>2. Without any consideration as to whether any of these can be easily implemented in the current framework, I would like to mention a number of optimizations that I have found very effective in my own code:</p><ol><li> Each control point of the B-spline transformation effects only a small neighborhood, and gradients can be computed using finite differences by only recomputing the metric contribution of that local region. This leads to computational performance increase of several orders of magnitude. Furthermore, all three degrees of freedom of the same control point (its x,y,z position) effect the same subvolume, so the &quot;baseline&quot; metric of the remaining, unaffected volume can be used three times. </li><li>The B-spline transformation can be computed very efficiently (50% faster) using a scanline algorithm. The control point grid is aligned with the reference image grid, so all pixels within one x image row share the same relative y and z coordinate in the control point grid row and plane. These relative positions are also invariant under changes of the control point positions, so they can be computed once when the transformation object is created. Moreover, all pixels within the same control point cell receive the same contributions from the B-spline basis functions in y and z. So two out of three nested sums in the B-spline formula can be precomputed for all pixels in a given cell. The same observations hold for computing analytical derivatives (e.g., for bending energy and Jacobian matrices).<br /></li><li>The affine pre-registration transformation can be included in the B-spline transformation by interpreting the B-spline output as the transformed vector, rather than as an offset vector. Then, the affine transformation can simply be applied to the control point positions.</li><li>It is not necessarily necessary to have each thread work on a separate copy of the B-spline transformation for finite difference gradient approximation. If local computation of the metric changes (see Item 2.1 above) is used, than degrees of freedom that affect control points separated by more than 4 steps in any direction are entirely independent of each other. One could, therefore, order the control points into a &quot;schedule&quot; in which the next control point is always at least 4 grid steps away from the previous. Such a schedule has a &quot;maximally safe concurrent computation range&quot; associated with it that specifies how many successive control points from the schedule can be moved without affecting one another&#39;s local neighborhoods. This is also the number of parallel threads that can work along the schedule concurrently using the same B-spline parameter array without interfering with each other. The advantage of this technique is that it avoids duplication of the (potentially large) array of B-spline parameters. The downside is that it doesn&#39;t scale as well to larger numbers of CPUs (more than about 3 actually in my experience), although scaling improves as the number of control points increases. I myself have abandoned this idea again, but I thought I&#39;d mention it.</li><li>The paper mentions the possibility of excluding &quot;background&quot; control points from optimization to reduce the number of degrees of freedom and increase performance. There are at least two difference ways to achieve this, and I wanted to comment on the two: the first is &quot;static&quot; in the sense that it analyzes the image data to determine image background (described in Rohlfing et al., MICCAI 2001), the second is more &quot;dynamic&quot; in that it looks at the full cost function gradient and deactivates the control points with low gradient contributions (this was done by Schnabel, Tanner, Rueckert around the same time, but I don&#39;t have the references handy right now). I used to think that the second way was better, because it is more directly related to the gradient, whereas the image background detection is a bit removed from the optimization process. After playing with both techniques, however, I concluded that the static image analysis is preferable (at least for me), especially for large problems (think: groupwise registration), because it does not require to ever compute the full cost function gradient using all degrees of freedom. In cases where the cost of the full gradient is prohibitive, you can still get away very well with the static image background detection in the images themselves. </li></ol><p><strong>Other observations:</strong></p><p> I will go and rummage through my code to check for any other optimizations I may have forgotten about.</p><p> Once I manage to build the new ITK tools, I will perform an direct comparison of my own B-spline with the new one to see how their performance compares. </p>", "review_id": 540}], "publication_id": 172},
{"reviews": [{"date": "09-11-2007", "author": {"author_id": 681, "author_email": "mmattar.cs@gmail.com", "author_lastname": "Mattar", "author_firstname": "Marwan"}, "content": "Overall Review:<br />The algorithm implemented through this paper is of great utility to the medical imaging community. It is implemented in ITK, which means that it will be accessible to a very large user base. A great amount of effort was placed to provide an efficient implementation of the algorithm along with two different transformation models. Their experimental results, while limited, provide sufficient evidence for the correctness of their implementation.<br /><br />Summary: <br />This paper experiments with a new transformation model based on B-splines for an existing joint alignment algorithm. Using the Jacobian of the deformation field within a stochastic optimization framework (in a multi-resolution setting) an efficient implementation of this algorithm is derived. The authors provide an open source implementation of the algorithm and their transformations using ITK. They provide basic experimental results on synthetic data to validate the correctness of their implementation and the similarity in results between affine registration and B-spline registration. <br /><br />Hypothesis: <br />B-splines have not yet been tested as a deformation model within existing Groupwise Registration algorithms. The implicit hypothesis in this work is that the use of B-splines is advantageous, at least for the type of data tested here. <br /><br />However, the major contribution of this work is providing an efficient open source implementation of the Groupwise Registration algorithm that can be used with either affine transformations or B-spline based transformations. <br /><br />Evidence: <br />The authors did not explicitly state that B-spline registration is better or worse than affine registration. No direct, quantitative analysis was performed to show which type of registration worked better. Visually, the results are very similar and it is not clear if B-spline registration provides any advantages over affine registration. Also, the experimental results are somewhat weak since they are based on synthetic data. Especially since the synthetic volumes are created by randomly transforming the same original volume. <br /><br />However, their results do confirm that their implementation of the algorithm using either transformation model is correct. In all 4 experiments, the algorithm produced significantly sharper mean images and an almost black STD image. <br /><br />I disagree that a black STD image is sufficient evidence for a perfect registration (as stated in page 7). One needs to also compare the mean image to the original image used before any random transformations were applied. That way we can ensure that the algorithm is not creating data. The extreme case is if the algorithm changed all the images to purely white, then the STD image will be black but the mean image will be far from reality. <br /><br />Open Science: &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;<br />This paper adheres strongly to the concept of open science. The authors provide an open source implementation of the algorithm and do a good job at describing it. They also provide all experiment parameters and the data used for their experiments. The experiments can easily be replicated by following the steps in Section 5 of the paper. <br /><br />Reproducibility: <br />I downloaded and viewed the provided code but did not attempt to compile it. By viewing the code and my basic understanding of ITK it seems as though one can reproduce the results by simply installing the necessary packages and running a provided script (as outlined in Section 5).<br />&nbsp;<br />Use of Open Source Software: <br />The authors used ITK to implement their algorithm. They did not provide any specific information regarding ITK with respect to its advantages, disadvantages or hints for users. However, ITK is a widely used open source package for registration, I am not sure that such information was necessary. Of course any important information specific to the classes they implemented might have been worth mentioning.<br />&nbsp;<br />Open Source Contributions: <br />The authors provide their code along with a helpful description on how to use it. Since it was implemented using ITK it is in usable form. I have not attempted to use it.<br />&nbsp;<br />Code Quality: <br />Their code is easy to read and since it was implemented with ITK, they followed all the guidelines and good code design enforced by ITK. <br />&nbsp;<br />Applicability to other problems: <br />Groupwise image registration is a very important problem in medical imaging. A large number of researchers will find this implementation of great value.<br /><br />Suggestions for future work: <br /><br />1.&nbsp;&nbsp; &nbsp; More extensive experiments using real data<br />2.&nbsp;&nbsp; &nbsp; A study to compare B-spline registration to affine registration<br />3.&nbsp;&nbsp; &nbsp; Provide run time information for the experiments<br />&nbsp;<br />Requests for additional information from authors: <br />None.<br />&nbsp;<br />Additional Comments: <br />The authors did not give a reason for extending previous work to include B-spline registration. It is not clear from their results if B-spline registration is better or even faster than affine registration. Filling in these gaps would make the paper much more complete.<br />", "review_id": 558}, {"date": "01-30-2008", "author": {"author_id": 762, "author_email": "tomash.kazmar@seznam.cz", "author_lastname": "Kazmar", "author_firstname": "Tomas"}, "content": "<strong>Summary:</strong><br />This entry deals with groupwise registration, that is a registration of multiple images at once without explicit reference frame.<br /><br /><strong><span>Hypothesis:</span></strong><br />Groupwise registration can be efficiently extended by B-spline deformable transform.<br /><br /><strong><span>Evidence:</span></strong><br />The authors provide output of the algorithm, that is test images before and after registration along with mean and standard deviation images. Sharper mean images and zero standard deviation images are interpreted as successful alignment.<br /><br /><strong><span>Open Science:</span></strong><br />Source code as well as input images are provided in the entry. Images used in the paper are not included, although one can expect these are selected from the input images as a result of the included tests. All the details needed to understand the algorithm are contained in the paper.<br /><br /><strong><span>Reproducibility:</span></strong><br />Downloaded, compile and run the tests was a matter of minutes. I did not verify if the results are the same as the tests with 3D volumes are more time expensive than I presumed.<br /><strong><br /><span>Use of Open Source Software:</span></strong><br />Only the Insight toolkit is used.<br /><br /><strong><span>Open Source Contributions:</span></strong><br />Provided source code is clearly described in the appendix to the article and accompanied by numerous tests.<br /><br /><strong><span>Code Quality:</span></strong><br />Source code is properly commented, cleanly divided into separate classes. It is possible to use it without any problem with current ITK, as far as I can tell the code does not involve any non-portable mechanism.<br /><br /><strong><span>Applicability to other problems:</span></strong><br />There are many problems that can benefit from a deformable groupwise registration, specifically where there is a need to bring a set of images into alignment without choosing a pivot/reference frame coordinate system.<br /><br /><strong><span>Suggestions for future work:</span></strong><br />Test the algorithm not only with volume data with synthetic deformations but also test alignment of 2D image sets and non-synthetic deformations.<br /><br /><strong><span>Requests for additional information from authors:</span></strong><br />Script that produces the output images used in the paper should be added.<br /><br /><strong><span>Additional Comments:</span></strong><br />Although B-splines transform used is have been optimized still the speed is not quick,<br />it takes over a minute to align two exactly identical 480x480 images(?).<br /><br />I encountered a bug worth patching, GroupwiseRegistration executable causes memory<br />corruption when registration-&gt;GetLastTransformParameters() is called after resetting the<br />length of parameters array registration-&gt;SetTransformParametersLength(int), this call<br />should be moved to line 1123, after using the old transform parameters.", "review_id": 638}], "publication_id": 173},
{"reviews": [], "publication_id": 174},
{"reviews": [{"date": "10-08-2007", "author": {"author_id": 692, "author_email": "heibel@cs.tum.edu", "author_lastname": "Heibel", "author_firstname": "Hauke"}, "content": "<p><strong>Summary:</strong><br />The paper describes a generalization of the vesselness measure introduced by Frangi which holds for multi-dimensional objects. The author introduces a closed form solution for the computation of N-dimensional objectness.</p><p>The idea to apply the vesselness measure to other structures (noise, plate-like, tubular, blob-like) has already been proposed by Frangi et al. (Multiscale vessel enhancement filtering, Table 1) but the generalized mathematical formulation is to my best knowledge new.</p><p>The author offers a well designed and implemented class to compute a general objectiveness measure as well as a class to compute the objectiveness on multiple scales. </p><p> <strong>Hypothesis:</strong><br />&quot;Non Applicable&quot;.<br /> <br /> <strong>Evidence:</strong><br />The author provides examples for two and three dimensional image data as well as objects of the first two dimensions (blobs, vessels). Furthermore evidence can be found in the mathematical derivation of the general objectiveness measure. </p><p> <strong>Open Science:</strong><br />The paper and its addendums fully adhere to the concept of Open Science. The authors provide the test data, all parameters and sample programs being fully functional.<br /> </p><p><strong>Reproducibility:</strong><br />I did not reproduce the data though I used the author&#39;s classes and applied them to my own datasets which was working as expected.</p><p> <strong>Use of Open Source Software:</strong><br />The authors used ITK and thus used Open Source Software. Their implementation is not depending on any additional third party libraries and can be used out of the box within the ITK framework.</p><p><strong>Open Source Contributions:</strong><br />The code is completely available. It was possible to setup a working and running project in about 10 minutes. </p><p><strong>Code Quality:</strong><br />The source code quality is high. No obviously non-portable mechanisms have been used the code is well documented. </p><p> <strong>Applicability to other problems:</strong><br />n/a </p><p> <strong>Suggestions for future work:</strong><br />Probably some users might be interested in equidistant sigma steps. I would love to see this as an option in a future implementation. I am not yet sure whether something like this should be implemented in terms of an additional template parameter of in terms of an enum and setter and getter methods to switch between different methods. </p><p> <strong>Requests for additional information from authors:</strong><br />n/a</p><p> <strong>Additional Comments:</strong><br />It took me a moment to get the difference between examples A and C, since I was assuming that objectness M=1 is actually vesselness...</p><p>I am not yet fully familiar with the ITK coding guidelines but I think using constructor initialization lists might be preferred to initialization of member variables within the constructors body.</p><p>The m_UpdateBuffer should be reset at each call to generate data, e.g. to itk::NumericTraits::NonpositiveMin().</p><p>The second output, i.e. the scales output should be reset at each call to generate data, e.g. to 0.</p><p>Besides those small remarks a nice work! </p>", "review_id": 590}], "publication_id": 175},
{"reviews": [{"date": "04-16-2008", "author": {"author_id": 480, "author_email": "xabiarta@unav.es", "author_lastname": "Artaechevarria", "author_firstname": "Xabier"}, "content": "<p><strong>Summary:</strong><br /> [Short description of the paper. In two or three phrases describe the problem that was addressed by the authors and the approach they took to solve it.]</p><p>The author presents a complete group of ITK classes to represent and manipulate label objects in ITK. This contribution fulfills a current need within the ITK toolkit. </p><p> <br /> <strong>Evidence:</strong><br /> [Describe the evidence that the authors provide in order to support their claims in the paper. This is a key component on Open Science, opinions that are not supported by evidence should be labeled as &quot;speculations&quot; or &quot;author&#39;s opinion&quot; while. The same rule applies to the text of the reviews: claims should be supported by evidence]</p><p>The author provides enough evidence to all the claims in the paper. Many example images show how the presented filters work. <br /> <br /> <strong>Open Science:</strong><br /> [Describe how much the paper and its addendums adhere to the concept of Open Science. Do the authors provide the source code of the programs used in their experiments? Do the authors provide the input images that they used? Or are those images publicly available? Do the authors provide the output images that they show in the paper? Do the authors provide enough details for you to be able to replicate their work?]</p><p>The paper adheres perfectly to the concept of Open Science. The source code and the images are provided, together with enough explanations to reproduce the results.</p><p><strong>Reproducibility:</strong></p><p>I did not reproduce all the results. I re-used a part of the code for label map creation, label object manipulation and binary image generation from label map image.</p><p> <strong>Use of Open Source Software:</strong><br /> [Did the authors use Open Source software in their work? Do they describe their experience with it, advantages and disadvantages? Do they provide advice for future users of those Open Source packages?]</p><p>The author makes use of ITK. The lack of and need for specific classes for label object manipulation is pointed out. I agree with that point. </p><p> <br /> <strong>Open Source Contributions:</strong><br /> Do the author&#39;s provide their source code?</p><p>Yes&nbsp;</p><p> Is it in a form that is usable?</p><p>Yes, there are ITK classes and practical usage examples.&nbsp;</p><p>Do they describe clearly how to use of the code?</p><p>There are not examples for all classes, but the available examples may be enough to be able to use all the classes.</p><p>How long did it take you to use that code?</p><p>One&nbsp; day.</p><p> <br /> <strong>Code Quality:</strong><br /> If the authors provided their source code: Was the code easy to read? </p><p>Yes</p><p>Did they use a modern coding style?</p><p>Yes, it adheres to the ITK style.&nbsp;</p><p>Was it suitable for multiple-platforms?</p><p>Yes</p><p> <br /> <strong>Applicability to other problems:</strong><br /></p><p>As shown in the article, the presented classes can be used in principle for any kind of images containing different objects, since they can be used for basic label object manipulation.</p><p> <strong>Suggestions for future work:</strong><br /></p><p>Maybe more attributes could be computed. </p><p> <strong>Requests for additional information from authors:</strong><br /><br /> <br /> <strong>Additional Comments:</strong><br />This is a very complete contribution which would be very useful to have inside ITK. </p>", "review_id": 652}, {"date": "07-09-2008", "author": {"author_id": 1018, "author_email": "daniel.blezek@gmail.com", "author_lastname": "Blezek", "author_firstname": "Daniel"}, "content": "<strong>Summary:</strong><br />Classes for efficient as a representation of labels and objects ITK.<br /> <br /> <strong>Hypothesis:</strong><br /> Not applicable.<br /> <br /> <strong>Evidence:</strong><br /> not applicable<br /> <br /> <strong>Open Science:</strong><br /> the software described in this article is completely open including many examples.<br /> <br /> <strong>Reproducibility:</strong><br />&nbsp;&nbsp; Was able to download and compile the code without any issues at all.&nbsp; Code is well documented and very usable.<br /> <br /> <strong>Use of Open Source Software:</strong><br />this package is completely built on ITK.<br /> <br /> <strong>Open Source Contributions:</strong><br />I was able to immediately use the code and incorporated into an internal project.<br /> <br /> <strong>Code Quality:</strong><br />the code does conform to the ITK coding style&nbsp; and is very readable.<br /> <br /> <strong>Applicability to other problems:</strong><br /><br /> <br /> <strong>Suggestions for future work:</strong><br />the main suggestion that I would have for this work is to connect it to the excellence analyze object map reader contributed by Hans Johnson.<br /> <br /> <strong>Requests for additional information from authors:</strong><br /><br /> <br /> <strong>Additional Comments:</strong><br />This contribution to the insight journal is a very welcome addition to the capabilities of ITK.ITK has long lacked classes and facilities for creating and manipulating label images or object maps.&nbsp; In general researchers use ad hoc methods to represent objects and communicate those objects to other programs.&nbsp; With this addition to ITK these ad hoc methods will no longer be required and researchers will be able to use consistent and well written classes for the representation of objects.&nbsp; I was particularly pleased that the object storage method is run length encoding which allows for efficient morphological operators but also consumes less space.<br /> <br /> ", "review_id": 700}, {"date": "09-16-2007", "author": {"author_id": 561, "author_email": "juanparedeswall@yahoo.com", "author_lastname": "Paredes", "author_firstname": "Juan"}, "content": "<p><strong>Summary:</strong><br />ITK lacks classes for computing shape-based attributes of objects contained in binary and labeled images. This paper contributes new classes for calculating such kind of attributes on those kind of images and allow users to conduct morphological operations based on the value of the attributes. </p><p><strong>Hypothesis:</strong><br />Non Applicable.</p><p> <strong>Evidence:</strong><br />Author provided enough background, technical information and implementation detail as evidence of his work. </p><p><br /> <strong>Open Science:</strong><br /> Author adheres to the concept of Open Science. Author provides source code, test images and enough details for readers to be able to replicate his work.</p><p> <strong>Reproducibility:</strong><br /> I downloaded, compiled and run the source code. I&#39;ve got the same results that were reported in the paper.<br /> <br /> <strong>Use of Open Source Software:</strong><br /> Author used ITK toolkit.<br /> <br /> <strong>Open Source Contributions:</strong><br />Author provided source code. Usage examples are also provided. Users can reproduce the author&#39;s work. <br /> <br /> <strong>Code Quality:</strong><br />Code is easy to read. I tested it on Linux (Ubuntu) and gcc 4.1.2. <br /> <br /> <strong>Applicability to other problems:</strong><br />Many computer vision applications use object-based image analysis. Many of them can take advantage of this contribution. </p><p><strong>Suggestions for future work:</strong><br />Author could include other shape-based attributes of objects like perimeter, perimeter/area and lenght/width. Some minor grammatical bugs could be fixed. </p><p><strong>Requests for additional information from authors:</strong><br />None. </p><p><strong>Additional Comments:</strong><br />This is a very valuable contribution. Very well documented and easy to read. Very well done!!!.<br /> <br /> </p>", "review_id": 583}], "publication_id": 176},
{"reviews": [], "publication_id": 177},
{"reviews": [{"date": "09-13-2007", "author": {"author_id": 328, "author_email": "gaetan.lehmann@gmail.com", "author_lastname": "Lehmann", "author_firstname": "Gaetan"}, "content": "<p><strong>Summary:</strong><br /> The authors describe a set of nez ITK classes made to read and write analyze map files, and to manipulate the object within them with ITK.</p><p>Some background about that review: I&#39;m not using the analyze map files, and thus my expertise on that point is quite limited. However, the way the objects are represented in that file format seem really closed to the one I used in the contribution about label object manipulation. I&#39;m reviewing that code with the hope to find some goo ideas, as well as a reader and a writer for the label object contribution. </p><p> <br /> <strong>Open Science:</strong><br />Source code, test programs and teste data are provided - fully open science.<br /> <br /> <strong>Reproducibility:</strong><br />I didn&#39;t reproduced the work. Using that code requires to install it in the ITK tree - I haven&#39;t done it yet. </p><p> <strong>Use of Open Source Software:</strong><br />ITK all the way<br /> <br /> <strong>Open Source Contributions:</strong><br />The authors are providing the source code. I read it, but didn&#39;t use it directly.</p><p><br /> <strong>Code Quality:</strong><br />Code quality is well documented and easy to read.&nbsp;</p><p> <strong>Applicability to other problems:</strong></p><p>That contribution will be useful for everyone who wants to store its label objects (a pretty common need). </p><p> <br /> <strong>Additional Comments:</strong></p><p>While this contribution look very promising to store the label object at the first read, it may be a bit difficult in practice, because of the limitation to 255 objects per map. This limit may not be reached by everybody, but really, it can happen quite easily.</p><p>&nbsp;About the way the&nbsp; way the data associated with the objects: I found quite interesting to have the map stored in a standard image, and the data associated with the objects in that image stored in the metadata of the image. However, I believe that storing the object in memory with the run-length encoding, as it is done in the analyze file format, also have some advantages:</p><p>- a low memory usage&nbsp; (most of the time)</p><p>- a high efficiency for some computations</p><p>- the ability to store the data associated to the object directly in the objects, which make the manipulation of the object easier, and ensure that no metadata will be still there if an object is removed for example </p><p>and some problems:</p><p>- it&#39;s more difficult to ensure the validity of the image (a pixel contain only one object for example)</p><p>- it&#39;s highly inefficient when the neighbors need to be visited</p><p>- it&#39;s a very different image representation than the itk::Image, and thus, it can&#39;t be used in the usual ITK filters (but some filters are available to convert from/to itk::Image)</p><p>&nbsp;</p><p>There are some advantages on both sides, however, I don&#39;t think that&#39;s a good idea to introduce both representation in the toolkit.</p><p>I hope we can discuss about how to integrate those 2 contributions soon :-)&nbsp;</p>", "review_id": 572}, {"date": "03-04-2008", "author": {"author_id": 1018, "author_email": "daniel.blezek@gmail.com", "author_lastname": "Blezek", "author_firstname": "Daniel"}, "content": "<p><strong>Summary:</strong></p><p>This submission is an implementation of an ITK Image IO object and factory for reading Analyze ObjectMaps. The code provides a helper class enabling the formation of object maps within ITK and writing them to disk.</p><p> <br /><strong>Hypothesis:</strong><br /> N/A</p><p> <br /> <strong>Evidence:</strong><br />N/A<br /> <br /> <strong>Open Science:</strong></p><p>All code and examples provided. Highly readable and written in the correct ITK style. The submission shows a deep understanding of ITK and the IO mechanisms.</p><p><br /><strong>Reproducibility:</strong></p><p>While I did not compile the examples and test, after review of the code, I dropped it immediately into my application. No compilation problems and the code works nicely. The static block failed to register the factory however. </p><p><br /> <strong>Use of Open Source Software:</strong></p><p>Library implemented using ITK, with VTK used for visualization. </p><p><br /> <strong>Open Source Contributions:</strong></p><p>No problems compiling and using the code. </p><p> <strong>Code Quality:</strong></p><p>Code compiled cleanly on Win and Linux. Static block failed to register the factory, but I manually initialized the library without issue. Fully documented and written in the ITK style. Was very impressed that the authors support all versions of Analyze&#39;s ObjectMap format.</p><p> <strong>Applicability to other problems:</strong><br />N/A</p><p><br /> <strong>Suggestions for future work:</strong></p><p>Develop a similar, but more flexible format for ITK. Would be useful to have object labels and be able to include a voxel in more than one object, perhaps with different levels of membership or probability. </p><p><br /> <strong>Requests for additional information from authors:</strong><br />N/A</p><p><br /> <strong>Additional Comments:</strong><br />Thanks for the very valuable contribution to ITK!<br /> </p>", "review_id": 647}], "publication_id": 178},
{"reviews": [], "publication_id": 179},
{"reviews": [], "publication_id": 180},
{"reviews": [], "publication_id": 181},
{"reviews": [{"date": "10-15-2007", "author": {"author_id": 156, "author_email": "tom.vercauteren@gmail.com", "author_lastname": "Vercauteren", "author_firstname": "Tom"}, "content": "<p><strong>Summary:</strong><br />The authors propose a new image class that takes into account an orientation matrix in addition to a diagonal spacing matrix and an origin point. The aim is to optimize the conversion of points and gradients between pixel space and physical space in the most commonly used cases. The focus is on providing a solution that is generic enough to cover all possible cases. This topic is very important for registration problems where the conversion can be needed millions of times. The solution proposed by the authors is based on function pointers.</p><p>Overall I think it is a good approach. I would suggest using this idea in the basic itk::Image class and deprecate the itk::OrientedImage class. </p><p> <br /> <strong>Hypothesis:</strong><br />I fully agree with the hypothesis made by the authors:<br />1) Most ITK users will typically use images with a simple combination of orientation matrix, spacing vector and origin<br />2) Many users will need non trivial orientation matrices<br />3) All users care about the performance of registration </p><p> <br /> <strong>Evidence:</strong><br />The authors claim that their solution:<br />1) is as generic as the oriented image class<br />2) can deal with the orientation of gradients<br />3) is often even more efficient than the standard image class<br />55 timing tests are provided to support the author claims. </p><p><br /> <strong>Open Science:</strong><br />The paper fully adheres to the open science concept. The code, the testing framework and the data are provided. The code uses only ITK.</p><p><strong><br />Reproducibility:<br /></strong>I have been able to reproduce the authors work. The only thing I needed to change was a #define SPEEDTESTNUM which by default was set to a ridiculously low value and did not allow me to compare the time taken by the different implementations. On my platform (ubuntu, x86, gcc 4.1.2), the authors fast implementation compared even better with respect to the standard image class.</p><p>A very small README file would be useful to tell the reader what the log files refer to.<br /> </p><p><br /> <strong>Use of Open Source Software:</strong><br />The work uses ITK. The author give a brief comparison of their approach to gradient orientation problems with the one being proposed by the ITK team.</p><p><strong>Open Source Contributions:</strong><br />It took me very little time to compile and run the tests.</p><p><br /> <strong>Code Quality:</strong><br />The code needs a little cleanup to give it a consistent indentation, move out the #define printouts and so on. In itkFastOrientedImage.h a few #include are nor necessary. </p><p> <br /> <strong>Applicability to other problems:</strong><br />The idea of using function pointers to use specialized optimized functions could be used in many ITK classes. A lot of filters could be optimized if, during their initialization, a function pointer was set to point to an efficient specialized function. </p><p> <br /> <strong>Suggestions for future work:</strong><br />As mentioned by the authors, the use of function pointers forbids the compiler to inline the function. This has a performance price. The author claim that using specialized template classes would lead to an even better performance. This approach is however less generic than the previous one as it has to be decided at compile-time rather than run-time. For some users, compile-time may be fine. It would thus be great to include for example a very basic image class that only allows for unit orientation, unit spacing and zero origin. This would prove the author claim and let the user decide whether the added performance is worth the loss of genericness.</p><p>Many specific cases are not addressed. If the orientation matrix (including spacing or not) is composed of only 1s and -1s, optimized version can also be designed. It would be nice to have all those specialized versions, even though it becomes tricky :)<br /><br /> <br /> <strong>Additional Comments:</strong><br />In the current constructor, the orientation and spacing are set to the identity and the origin is set to zero but the function pointers are set to the generic cases. I would be more consistent and make more sense to point to the specialized version.</p><p>The authors claim that &quot;there is no point implementing a set of functions for TransformPhysicalPointToIndex&quot;. At first this puzzled me. It would be clearer to say something like &quot;there is no point implementing a set of specialized functions for TransformPhysicalPointToIndex because the generic one cannot really be improved.&quot;</p><p>In the code, I saw:<br /> // cast to integer is really really slow... maybe rewrite in assembly later.<br />#define RealToInt(A) static_cast(A)<br />A first improvement may come from using vcl functions. Then it might be worth looking at how this issue is addressed in the BSplineInterpolator. See http://www.itk.org/Bug/view.php?id=2078 for a discussion of its accuracy.<br /> </p>", "review_id": 594}], "publication_id": 182},
{"reviews": [{"date": "10-18-2007", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<p>When using open-source data, please include any citations requested by the person who donated the data, as well as the link to where the data can be found.</p><p><br />The details on the data used are published on MIDAS:</p><p>http://insight-journal.org/midas/view_community.php?communityid=21</p><p>The data was donated by Dr. Bullitt at UNC and she has provided a reference.</p>", "review_id": 599}], "publication_id": 183},
{"reviews": [{"date": "10-18-2007", "author": {"author_id": 1, "author_email": "stephen.aylward@kitware.com", "author_lastname": "Aylward", "author_firstname": "Stephen"}, "content": "<p>When using open-source data, please include any citations requested by the person who donated the data, as well as the link to where the data can be found</p><p>The details on the data used are published on MIDAS:</p><p>http://insight-journal.org/midas/view_community.php?communityid=21</p><p>The data was donated by Dr. Bullitt at UNC and she has provided a reference.</p>", "review_id": 598}], "publication_id": 184},
{"reviews": [], "publication_id": 186},
{"reviews": [], "publication_id": 187},
{"reviews": [], "publication_id": 188},
{"reviews": [], "publication_id": 189},
{"reviews": [{"date": "10-25-2007", "author": {"author_id": 704, "author_email": "edmanm2@cs.rpi.edu", "author_lastname": "Edman", "author_firstname": "Matt"}, "content": "<p><strong>Summary:</strong><br />The author uses a confidence connected region growing algorithm to segment the ventricles of the brain in a medical image.<br /> <br /> </p><p><strong>Evidence:</strong><br />For evidence, the author has provided his source code, sample input, and expected output so a reviewer can independently verify the results.</p><p> <br /><strong>Open Science:</strong><br />This paper adheres to the concept of Open Science by including all source code, documentation, and sample data necessary to reproduce the author&#39;s work.</p><p><br /> <strong>Reproducibility:</strong><br />I reproduced the author&#39;s work by downloading, compiling, and running the code. I was able to get the same results given in the paper. The output produced by the source code was also the same as the sample output included with the paper. In this reviewer&#39;s opinion, no further improvements are necessary for future readers to reproduce this work. </p><p><br /> <strong>Use of Open Source Software:</strong><br />The author did use open source software in his work. No particular experiences or advantages of using open source were described in the paper.</p><p> <br /> <strong>Open Source Contributions:</strong><br />The author&#39;s source code was provided and is in a usable form. No particular instructions were included as to how to compile the code, but anyone mildly familiar with CMake and C++ will have no trouble building the executable. The author did describe the command line arguments required by the resulting executable.</p><p> <br /> <strong>Code Quality:</strong><br />The authors code is easy to read and does not appear to rely on any platform-specific mechanisms. Thus, it should be sufficiently portable. The coding style is not one preferred by this reviewer, but it is consistent with the Insight Toolkit. The source file did contain Windows-specific line endings (CRLF instead of LF), but any compiler worth using has no trouble with either form of line ending. </p><p> <br /> <strong>Applicability to other problems:</strong><br />The authors methods seem applicable to any image analysis problem where a confidence connected region growing algorithm is appropriate.</p><p> <br /> <strong>Suggestions for future work:</strong><br />A link to the online database from which you obtained the sample input data could be useful.</p><p> <br /><strong>Requests for additional information from authors:</strong><br />None.<br /> </p><p><strong>Additional Comments:</strong><br /> <br /> </p>", "review_id": 605}], "publication_id": 190},
{"reviews": [], "publication_id": 191},
{"reviews": [], "publication_id": 192},
{"reviews": [], "publication_id": 193},
{"reviews": [], "publication_id": 194},
{"reviews": [], "publication_id": 195},
{"reviews": [], "publication_id": 196},
{"reviews": [], "publication_id": 197},
{"reviews": [], "publication_id": 198},
{"reviews": [], "publication_id": 199},
{"reviews": [], "publication_id": 200},
{"reviews": [], "publication_id": 201},
{"reviews": [], "publication_id": 202},
{"reviews": [], "publication_id": 203},
{"reviews": [], "publication_id": 204},
{"reviews": [], "publication_id": 207},
{"reviews": [], "publication_id": 208},
{"reviews": [], "publication_id": 209},
{"reviews": [], "publication_id": 210},
{"reviews": [], "publication_id": 211},
{"reviews": [], "publication_id": 213},
{"reviews": [], "publication_id": 216},
{"reviews": [], "publication_id": 217},
{"reviews": [], "publication_id": 218},
{"reviews": [], "publication_id": 228},
{"reviews": [], "publication_id": 230},
{"reviews": [], "publication_id": 231},
{"reviews": [], "publication_id": 237},
{"reviews": [{"date": "06-17-2008", "author": {"author_id": 168, "author_email": "torsten@synapse.sri.com", "author_lastname": "Rohlfing", "author_firstname": "Torsten"}, "content": "<p><strong>Summary:</strong><br /> </p><p>A class for generating a deformation field based on a parametric coordinate transformation.</p><p>&nbsp;<strong>Open Science:</strong><br /> </p><p>&nbsp;Source code and test data are included.</p><p><br /> <strong>Reproducibility:</strong></p><p>The code compiles out of the box with current ITK. Tests provided by the authors run successfully. Did not test withmy own data.</p><p><br /> <strong>Use of Open Source Software:</strong><br /> Extension to ITK.</p><p><br /> <strong>Open Source Contributions:</strong><br /> All source code is included and immediately usable.</p><p><br /> <strong>Code Quality:</strong></p><p>The code quality is on par with ITK. </p><p><br /> <strong>Requests for additional information from authors:</strong><br /> </p><p>The use of a reference image to define the output field structure is not documented in the paper.</p><p>Class member variables (e.g., m_OutputSize) are documented, but not using Doxygen convention.</p><p><br /> <strong>Additional Comments:</strong><br /> </p><p>This is a small and straightforward but very useful addition to ITK. It provides, for example, a systematic way to feed parametric transformations into deformable registration algorithms (PDE-type) as initial transformations.</p>", "review_id": 663}, {"date": "06-19-2008", "author": {"author_id": 156, "author_email": "tom.vercauteren@gmail.com", "author_lastname": "Vercauteren", "author_firstname": "Tom"}, "content": "<p><strong>Summary:</strong><br /> The title is pretty explicit. The author propose a filter that takes a spatial transformation as input and generates a deformation field that reproduces the spatial mapping of the input transformation. This is important for example to initialize a non-parametric registration algorithm with the result of a parametric image registration scheme. </p><p>It is great to see that the filter is multi-threaded and uses an optimized path for linear spatial transformations. </p><p>The submission is well-written but needs some more work in terms of testing and concept checking.</p><p>I would thus recommend that this submission be integrated within ITK provided that the testing be reinforced. </p><p> <br /> <strong>Hypothesis:</strong><br /> The spatial mapping to be mimicked can of course only be represented by a deformation field on a finite region of interest and with a given interpolation grid.<br /> <br /> <strong>Evidence:</strong><br /> The authors provide some unit tests to check that the filter behaves as it does on their machine. It is already a good thing to have this unit test but I would recommend increasing the testing coverage. Here is a proposed testing procedure.</p><ol><li>Generate some 2D and 3D random scalar images with different sizes/origin/spacing/direction (or use some given input images)<br /></li><li>Generate some random spatial transformations (or use some given input spatial transformations)</li><li>Use a resample filter to warp the scalar images with the spatial transformations</li><li>Generate some deformation fields from the spatial transformations using the contributed filter with different output&nbsp; sizes/origin/spacing/direction with some constraints (e.g. spacing smaller that the scalar image spacing)</li><li>Use a warp filter to warp the scalar images with the generated deformation fields</li><li>Compare the images warped through the spatial transformation with the ones warped through the deformation field<br /></li></ol><p> <br /> <strong>Open Science / </strong><strong>Use of Open Source Software / </strong><strong>Open Source Contributions</strong><strong>:</strong><br /> The contribution fully adheres to those concepts.<br /> <br /> <strong>Reproducibility:</strong><br /> Compiling and running the tests was straightforward. I would however recommend packaging the files differently to let the automatic testing system do its job.<br /> <br /> <strong>Code Quality:</strong><br /> The quality of the filter is up to ITK&#39;s standards. I would however add some concept checking to it, such as:</p><p>&nbsp;itkStaticConstMacro(PixelDimension, unsigned int,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; OutputPixelType::Dimension );</p><p>&nbsp;#ifdef ITK_USE_CONCEPT_CHECKING<br />&nbsp; /** Begin concept checking */<br />&nbsp; itkConceptMacro(SameDimensionCheck,<br />&nbsp;&nbsp;&nbsp; (Concept::SameDimension));<br />&nbsp; /** End concept checking */<br />#endif</p><p>&nbsp;</p><p>The testing code should however be better documented. </p><p> <br /> <strong>Suggestions for future work:</strong><br /> </p><ul><li>Improve the unit tests</li><li>Add some concept checking</li><li>Add a link to <a href=\\\"http://hdl.handle.net/1926/510\\\" target=\\\"_blank\\\">http://hdl.handle.net/1926/510</a> that already provided a filter doing the same thing but without the cool features presented here (multi-threading, linear transformation optimization, unit testing)</li><li>Add some documentation such as &quot;This source object expects the image to be of pixel type Vector.&quot;<br /></li></ul><p>&nbsp;</p>", "review_id": 666}], "publication_id": 240},
{"reviews": [], "publication_id": 242},
{"reviews": [], "publication_id": 244},
{"reviews": [], "publication_id": 247},
{"reviews": [], "publication_id": 249},
{"reviews": [], "publication_id": 272},
{"reviews": [], "publication_id": 285},
{"reviews": [], "publication_id": 296},
{"reviews": [], "publication_id": 298},
{"reviews": [], "publication_id": 299},
{"reviews": [{"date": "08-26-2008", "author": {"author_id": 3102, "author_email": "xiaoxiao.liu@kitware.com", "author_lastname": "Liu", "author_firstname": "Xiaoxiao"}, "content": "<p>&nbsp;I had some experience with processing&nbsp; labeled images using this filter. </p><p>&nbsp;It is a very neat filter that wraps many useful statistics features from labeled regions or objects. It uses hash map to&nbsp; store and look up&nbsp; the features&nbsp; for each labeled region, which makes the filter computationally efficient. </p><p>The code itself is very well documented and structured.&nbsp; </p>", "review_id": 752}, {"date": "08-24-2008", "author": {"author_id": 953, "author_email": "kuttek@rpi.edu", "author_lastname": "Kutten", "author_firstname": "Kwame"}, "content": "<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves/> <w:TrackFormatting/> <w:PunctuationKerning/> <w:ValidateAgainstSchemas/> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF/> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables/> <w:SnapToGridInCell/> <w:WrapTextWithPunct/> <w:UseAsianBreakRules/> <w:DontGrowAutofit/> <w:SplitPgBreakAndParaMark/> <w:DontVertAlignCellWithSp/> <w:DontBreakConstrainedForcedTables/> <w:DontVertAlignInTxbx/> <w:Word11KerningPairs/> <w:CachedColBalance/> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\"Cambria Math\"/> <m:brkBin m:val=\"before\"/> <m:brkBinSub m:val=\"&#45;-\"/> <m:smallFrac m:val=\"off\"/> <m:dispDef/> <m:lMargin m:val=\"0\"/> <m:rMargin m:val=\"0\"/> <m:defJc m:val=\"centerGroup\"/> <m:wrapIndent m:val=\"1440\"/> <m:intLim m:val=\"subSup\"/> <m:naryLim m:val=\"undOvr\"/> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\"/> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\"/> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\"/> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\"/> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\"/> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\"/> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\"/> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\"/> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\"/> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\"/> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\"/> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\"/> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\"/> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\"/> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\"/> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\"/> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\"/> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\"/> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\"/> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\"/> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\"/> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\"/> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\"/> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\"/> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\"/> </w:LatentStyles> </xml><![endif]--> <!-- /* Font Definitions */ @font-face \t{font-family:\"Cambria Math\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:1; \tmso-generic-font-family:roman; \tmso-font-format:other; \tmso-font-pitch:variable; \tmso-font-signature:0 0 0 0 0 0;} @font-face \t{font-family:Calibri; \tpanose-1:2 15 5 2 2 2 4 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:swiss; \tmso-font-pitch:variable; \tmso-font-signature:-1610611985 1073750139 0 0 159 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmso-style-next:\"No Spacing\"; \tmargin:0in; \tmargin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:12.0pt; \tmso-bidi-font-size:11.0pt; \tfont-family:\"Times New Roman\",\"serif\"; \tmso-fareast-font-family:Calibri;} p.MsoNoSpacing, li.MsoNoSpacing, div.MsoNoSpacing \t{mso-style-priority:1; \tmso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmargin:0in; \tmargin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:12.0pt; \tmso-bidi-font-size:11.0pt; \tfont-family:\"Times New Roman\",\"serif\"; \tmso-fareast-font-family:Calibri;} .MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:Calibri; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} .MsoPapDefault \t{mso-style-type:export-only; \tmargin-bottom:10.0pt; \tline-height:115%;} @page Section1 \t{size:8.5in 11.0in; \tmargin:1.0in 1.0in 1.0in 1.0in; \tmso-header-margin:.5in; \tmso-footer-margin:.5in; \tmso-paper-source:0;} div.Section1 \t{page:Section1;} --> <!--[if gte mso 10]> <style> /* Style Definitions */ table.MsoNormalTable \t{mso-style-name:\"Table Normal\"; \tmso-tstyle-rowband-size:0; \tmso-tstyle-colband-size:0; \tmso-style-noshow:yes; \tmso-style-priority:99; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmso-padding-alt:0in 5.4pt 0in 5.4pt; \tmso-para-margin-top:0in; \tmso-para-margin-right:0in; \tmso-para-margin-bottom:10.0pt; \tmso-para-margin-left:0in; \tline-height:115%; \tmso-pagination:widow-orphan; \tfont-size:11.0pt; \tfont-family:\"Calibri\",\"sans-serif\"; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:\"Times New Roman\"; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin;} </style> <![endif]--> <p class=\"MsoNormal\"><strong>Summary:</strong></p> <p class=\"MsoNormal\"><span>The authors described a filter which can be used to determine the properties (volumes, centroids, ...) of regions in an labeled ND image.<span>&nbsp; </span>It is similar to MATLAB&rsquo;s &quot;regionprops&quot; command.</span><br /> <br /> <strong>Open Science:</strong><span></span></p> <p class=\"MsoNormal\">The authors provided the source code and a test image.<span>&nbsp; </span>This was enough to replicate their work.<br /> <br /> <strong>Reproducibility:</strong></p> <p class=\"MsoNormal\"><span>I was able to reproduce the authors&rsquo; work.<span>&nbsp; </span>The test code compiled and ran without any modifications in Visual Studio 2005 on Windows XP.<span>&nbsp; </span>I integrated the code into a project I am working on.<span>&nbsp; </span>I used this filter to find the centroids, volumes and eccentricities of </span>regions in a 2D binary image.</p> <p class=\"MsoNormal\"><br /> <strong>Use of Open Source Software:</strong><span></span></p> <p class=\"MsoNormal\">The authors used ITK, an open source library.</p> <p class=\"MsoNormal\"><br /> <strong>Open Source Contributions:</strong><br /> The authors provided the filter&rsquo;s source code, test code and a test image.<br /> <br /> <strong>Code Quality:</strong></p> <p class=\"MsoNormal\">The test code (itkLabelGeometryImageFilterTest.cxx) and source was easy to follow and understand.</p> <p class=\"MsoNormal\"><br /> <strong>Additional Comments:</strong><br /> This was very useful in translating MATLAB code which used &quot;regionprops&quot; to C++.</p> ", "review_id": 751}, {"date": "08-19-2008", "author": {"author_id": 951, "author_email": "sunzh@research.ge.com", "author_lastname": "Sun", "author_firstname": "Zhaohui"}, "content": "I have used the filter in my project. It has some nice features that I wanted but could not find in ITK. The filter has worked well and I have not had any errors so far. ", "review_id": 750}], "publication_id": 301},
{"reviews": [], "publication_id": 302},
{"reviews": [], "publication_id": 303},
{"reviews": [], "publication_id": 304},
{"reviews": [], "publication_id": 305},
{"reviews": [], "publication_id": 306},
{"reviews": [], "publication_id": 307},
{"reviews": [], "publication_id": 308},
{"reviews": [], "publication_id": 309},
{"reviews": [], "publication_id": 310},
{"reviews": [], "publication_id": 311},
{"reviews": [], "publication_id": 312},
{"reviews": [], "publication_id": 313},
{"reviews": [], "publication_id": 314},
{"reviews": [], "publication_id": 315},
{"reviews": [], "publication_id": 316},
{"reviews": [], "publication_id": 317},
{"reviews": [], "publication_id": 318},
{"reviews": [], "publication_id": 319},
{"reviews": [], "publication_id": 320},
{"reviews": [], "publication_id": 321},
{"reviews": [], "publication_id": 322},
{"reviews": [], "publication_id": 323},
{"reviews": [], "publication_id": 324},
{"reviews": [], "publication_id": 543},
{"reviews": [], "publication_id": 544},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 832, "author_email": "grandj@mech.uwa.edu.au", "author_lastname": "Joldes", "author_firstname": "Grand roman"}, "content": "<p><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\"><font size=\"3\">&nbsp;&nbsp;&nbsp; In this paper the authors propose a registration method that combines a registration metric, a nonlinear elastic regularization and an unbiased registration constraint. The registration metric can be defined in terms of intensity matching or as mutual information. An additional unknown that approximates the Jacobian matrix is introduced in order to simplify the minimization process.</font></span></p><p><font size=\"3\"><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">&nbsp;&nbsp; </span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">Although the authors say they are interested in parameter free registration methods, the proposed method has quite a few parameters (&lambda;, &beta;, &nu;, &mu;), whose selection criteria is not described in the paper. </span></font></p><p><font size=\"3\"><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">&nbsp;&nbsp; </span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">One important part missing from this paper is the validation of the proposed algorithm (accuracy, convergence) using quantitative results. The qualitative results presented do not give any indication about the performance of the algorithm.</span></font></p><p><font size=\"3\"><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">&nbsp;&nbsp; </span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">Paragraph 2.1: some references describing the metrics would be useful, especially for the mutual information metric derivation and computation of the intensity distributions.</span></font></p><p><font size=\"3\"><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">&nbsp;&nbsp; </span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">Paragraph 2.2:<span>&nbsp; </span>the regularization term might not correctly describe the elastic behavior of the organ. For example, an organ could have sections with different material properties (both for the stored energy function and for the elastic material constants). In such a case the regularization term might introduce more errors instead of making the solution more accurate.</span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\"><span>&nbsp;</span></span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">&nbsp;</span></font> </p><p>&nbsp;</p>", "review_id": 1485}], "publication_id": 549},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 832, "author_email": "grandj@mech.uwa.edu.au", "author_lastname": "Joldes", "author_firstname": "Grand roman"}, "content": "<p><br /><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\"><font size=\"3\">&nbsp;&nbsp; In this paper the authors propose a method of computing external forces that would reproduce the cyclical movement of an organ when applied to a FEM model of the respective organ. The recovered external forces for each node are divided between elements surrounding the node and expressed in local coordinate systems created from the surrounding elements&rsquo; geometry in order to accommodate large deformations or rigid motion of the organ. External forces from a surgical tool can be added to the recovered forces in order to simulate the interaction between the tool and the organ.</font></span></p><p><font size=\"3\"><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">&nbsp;&nbsp; </span><span style=\"font-family: &#39;Times New Roman&#39;,&#39;serif&#39;\">The displacements of the nodes are computed using a B-spline registration method, which register the original mesh to following deformation phases. Clearly these displacements might not correspond to the real ones, and the recovered forces will depend on the registration method used. Therefore, the stress state inside the organ might not be represented properly and the predicted organ&rsquo;s response to external forces might not be accurate (especially for non-linear material models). The representation of the recovered nodal forces in the local coordinate system might also introduce additional errors. These aspects should be considered and a careful validation of the method must be done. No validation results are presented in the paper.<span>&nbsp;&nbsp;&nbsp; </span></span></font></p>", "review_id": 1481}], "publication_id": 550},
{"reviews": [{"date": "07-07-2008", "author": {"author_id": 899, "author_email": "tduttar@mech.uwa.edu.au", "author_lastname": "Dutta roy", "author_firstname": "Tonmoy"}, "content": "<strong><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Paper authors and title: </p><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span><span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">A mix resolution Bone related statistical deformation model for soft tissue prediction in Orthognathic surgery planning</font></font></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\"><span>Qizhen He et al.</span></font></font><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Please, rank the following on the scale from 1 (worst) to 5 (best)</p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Methodological originality<span> </span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Biologic originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Completeness of discussion <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Appropriate references <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Organisation <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Clarity <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>4</p><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Is the technical treatment plausible and free from technical errors?<span>&nbsp;&nbsp;&nbsp; </span>Yes <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\"><font face=\\\"\\\\\\\\\\\\&quot;Times\\\">Have you checked the equations<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>NA<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></font></p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Are you aware of prior publication or presentation of this work<span> </span>No</p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Is the paper too long<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>No</p><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Recommendation:</p><span><span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">(A)</font><span>Accept </span></span></span><span><span><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">(B) Accept subject to minor revisions</p></span><span><span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">(C)</font><span>Accept with major revisions</span></span></span><span><span><span><span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">(D)</font><span>Reject</span></span></span><span><span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Accept with major revisions</p></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</p></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Poster</p></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">Comments to the manuscript:</p></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">An interesting approach to solving complicated solid mechanics problems. I have a few comments:</p></span><span><font face=\\\"\\\\\\\\\\\\&quot;Times\\\" size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">&nbsp;</font></span> <span><span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">a)</font><span>The FEM used, is it fully non-linear (finite deformation, constitutive law and non-linear boundary conditions)? </span></span></span><span><span><span><span><font size=\\\"\\\\\\\\\\\\&quot;2\\\\\\\\\\\\&quot;\\\">b)</font><span>How have the authors determined appropriate boundary conditions for the model? The deviations in results with increased samples [Fig 4 (b)]<span>&nbsp; </span>could be due to inappropriate boundary conditions used in the FEM.</span></span></span><span><span> <p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">&nbsp;</p><p class=\\\"\\\\\\\\\\\\&quot;MsoNormal\\\\\\\\\\\\&quot;\\\">References</p></span></span></span></span></strong>", "review_id": 1502}], "publication_id": 551},
{"reviews": [{"date": "07-04-2008", "author": {"author_id": 875, "author_email": "v.rajagopal@auckland.ac.nz", "author_lastname": "Rajagopal", "author_firstname": "Vijayaraghavan"}, "content": "<p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Please, rank the following on the scale from 1 (worst) to 5 (best)</span></strong></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Originality <span> </span>2</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Methodological originality<span> </span><span> </span>2</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Biologic originality <span> </span>2<span> </span></span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Completeness of discussion <span> </span>3</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Appropriate references <span> </span>3</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Organisation <span> </span>3</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Clarity <span> </span><span> </span>3</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Is the technical treatment plausible and free from technical errors?</span></strong><span><span> </span><span> </span>No</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Have you checked the equations</span></strong><span><span> </span>no</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Are you aware of prior publication or presentation of this work</span></strong><span><span> </span>no</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Is the paper too long<span> </span></span></strong><span><span> </span>no</span></p><p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span><br /></span><strong><span>Recommendation:</span></strong></p> <p style=\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\" class=\"MsoNormal\"><!--[if !supportLists]--><span><span>(A)<span> </span></span></span><!--[endif]--><span>Accept </span></p> <p style=\"margin-left: 0.25in; text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>(B) Accept subject to minor revisions</span></p> <p style=\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\" class=\"MsoNormal\"><!--[if !supportLists]--><span><span>(C)<span> </span></span></span><!--[endif]--><span>Accept with major revisions</span></p> <p style=\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\" class=\"MsoNormal\"><!--[if !supportLists]--><span><span>(D)<span> </span></span></span><!--[endif]--><span>Reject</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>D, Reject</span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</span></p> <p class=\"MsoNormal\"><span> </span><strong><span>Comments to the manuscript:</span></strong></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>At first glance I thought that the paper would present a novel contact-mechanics implementation (or modifications to existing implementations of this difficult problem). But, as I read on I realised that the paper explains, in a complicated way, that displacements can be applied to nodes of the brain that appear to penetrate the skull so that they touch the surface of the skull. A simulation using an explicit scheme is then run to obtain total brain deformation. Although the search algorithm may be novel, I do not believe this to be immediately relevant to the workshop community. More relevant results would include patient validation studies and comparison of performance of the presented simulation studies with true contact-mechanics simulations. It is unclear to me how accurate this technique is and how accurate it needs to be. I would therefore argue to reject this paper. </span></p>", "review_id": 1500}, {"date": "07-04-2008", "author": {"author_id": 857, "author_email": "p.nielsen@auckland.ac.nz", "author_lastname": "Nielsen", "author_firstname": "Poul"}, "content": "Please, rank the following on the scale from 1 (worst) to 5 (best)<br />Originality &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; 3<br />Methodological originality&nbsp;&nbsp;&nbsp; 4<br />Biologic originality &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; 2<br />Completeness of discussion &nbsp;&nbsp;&nbsp; 3<br />Appropriate references &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; 4<br />Organisation &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; 4<br />Clarity &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; 3<br /><br /><br />Is the technical treatment plausible and free from technical errors?&nbsp;&nbsp;&nbsp; yes<br />Have you checked the equations&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; yes<br />Are you aware of prior publication or presentation of this work&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; no<br />Is the paper too long&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; yes<br /><br /><br />Recommendation:&nbsp;&nbsp;&nbsp; C<br />(A)&nbsp;&nbsp;&nbsp; Accept <br />(B) &nbsp;&nbsp;&nbsp; Accept subject to minor revisions<br />(C)&nbsp;&nbsp;&nbsp; Accept with major revisions<br />(D)&nbsp;&nbsp;&nbsp; Reject<br /><br /><br />Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?&nbsp;&nbsp;&nbsp; Poster or podium<br /><br /><br />Comments to the manuscript:<br />The authors present a computationally efficient method for determining whether two surfaces, represented by C0 bilinear simplex meshes, have regions of penetration. The work is motivated by the desire to solve the contact problem between the soft brain and rigid skull. The description in section 3 is thorough, if somewhat verbose. I believe that this section could be shortened, without loss of completeness, with a careful rewrite. The modelling assumptions appear to be rather simplistic, especially the claim that &ldquo;contact force is not specifically of interest&rdquo;. How does this approach account for separation of the brain from the skull when/if air or fluid is allowed to enter into the cavity? Is this not an issue relevant to the brain-skull contact mechanics problem? A more considered discussion of the assumptions is required. Some discussion is also required regarding the assumptions associated with surface representations. It appears to me that the algorithm is limited to surface representation using bilinear C0 simplex elements. If so, this needs to be stated explicitly. It would be of interest to know if the approach could be generalised to other representations (e.g. higher order bases and/or smoother interelement continuity).<br /><br />The text needs to be proof-read. For example, it took several readings to understand what the following sentence in section 1 means: &ldquo;A registration method that leads to physically plausible deformation estimates is the computation of the intra-operative brain deformations using a biomechanical model, therefore treating the brain shift as a solid mechanics problem&rdquo;.<br />", "review_id": 1498}, {"date": "07-03-2008", "author": {"author_id": 893, "author_email": "jh.chung@auckland.ac.nz", "author_lastname": "Chung", "author_firstname": "Jae-hoon"}, "content": "<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves/> <w:TrackFormatting/> <w:PunctuationKerning/> <w:ValidateAgainstSchemas/> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF/> <w:LidThemeOther>EN-NZ</w:LidThemeOther> <w:LidThemeAsian>KO</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables/> <w:SnapToGridInCell/> <w:WrapTextWithPunct/> <w:UseAsianBreakRules/> <w:DontGrowAutofit/> <w:SplitPgBreakAndParaMark/> <w:DontVertAlignCellWithSp/> <w:DontBreakConstrainedForcedTables/> <w:DontVertAlignInTxbx/> <w:Word11KerningPairs/> <w:CachedColBalance/> <w:UseFELayout/> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\\\"Cambria Math\\\"/> <m:brkBin m:val=\\\"before\\\"/> <m:brkBinSub m:val=\\\"--\\\"/> <m:smallFrac m:val=\\\"off\\\"/> <m:dispDef/> <m:lMargin m:val=\\\"0\\\"/> <m:rMargin m:val=\\\"0\\\"/> <m:defJc m:val=\\\"centerGroup\\\"/> <m:wrapIndent m:val=\\\"1440\\\"/> <m:intLim m:val=\\\"subSup\\\"/> <m:naryLim m:val=\\\"undOvr\\\"/> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\\\"false\\\" DefUnhideWhenUsed=\\\"true\\\" DefSemiHidden=\\\"true\\\" DefQFormat=\\\"false\\\" DefPriority=\\\"99\\\" LatentStyleCount=\\\"267\\\"> <w:LsdException Locked=\\\"false\\\" Priority=\\\"0\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Normal\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"heading 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 7\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 8\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 9\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 7\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 8\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 9\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"35\\\" QFormat=\\\"true\\\" Name=\\\"caption\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"10\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Title\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"1\\\" Name=\\\"Default Paragraph Font\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"11\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Subtitle\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"22\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Strong\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"20\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Emphasis\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"59\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Table Grid\\\"/> <w:LsdException Locked=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Placeholder Text\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"1\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"No Spacing\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Revision\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"34\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"List Paragraph\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"29\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Quote\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"30\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Intense Quote\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"19\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Subtle Emphasis\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"21\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Intense Emphasis\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"31\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Subtle Reference\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"32\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Intense Reference\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"33\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Book Title\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"37\\\" Name=\\\"Bibliography\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" QFormat=\\\"true\\\" Name=\\\"TOC Heading\\\"/> </w:LatentStyles> </xml><![endif]--> <!-- /* Font Definitions */ @font-face \t{font-family:\\\"Cambria Math\\\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:roman; \tmso-font-pitch:variable; \tmso-font-signature:-1610611985 1107304683 0 0 159 0;} @font-face \t{font-family:\\\"&#47569;&#51008; &#44256;&#46357;\\\"; \tpanose-1:2 11 5 3 2 0 0 2 0 4; \tmso-font-charset:129; \tmso-generic-font-family:modern; \tmso-font-pitch:variable; \tmso-font-signature:-1879047505 165117179 18 0 524289 0;} @font-face \t{font-family:\\\"@&#47569;&#51008; &#44256;&#46357;\\\"; \tpanose-1:2 11 5 3 2 0 0 2 0 4; \tmso-font-charset:129; \tmso-generic-font-family:modern; \tmso-font-pitch:variable; \tmso-font-signature:-1879047505 165117179 18 0 524289 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\\\"\\\"; \tmargin:0cm; \tmargin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:10.0pt; \tfont-family:\\\"Times New Roman\\\",\\\"serif\\\"; \tmso-fareast-font-family:\\\"&#47569;&#51008; &#44256;&#46357;\\\"; \tmso-ansi-language:EN-AU; \tmso-fareast-language:EN-US;} .MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-size:10.0pt; \tmso-ansi-font-size:10.0pt; \tmso-bidi-font-size:10.0pt; \tmso-fareast-font-family:\\\"&#47569;&#51008; &#44256;&#46357;\\\";} @page Section1 \t{size:612.0pt 792.0pt; \tmargin:3.0cm 72.0pt 72.0pt 72.0pt; \tmso-header-margin:36.0pt; \tmso-footer-margin:36.0pt; \tmso-paper-source:0;} div.Section1 \t{page:Section1;} /* List Definitions */ @list l0 \t{mso-list-id:260070017; \tmso-list-type:hybrid; \tmso-list-template-ids:1550744384 -1 -1 -1 -1 -1 -1 -1 -1 -1;} @list l0:level1 \t{mso-level-start-at:3; \tmso-level-number-format:alpha-upper; \tmso-level-text:\\\"(%1)\\\"; \tmso-level-tab-stop:36.0pt; \tmso-level-number-position:left; \ttext-indent:-18.0pt;} @list l1 \t{mso-list-id:1769153127; \tmso-list-type:hybrid; \tmso-list-template-ids:1256257460 1227274586 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;} @list l1:level1 \t{mso-level-number-format:alpha-upper; \tmso-level-text:\\\"(%1)\\\"; \tmso-level-tab-stop:36.0pt; \tmso-level-number-position:left; \ttext-indent:-18.0pt;} ol \t{margin-bottom:0cm;} ul \t{margin-bottom:0cm;} --> <!--[if gte mso 10]> <style> /* Style Definitions */ table.MsoNormalTable \t{mso-style-name:\\\"&#54364;&#51456; &#54364;\\\"; \tmso-tstyle-rowband-size:0; \tmso-tstyle-colband-size:0; \tmso-style-noshow:yes; \tmso-style-priority:99; \tmso-style-qformat:yes; \tmso-style-parent:\\\"\\\"; \tmso-padding-alt:0cm 5.4pt 0cm 5.4pt; \tmso-para-margin:0cm; \tmso-para-margin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:10.0pt; \tfont-family:\\\"Times New Roman\\\",\\\"serif\\\";} </style> <![endif]--> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Please, rank the following on the scale from 1 (worst) to 5 (best)</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">3</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Methodological originality<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Biologic originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">3</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Completeness of discussion <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Appropriate references <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Organisation <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Clarity <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Is the technical treatment plausible and free from technical errors?<span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">yes</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Have you checked the equations<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">yes</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Are you aware of prior publication or presentation of this work<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">no</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Is the paper too long<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">yes</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Recommendation:</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">(C)</span></span></p> <p style=\\\"margin-left: 36pt; text-align: justify; text-indent: -18pt; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(A)<span>&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Accept </span></p> <p style=\\\"margin-left: 18pt; text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>(B) Accept subject to minor revisions</span></p> <p style=\\\"margin-left: 36pt; text-align: justify; text-indent: -18pt; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(C)<span>&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Accept with major revisions</span></p> <p style=\\\"margin-left: 36pt; text-align: justify; text-indent: -18pt; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(D)<span>&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Reject</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</span><span><span>&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">Poster</span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p class=\\\"MsoNormal\\\"><span>Comments to the manuscript:</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>This paper describes a contact mechanics problem between the brain tissue and the surrounding skull during surgical procedures. A lot of emphasis has been put on the detecting the penetration of slave nodes defined on the brain tissue into the master body. Yet the treatment of the penetration itself is rather simple (explicit displacement boundary conditions). I wonder if this is appropriate to be called a contact problem, since it does not involve any computation on contact forces. Authors claim that the computation speed is almost independent of the mesh density for the skull surface, which seems trivial since the degrees of freedom for the master body are removed due to the fact that the skull is much stiffer than the brain tissue. Also, the algorithm requires no configuration parameters because contact forces are not computed. It seems that this method is more closely related to the approach of applying explicit boundary conditions over the entire surface of the brain, than contact mechanics approach. </span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>I think Section 3can be substantially shortened, and it would be good to have some preliminary results on actual brain and skull geometries. Also, I wonder if any numerical issues were observed for not having continuous normal vector field defined on the master surface (due to C&shy;<sub>0</sub>-continuity).</span></p> ", "review_id": 1492}], "publication_id": 552},
{"reviews": [{"date": "07-07-2008", "author": {"author_id": 899, "author_email": "tduttar@mech.uwa.edu.au", "author_lastname": "Dutta roy", "author_firstname": "Tonmoy"}, "content": "<font size=\"2\"><font face=\"Times New Roman\"><span><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><span>Paper authors and title: </span></p><span>&nbsp;</span><span>Integration of Geometrical Boundary Conditions on Soft Tissue Characterization under large deformation </span><span>&nbsp;</span><span>Bummo Ahn and Jung Kim</span><span></span><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Please, rank the following on the scale from 1 (worst) to 5 (best)</span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>2<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Methodological originality<span> </span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>2<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Biologic originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>2<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Completeness of discussion <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Appropriate references <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>2<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Organisation <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Clarity <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3</span></p><span>&nbsp;</span><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Is the technical treatment plausible and free from technical errors?<span>&nbsp;&nbsp;&nbsp; </span>Yes <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Have you checked the equations<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>NA<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Are you aware of prior publication or presentation of this work<span> </span>No</span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Is the paper too long<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>No</span></p><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Recommendation:</span></p><p style=\"margin: 0cm 0cm 0pt 36pt; text-indent: -18pt; line-height: 150%; text-align: justify; tab-stops: list 36.0pt\" class=\"MsoNormal\"><span><span>(A)<span style=\"font: 7pt &#39;Times New Roman&#39;\">&nbsp;&nbsp; </span></span></span><span>Accept </span></p><p style=\"margin: 0cm 0cm 0pt 18pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>(B) Accept subject to minor revisions</span></p><p style=\"margin: 0cm 0cm 0pt 36pt; text-indent: -18pt; line-height: 150%; text-align: justify; tab-stops: list 36.0pt\" class=\"MsoNormal\"><span><span>(C)<span style=\"font: 7pt &#39;Times New Roman&#39;\">&nbsp;&nbsp;&nbsp; </span></span></span><span>Accept with major revisions</span></p><p style=\"margin: 0cm 0cm 0pt 36pt; text-indent: -18pt; line-height: 150%; text-align: justify; tab-stops: list 36.0pt\" class=\"MsoNormal\"><span><span>(D)<span style=\"font: 7pt &#39;Times New Roman&#39;\">&nbsp;&nbsp;&nbsp; </span></span></span><span>Reject</span></p><p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>Reject</span></p><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; text-align: justify\" class=\"MsoNormal\"><span>Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</span></p><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; line-height: 150%; text-align: justify\" class=\"MsoNormal\"><span>NA</span></p><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><span>Comments to the manuscript:</span></p><span>&nbsp;</span><span>Though the paper tries to investigate a relevant clinical procedure (needle insertion/surgical simulation), the authors fail to differentiate their work from those of Dr Salcudean&rsquo;s group (Dr DiMaio) at UBC, Canada and Dr Adam Wittek&rsquo;s team (UWA, Perth). The authors claim in their paper that no other published work exists on needle insertion/surgical simulation, which takes into account finite deformation and non-linear constitutive law. I would strongly urge the authors to follow the work of Dr Adam Wittek at UWA (</span><strong><span>Wittek, A., Dutta-Roy, T., Taylor, Z., Horton, A., Washio, T., Chinzei, K. and Miller, K., Subject Specific Non-Linear Biomechanical Model of Needle Insertion into Brain, <span style=\"color: black\">Computer Methods in Biomechanics and Biomedical Engineering, 2008, 11 (2), 135-146; </span>Wittek A., Dutta-Roy T., Miller K., <span>Biomechanics of Needle Insertion into Brain Using Non Linear Biomechanical Model, Proceedings of the 7<sup>th</sup> International Symposium on Computer Methods in Biomechanics and Biomedical Engineering, 22<sup>nd</sup> &ndash; 25<sup>th</sup> March 2006, Antibes, Cote D&rsquo; Azur, France, pp. 870-875 and </span>Dutta-Roy, T., Wittek A., Taylor, Z., Chinzei, K., Washio T., Miller, K., <span>Towards Realistic Surgical Simulation: Biomechanics of Needle Insertion into Brain, Proceedings of the </span>16<sup>th</sup> CISM-IFToMM Symposium on Robot Design, Dynamics and Control, RoManSy 2006 Symposium, Warsaw University of Technology, Warsaw, Poland, 22<sup>nd</sup> -25<sup>th</sup> March 2006, pp. 297-304 etc</span></strong><span>). The authors would find that Dr Wittek and his team in their papers argue precisely for a fully non linear model (finite deformations, non-linear constitutive law and non-linear boundary conditions) to completely understand the mechanics of needle insertion/surgical simulation.</span><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; text-align: justify\" class=\"MsoNormal\"><span>The current approach taken by the authors in the paper slightly varies from the work done by Dr DiMaio <strong>(</strong></span><strong><span style=\"color: black\">Simon P. DiMaio, <a href=\"http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salcudean:S=_E=.html\"><span style=\"text-decoration: none; text-underline: none\"><font color=\"#000000\">S. E. Salcudean</font></span></a>: Needle Insertion Modelling and Simulation. <a href=\"http://www.informatik.uni-trier.de/~ley/db/conf/icra/icra2002.html#DiMaioS02\"><span style=\"text-decoration: none; text-underline: none\"><font color=\"#000000\">ICRA 2002</font></span></a>: 2098-2105 etc</span></strong><span style=\"color: black\">)</span><span>. It uses the same methodology proposed by Dr DiMaio for measuring the deformation field using digital CCD cameras, though, the authors use it on porcine liver.</span></p><span>&nbsp;</span> <p style=\"margin: 0cm 0cm 0pt; text-align: justify\" class=\"MsoNormal\"><span>Also, the reviewer has difficulties to understand why the authors use an inverse FE parameter optimization methodology to characterise the porcine liver properties when the same could be done using the techniques described by Prof Miller (ISML, UWA, Perth, Australia) (<strong>Miller K. (2005) &quot;Method of testing soft biological tissues in compression&quot; J. Biomechanics. Vol. 38, Issue 1, 153-158</strong> <strong>etc.</strong>). The method proposed by Prof Miller is simpler and easier to co-relate to the physical world as it directly deals with mechanical testing of the tissue.<span>&nbsp; </span>Also, in Table 2, the reviewer fails to understand why the same porcine liver would have different viscoelastic and hyperelastic parameters for different indenter shapes. Are two different porcine livers used for each kind of indenter shapes?</span></p><span>&nbsp;</span> <p><span style=\"font-size: 10pt; font-family: &#39;Times New Roman&#39;\">On the reasons given above, the reviewer feels that the paper does not introduce any new material for discussions in the workshop and hence would argue against accepting the paper.&nbsp;<span>&nbsp;</span></span></p></span></font></font>", "review_id": 1501}], "publication_id": 553},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 864, "author_email": "adwit@mech.uwa.edu.au", "author_lastname": "Wittek", "author_firstname": "Adam"}, "content": "<p><em>(This review can be also viewed by opening the attached PDF file)</em></p><p>The paper addresses an important problem of the design of orthopaedic implants to to<br />ensure that they fit the maximum of the target population. The Authors build statistical<br />shape model of a tibia and use to optimise the implant position. They also conduct<br />modelling analysis (FE method is used) biomechanical performance of bone-implant<br />construct. The methodology appears to be original and technically sound. However, some<br />aspects (bone-to-bone and bone-to-implant interactions) of the modelling conduct require<br />further clarification. Therefore, my opinion is that before the paper can be regarded as<br />ready for publication/presentation in the Workshop, the Authors should answer the<br />questions given below and modify the paper following them.</p><p><br /><strong>Major comments</strong><br />1) Biomechanical FE Simulations: How were the interactions between two split (as a<br />result of fracture) bone parts and between the bones and implant modelled?<br />The Authors write that &ldquo;3D beam elements were used to fix implant to the bone&rdquo;<br />and that &ldquo;Attachment of the beam to the bone was preformed using an embedded<br />element technique&rdquo;. However, in order for such modelling of attachment to be<br />meaningful, the implant should be allowed to move/slide in relation to the bone. This<br />would require application of contact interface (or similar type of constrain) between<br />the implant and bone, and between two split bone parts. The paper does not mention<br />existence of any type of such interface between the bone and implant and between<br />two split bone parts.</p><p><br />2) What finite element solver was used and what type of finite element analysis (i.e.<br />geometrically linear or non-linear) was applied?</p><p><br />3) Legend of Table 1 (p. 8): Was the bone-implant distance determined using imagebased<br />methods described in Sections 2-4?</p><p><br /><strong>Minor comments</strong><br />1) P. 2 reference [Rueckert] is missing in the Reference list</p><p><br />2) P. 2, figure 1 caption. Is: &ldquo;axis&rdquo;, should be: &ldquo;axes&rdquo; (plural)</p><p><br />3) P. 3, second column, second paragraph. Is: &ldquo;the fracture should be a continuous&rdquo;,<br />should be: &ldquo;the fracture should be continuous&rdquo;</p><p><br />4) P. 4, last sentence. Is &ldquo;in Eq. 3&rdquo;, should be: &ldquo;in Eq. 4&rdquo;. </p>", "review_id": 1478}], "publication_id": 554},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 864, "author_email": "adwit@mech.uwa.edu.au", "author_lastname": "Wittek", "author_firstname": "Adam"}, "content": "<p><em>(This review can be also viewed by opening the attached PDF file)</em><br /> </p><p>The idea of pre-operative prediction of mechanical properties of dental implant using<br />finite element method presented in the paper is very exciting. However, the<br />implementation of this idea appears to be flawed, which includes the following:</p><p><br />1) Justification for building &ldquo;a patient-specific&rdquo; model using a generic mesh and<br />patient-specific bone material properties is not given.</p><p><br />2) Selection of boundary conditions for the implant (the implant is rigidly fixed<br />to the bone) lacks justification.</p><p><br />3) Verification of in-house finite element code developed in the study is<br />incomplete.</p><p><br />4) The finite element modelling results grossly differ from the experimental data<br />obtained using artificial bone.</p><p><br />Therefore, I cannot recommend this manuscript for publication in its current form. A<br />major revision of the entire study should be undertaken.</p><p><br /><strong>Major comments</strong><br />1) It is commonly accepted practice that newly developed numerical algorithms<br />(such as e.g. in-house finite element codes) are at first verified against the<br />existing well-established numerical procedures (such as e.g. those<br />implemented in commercial finite element codes) or against simple examples<br />for which solutions are known (e.g. Viceconti et al. 2005, Zienkiewicz 2000).<br />The Authors should include such verification of their code in the paper.</p><p><br />2) Finite element method is a numerical method for solving partial differential<br />equations. Therefore, determining correlation coefficients between the<br />experimental and finite element modelling results when validating finite<br />element models as done in Results section is misleading. Close to linear<br />relationship between the modelling and experimental results is not sufficient<br />to claim that the modelling results are &ldquo;promising &hellip; in terms of accuracy &hellip;&rdquo;<br />as stated by the Authors in Discussion. The results shown in Figure 5 indicate<br />that the experimentally determined removal torque is around five times greater<br />than the one predicted using the finite element model. This is a clear<br />indication of gross disagreement between the modelling and experimental<br />results and evidence of serious flaw in either modelling or experimental (or<br />both) part of the study. Differences of 500% between the modelling and<br />experimental are unacceptable by any engineering standard given the fact the<br />constitutive properties of the modelled continuum are well-known. These<br />differences call for major revision of the entire study.</p><p><br />3) Figure 6 clearly indicates that the relationship between the modelling and<br />experimental results is non-linear. Justification for drawing a straight line<br />trough the points clearly following non-linear pattern should be given. As was<br />with Figure 5, 200% difference between the experimental and modelling<br />results should be explained, and relevant revision of the study should be<br />undertaken to eliminate any difference of such large magnitude.</p><p><br />4) P. 3: &ldquo;The removal torque is approximated by multiplying the friction<br />coefficient by the total of the radial reaction forces due to pressfit at the<br />bone/implant interface&rdquo;. Given the fact that no contact between the bone and<br />implant was modelled, how was the radial reaction force calculated?</p><p><br />5) Quality of the results obtained using a finite element model is determined not<br />only by accuracy of the constitutive parameters for the model but also by how<br />closely the model represents the geometry and boundary conditions of the<br />analysed structure (see e.g. Bathe 1996). What was the rationale for the<br />Authors&rsquo; assumption that patient-specific constitutive properties and generic<br />implant and bone geometry are sufficient to build a patient-specific boneimplant<br />model?</p><p><br />6) How were the dimensions of the bone part of the model determined?</p><p><br />7) In the first paragraph of section 2.1.2 Construction of patient-specific finite<br />element analysis the Authors state that &ldquo;The mesh used for the simulation is a<br />generic mesh &hellip;&rdquo;. However, in the second paragraph in the same section they<br />write that &ldquo; Elements outside of the bone are assigned near zero &hellip;stiffness,<br />making the patient specific mesh construction entirely automatic&rdquo;. This seems<br />a contradiction. Was the patient-specific or generic mesh used?</p><p><br />8) What do the Authors mean by the &ldquo;implant stability&rdquo; given the fact that they<br />assume that there is no movement between the bone and implant?</p><p><br /><strong>Minor comment:</strong><br />The paper should be re-written using the single-column format (see the Insight<br />Journal submission template at<br />http://insightsoftwareconsortium.org/wiki/index.php/IJ-Article-Template).</p><p><br /><strong>References</strong><br />Bathe, K.-J., 1996. Finite Element Procedures. Prentice-Hall, Upper Saddle River.</p><p><br />Viceconti, M., Olsen, S., Nolte, L.-P., and Burton, K., 2005. &quot;Extracting clinically<br />relevant data from finite element simulations,&quot; Clinical Biomechanics, Vol. 20,<br />pp. 451-454.</p><p><br />Zienkiewicz, O. C. and Taylor, R. L., 2000. The Finite Element Method. Vol. 2: Solid<br />mechanics London: McGraw-Hill.<br /> </p>", "review_id": 1477}], "publication_id": 555},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 882, "author_email": "a.young@auckland.ac.nz", "author_lastname": "Young", "author_firstname": "Alistair"}, "content": "<br /><span><font face=\"Times New Roman\" size=\"2\">This paper presents a mechanical simulation of heart mechanics, for analysis of medical images. A Cartesian coordinate system is employed with the Costa nonlinear hyperelastic material law. This is an interesting attempt to apply non-linear hyperelastic large strain mechanics to the modelling of heart wall motion. The application to parameter estimation and motion recovery is left to future work. The technique used for solving the nonlinear system of equations looks interesting. The paper would benefit from validation with motions derived from cardiac images using standard methods.&nbsp;</font></span><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span> <p style=\"margin: 0cm 0cm 0pt; text-align: justify\" class=\"MsoNormal\"><span><font face=\"Times New Roman\" size=\"2\">References</font></span></p><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span> <ol style=\"margin-top: 0cm\"><li class=\"MsoNormal\" style=\"margin: 0cm 0cm 0pt; tab-stops: list 36.0pt\"><span><font size=\"2\"><font face=\"Times New Roman\"><span>&nbsp;</span>&ldquo;we are the first one to implement the Costa law up the ventricular level&rdquo; &ndash; such statements of priority are generally best avoided, and I believe others have published Costa implementations in realistic ventricular geometries (eg Costa <em>et al</em> Phil Trans R Soc Lond A 2001 359:1233-1250). Perhaps you mean Costa law in an active electromechanical model?</font></font></span></li><li class=\"MsoNormal\" style=\"margin: 0cm 0cm 0pt; tab-stops: list 36.0pt\"><span><font face=\"Times New Roman\" size=\"2\">&ldquo;we could not find any relevant literature which specifies&hellip;&rdquo; the displacement normal to the surface &ndash; see Sermesant <em>et al</em> IEEE TMI 25:612-625;2006.</font></span></li></ol><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span>", "review_id": 1489}, {"date": "07-04-2008", "author": {"author_id": 883, "author_email": "martyn.nash@auckland.ac.nz", "author_lastname": "Nash", "author_firstname": "Martyn"}, "content": " <p class=\"MsoNormal\"><span>Comments to the manuscript:</span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>This manuscript describes methods for simulating mechanics of the cardiac ventricles.<span> </span>The authors use finite deformation hyperelasticity with an orthotropic constitutive relation, and linearize and solve the governing nonlinear equations using total-Lagrangian system dynamics.<span> </span>They present a limited validation study in order to verify their implementation, followed by a simulation of ventricular systole that is only qualitatively compared to a limited set of MR images. Intro/Methods/Results sections are presented rather well, however Discussion of the findings and limitations are overly brief or non-existent.</span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>The authors claim to be the first to implement an orthotropic exponential constitutive relation (&ldquo;Costa law&rdquo;) at the ventricular level [Intro: last parag], however the UCSD group have published several studies on the use of orthotropic exponential constitutive relations for whole ventricle mechanics (e.g. Usyk et al. Journal of Elasticity 61:143&ndash;164, 2000; which also uses the penalty method for incompressibility). <span> </span>Throughout the manuscript, the authors repeatedly highlight some issues regarding one previous study (ref [9]), such as the choice of constitutive relation (&ldquo;pole-zero law&rdquo;) and coordinate system (&ldquo;prolate spheroidal coordinates&rdquo;). Instead, they would do better to concentrate on the/novel aspects of their own work &ndash; noting that models using Cartesian coordinates (e.g. Vetter et al., Annals of Biomedical Engineering, 28:781&ndash;792, 2000), and orthotropic material relations (e.g. Usyk et al., as above) have been widely studied. </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>The authors also claim that their representation of the constraint that the pericardial sac places on wall motion is novel. However, the use of this choice of boundary conditions is remains to be quantitatively validated against experimental recordings or medical images (more on this below). Furthermore, a similar constraint was previously described by the INRIA group (Sermesant et al.).<span> </span></span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>Perhaps the main novelty of this study is the use of total-Lagrangian system dynamics numerical methods for cardiac electro-mechanics, but this requires further validation (more on this below). It would be interesting to quantitatively compare over multiple heart cycles the accuracy of this technique against that of the more traditional implicit finite element methods. </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>The validation studies presented here are inadequate. A deformation study involving simple shear is presented. Analytical homogenous data are compared against numerical (finite element) non-homogeneous model predictions (Fig 1a shows non-homogeneous deformation). Thus two different types of deformation are being compared. Also of concern is: &ldquo;yet the errors increase when the deformation becomes large&rdquo; (parag. below Eq.14) &ndash; this requires further investigation (e.g. did errors reduce with smaller step size?). Furthermore, this test is based on just one mode of deformation, which involves just 2 of the 6 independent components of the strain tensor. A full validation should include multiple modes of deformation involving the shear and normal components of strain. Perhaps a more appropriate and comprehensive closed-form solution is that of the pressure inflation, axial extension and torsion of a homogeneous, isotropic cylinder (eg. Rivlin 1950, Phil. Trans. A242: 173&ndash;195).<span> </span></span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>Finally, another major shortcoming of this manuscript is the distinct lack of quantitative validation against experimental/clinical measures of ventricular wall motion.<span> </span>Just one set of medical images are presented and the comparison against model predictions is limited to a few qualitative statements (see parag. below Fig 4). Such gross observations have been previously reproduced using axi-symmetric truncated ellipsoids (e.g. the Dutch groups of Arts, Bovendeerd, et al.). The use of a geometrically detailed biventricular model should be justified and validated using regional measures of wall motion (e.g. from tagged MRI).</span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>Specific minor comments:</span></p> <ul style=\"margin-top: 0cm\"><li class=\"MsoNormal\" style=\"text-align: justify\"><span>In several places, &ldquo;In consequence&rdquo; should be changed to -&gt; &ldquo;As a consequence&rdquo;.</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 2, Intro, line 3: &ldquo;At the macroscopic&rdquo;</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 2, Intro, line 10: &ldquo;apart from&rdquo; -&gt; &ldquo;as well as&rdquo;</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 2, bottom: last line &ldquo;Furthermore, &hellip;&rdquo; needs rewording.</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 3, bottom: last line &ldquo;The f-n-s, &hellip;&rdquo; needs rewording.</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 4, &ldquo;Elasticity Tensor&rdquo;, line 3: &ldquo;stain&rdquo; -&gt; &ldquo;strain&rdquo;</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 5, eq (8): there are other nearly incompressible formulations. Cite a ref, and explain why this one was selected.</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 5, Sec 2.3: it is unclear why you would want to &ldquo;impose transmural shear resistance&hellip;&rdquo;. This sentence is very unclear.<span> </span>Note that another (simpler?) way to approximate the effects would be to add an external traction constraint on the epicardium. Discuss pros/cons of this.</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 9, line 1: &ldquo;20 frames&rdquo; of &ldquo;5 frames&rdquo; as pictured?</span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 9, bottom parag: the first 5-6 lines describes methods (and should thus be moved to Methods section) and takes material constants from a pig study. But at the bottom, there is a suggestion that these parameters are too stiff (&ldquo;stroke volume is very small&rdquo;). Thus, it would perhaps be better to use parameters for canine myocardium (e.g. from Usyk et al. Journal of Elasticity 61: 143&ndash;164, 2000). </span></li><li class=\"MsoNormal\" style=\"text-align: justify\"><span>Page 10, bottom: &ldquo;only the blood filling phase is included&rdquo;: this point is confusing and probably needs rewording. Suggests that the authors only studied diastole (however results for systole were also presented).</span></li></ul> <p style=\"text-align: justify\" class=\"MsoNormal\"><span> </span></p> <br /> <br /> ", "review_id": 1496}], "publication_id": 556},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 882, "author_email": "a.young@auckland.ac.nz", "author_lastname": "Young", "author_firstname": "Alistair"}, "content": "<p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><span><font face=\"Times New Roman\" size=\"2\">This paper presents a method for myocardial motion estimation from HARP-like MRI tagged images, based on multiscale optical flow methods. The paper is well written and clearly presented. The method of topological number for feature classification is interesting. </font></span></p><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span> <p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><span><font face=\"Times New Roman\" size=\"2\">Specific Points:</font></span></p><ol style=\"margin-top: 0cm\"><li class=\"MsoNormal\" style=\"margin: 0cm 0cm 0pt; tab-stops: list 36.0pt\"><span><font size=\"2\"><font face=\"Times New Roman\">The experiments only report validation against rigid body translations. Validation on a deformation field would be more convincing. It would also be necessary to validate against an accepted tag tracking method.</font></font></span></li><li class=\"MsoNormal\" style=\"margin: 0cm 0cm 0pt; tab-stops: list 36.0pt\"><span><font size=\"2\"><font face=\"Times New Roman\">typo &ldquo;asses&rdquo; on page 7</font></font></span></li><li class=\"MsoNormal\" style=\"margin: 0cm 0cm 0pt; tab-stops: list 36.0pt\"><span><font size=\"2\"><font face=\"Times New Roman\">Include discussion on how these methods can be used in biomechanical modelling, eg to validate models. This would make it more applicable to the goals of the CBM workshop.</font></font></span></li></ol><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span> <p style=\"margin: 0cm 0cm 0pt; text-align: justify\" class=\"MsoNormal\"><span><font face=\"Times New Roman\" size=\"2\">References</font></span></p><ol style=\"margin-top: 0cm\"><li class=\"MsoNormal\" style=\"margin: 0cm 0cm 0pt; tab-stops: list 36.0pt\"><font size=\"2\"><font face=\"Times New Roman\"><span>Dougherty et al.<span>&nbsp; </span></span><span>IEEE TMI 1999;18,359&ndash;363. was one of the first applications of optical flow methods to tagged MRI and should be referenced. </span></font></font></li></ol><span><font face=\"Times New Roman\" size=\"2\">&nbsp;</font></span> <p>&nbsp;</p>", "review_id": 1487}, {"date": "07-03-2008", "author": {"author_id": 894, "author_email": "heye.zhang@auckland.ac.nz", "author_lastname": "Zhang", "author_firstname": "Heye"}, "content": "Please, rank the following on the scale from 1 (worst) to 5 (best)<br />Originality 4<br />Methodological originality 4<br />Biologic originality 3<br />Completeness of discussion 3<br />Appropriate references 4<br />Organisation 4<br />Clarity 4<br />Is the technical treatment plausible and free from technical errors?<br />Have you checked the equations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No<br />Are you aware of prior publication or presentation of this work No<br />Is the paper too long No<br />Recommendation:<br />&nbsp;&nbsp;&nbsp;&nbsp; (A) Accept<br />&nbsp;&nbsp;&nbsp;&nbsp; (B) Accept subject to minor revisions<br />&nbsp;&nbsp;&nbsp;&nbsp; (C) Accept with major revisions<br />&nbsp;&nbsp;&nbsp;&nbsp; (D) Reject<br />&nbsp;&nbsp;&nbsp;&nbsp; My recommendation: Accept<br />Should this paper be presented as poster or as podium presentation (this recommendation does not reflect<br />upon the relative quality of the paper)?<br />oral<br />Comments to the manuscript:<br />This paper present a multi-scale feature tracking algorithm. It is quite interesting, but it is still in<br />preliminary stage. Authors may apply their work into more clinical data to demonstrate the ability of their<br />approach.<br />", "review_id": 1493}], "publication_id": 558},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 864, "author_email": "adwit@mech.uwa.edu.au", "author_lastname": "Wittek", "author_firstname": "Adam"}, "content": "<p><em>(This review can be also viewed by opening the attached PDF file)</em></p><p><br />The paper addresses an important problem of the bone tissue anisotropy in finite element<br />modelling of long bones (femur is used) and, as such, fits well within the scope of the<br />Workshop. However, description of the modelling methods used is insufficient to fully<br />evaluate whether the study is technically sound. Therefore, my opinion is that the paper<br />can be accepted for publication in the Workshop only if the Authors answer the<br />questions/comments given below and modify their manuscript following them.</p><p><br /><strong>Major comments</strong><br />1) What were the boundary conditions for the finite element model used? Figure 2<br />shows the force applied to the femoral head, but no information is given how the<br />bone was supported. Was the force applied to a single node or distributed over a set<br />of nodes?</p><p><br />2) On p. 3 the Authors write that linear hexahedral element were used. Were they fullyintegrated<br />or under-integrated hexahedrals?</p><p><br />3) What finite element solver was used and what type of finite element analysis (i.e.<br />geometrically linear or non-linear) was applied?</p><p><br />4) P. 6 Eqs. (7) and (8): How the parameters &Delta;u and &Delta;&sigma; in a given region of interest<br />were calculated? Were they averaged over the elements and nodes in a given region<br />or they were calculated for the selected nodes and elements?</p><p><br />5) In the last paragraph of Discussion the Authors state that the models developed so far<br />&ldquo;cannot reproduce exactly in vivo conditions&rdquo; and suggest that their method has<br />features that ensure such &ldquo;reproducibility&rdquo;. Can the Authors explain what do they<br />mean by &ldquo;in vivo conditions&rdquo; and how they can be sure that their method can<br />represent them given the fact that the study contains no validation of the modelling<br />results.</p><p><br />6) Figure 3: The regions of interests are not indicated.</p><p><br />7) Figure 4: What material properties are shown in this figure and what are their units?</p><p><br />8) Eqs. (1)-(6): Were Eqs. (1)-(6) derived by the Authors or were they obtained from<br />the literature. If they were obtained from the literature, the references should be<br />given.</p><p><br /><strong>Minor comments:</strong><br />1) The title &ldquo;Orientation definition of anisotropy is important to finite element<br />simulation of bone material properties&rdquo; does not correspond well to the scope and<br />content of the study. The study indicates that there are important differences between<br />the Von Mises stress and nodal displacements determined using isotropic and<br />orthotropic material models in regions where the principal material orientations vary.<br />The &ldquo;finite element simulation of bone material properties&rdquo; as such is not addressed<br />despite reference to such simulation in the title. Therefore, the Authors should<br />modify the title so it signals the study scope and results to the readers in a<br />meaningful way.</p><p><br />2) First sentence of Introduction: What do the Authors mean by stating that Finite<br />element (FE) analysis is &ldquo;non-invasive method&rdquo;. Finite element analysis is a<br />numerical method for solving partial differential equations and it does make much<br />sense to refer to it as either &ldquo;invasive&rdquo; or &ldquo;non-invasive&rdquo;.</p><p><br />3) Does MP refer to MPa (mega Pascals) and GP to GPa (giga Pascals)?</p><p><br />4) What are the units for density and Young&rsquo;s modulus in Eqs. (3) and (4). </p>", "review_id": 1476}], "publication_id": 561},
{"reviews": [{"date": "07-06-2008", "author": {"author_id": 882, "author_email": "a.young@auckland.ac.nz", "author_lastname": "Young", "author_firstname": "Alistair"}, "content": "<p class=\"\\&quot;MsoNormal\\&quot;\">This manuscript proposes a method for the analysis of heart wall motion using an electromechanical model. The goal is to recover the motion of the heart, including the recovery of through-plane motion and rotational motion, which are poorly constrained by the image data, due to the aperture problem. A deformable model framework is presented which uses the model as an &ldquo;internal energy&rdquo; providing physiologically realistic motions constrained by the given data. This framework is shown to be equivalent to a data assimilation approach derived from system identification theory (reference 7). This is an interesting paper, well written on the whole, and clearly presented. </p><p class=\"\\&quot;MsoNormal\\&quot;\">General comments:</p><ol>The application of state estimation methods to cardiac motion recovery is not new and the authors should reveiw the work by Shi et al. <li class=\"\\&quot;MsoNormal\\&quot;\">The application is limited to motion recovery. Another application could be the recovery of biophysical information such as the model parameters, but this is not explored here. Model parameters are fixed and not optimized to the motion (unlike reference 7 in which physiological parameters of the model itself are also estimated). Rather, the method utilizes a model in a similar way to previous methods which incorporate <em>a priori</em> knowledge as a smoothing term (model energy) in the objective function. If so, the motivation for a physiological electromechanical energy term should be made clearer in the Introduction, as opposed to simpler terms used in the past. It should also be made clearer in the Methods that the model parameters are not optimized. </li><li class=\"\\&quot;MsoNormal\\&quot;\">In the absence of data, the model will deform in a manner totally prescribed by the model energy. With data, there is a tradeoff between the model energy and the data term leading to a solution outside the space of physiological solutions. It should be made clear in the Discussion that this formulation is not physiological, for example boundary forces are not applied in this fashion in the real heart.</li><li class=\"\\&quot;MsoNormal\\&quot;\">It should be noted in the conclusions that the assumptions of the model are not realistic, given that we know the heart is a nonlinear material undergoing large strains. This does not detract from the clinical utility of the method, so long as the simplistic nature of the assumptions are noted.</li></ol><span><font face=\"\\&quot;Times\" size=\"\\&quot;2\\&quot;\">&nbsp;</font></span> <p class=\"\\&quot;MsoNormal\\&quot;\">Specific Comments:</p><span><font face=\"\\&quot;Times\" size=\"\\&quot;2\\&quot;\">&nbsp;</font></span> <ol>The explanation of the acquisition and problems with the real data (RV segmentation etc) should occur in the Methods section (around 3.2), rather than in the Results section 5.2. This would explain the RV-LV volume mismatch near Fig 3, where it is demonstrated. Give details of what images were acquired, pulse sequence parameters etc. <li class=\"\\&quot;MsoNormal\\&quot;\">There are a few mistakes in the English: eg. in the Introduction &ldquo;the heart electromechanical activity&rdquo; should be &ldquo;the heart&rsquo;s electromechanical activity&rdquo;, &ldquo;has received a growing attention&rdquo; should be &ldquo;has received growing attention&rdquo;, &ldquo;personalised electromechanical model of the heart&rdquo; should be &ldquo;personalised electromechanical models of the heart&rdquo;, &ldquo;In such framework&rdquo; should be &ldquo;In such a framework&rdquo;, &ldquo;mesh is fit on the&rdquo; should be &ldquo;mesh is fit to the&rdquo;, &ldquo;assimilation techniques consisting in adjusting&rdquo; should be &ldquo;assimilation techniques consisting of adjusting&rdquo;, &ldquo;since they involves full covariance&rdquo; should be &ldquo;since they involve full covariance&rdquo;.</li><li class=\"\\&quot;MsoNormal\\&quot;\">Section 3.2: What passive material parameters are taken from what literature?</li></ol><span><font face=\"\\&quot;Times\" size=\"\\&quot;2\\&quot;\">&nbsp;</font></span><span><font face=\"\\&quot;Times\" size=\"\\&quot;2\\&quot;\">&nbsp;</font></span><span><font face=\"\\&quot;Times\" size=\"\\&quot;2\\&quot;\">&nbsp;</font></span> <p>&nbsp;</p>", "review_id": 1488}, {"date": "07-06-2008", "author": {"author_id": 894, "author_email": "heye.zhang@auckland.ac.nz", "author_lastname": "Zhang", "author_firstname": "Heye"}, "content": "Originality 3<br />Methodological originality 1<br />Biologic originality 3<br />Completeness of discussion 4<br />Appropriate references 4<br />Organisation 4<br />Clarity 4<br />Is the technical treatment plausible and free from technical errors?<br />Have you checked the equations Yes<br />Are you aware of prior publication or presentation of this work No<br />Is the paper too long No<br />Recommendation:<br />(A) Accept<br />(B) Accept subject to minor revisions<br />(C) Accept with major revisions<br />(D) Reject<br />My recommendation: Accept with major revisions<br />Should this paper be presented as poster or as podium presentation (this recommendation does not reflect<br />upon the relative quality of the paper)?<br />poster<br />Comments to the manuscript:<br />I have seen very similar work in term of electromechanical modelling and data assimilation from authors<br />and Dr. Pengcheng Shi&#39;s group before. The main issue that I concern is difference between this paper and<br />Dr. Pengcheng Shi previuos work.<br />Authors claims that their data assimilation, which actually is the state space motion estimation, is inspired<br />by reference [7]. But Dr. Pengcheng Shi&#39;s group have published a series of papers of the state space motion<br />estimation framework:<br />Stochastic finite element framework for simultaneous estimation of cardiac kinematic functions and<br />material parameters in Medical Image Analysis 2003.<br />Huafeng Liu, Pengcheng Shi: Simultaneous Estimation of Left Ventricular Motion and Material Properties<br />with Maximum a Posteriori Strategy. CVPR 2003.<br />Ken C.L. Wong, Pengcheng Shi: Finite Deformation Guided Nonlinear Filtering for Multiframe Cardiac<br />Motion Analysis. MICCAI 2004<br />Authors of reference [7] may not know medical image community so well, but author of this paper should<br />realize the simality of reference [7] and Dr. Pengcheng Shi&#39;s work. It is hard not to ask the simality between<br />reference [7] and [12]. Obviously I can see Dr. Pengcheng Shi has introduced the state space into medical<br />image community first. It is not hard to see that data assimilation in this paper is very similar to Dr.<br />Pengcheng Shi&#39;s the state space motion estimation framework, but authors only mention one of their works.<br />So authors should clearify their originality in this paper with a comparison of this work and Dr. Pengcheng<br />Shi&#39;s works, otherwise I recommend a direct reject. Furthermore, in the part of data assimilation, authors<br />failed to quantitively describe their data assimilation method, such as what is the noise rate.<br />The conclusion in reference in [17] is correct, but authors should notice that their groups have developed<br />several efforts to decrease the size of covariance matrices.<br />More details should be added. Such as equation (1). what is the value of APD, sigma_c and sigma_0.<br />What is HP? How to determine Td and Tr from authors&#39; electrical simulation? Though authors describe<br />what is Td and Tr qualitively, readers still can not determine Td and Tr quantitively. These inefficiencies<br />dmage the quality of paper a lot. Authors should definitely revise them.", "review_id": 1491}], "publication_id": 563},
{"reviews": [{"date": "07-03-2008", "author": {"author_id": 893, "author_email": "jh.chung@auckland.ac.nz", "author_lastname": "Chung", "author_firstname": "Jae-hoon"}, "content": "<!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves/> <w:TrackFormatting/> <w:PunctuationKerning/> <w:ValidateAgainstSchemas/> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF/> <w:LidThemeOther>EN-NZ</w:LidThemeOther> <w:LidThemeAsian>KO</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables/> <w:SnapToGridInCell/> <w:WrapTextWithPunct/> <w:UseAsianBreakRules/> <w:DontGrowAutofit/> <w:SplitPgBreakAndParaMark/> <w:DontVertAlignCellWithSp/> <w:DontBreakConstrainedForcedTables/> <w:DontVertAlignInTxbx/> <w:Word11KerningPairs/> <w:CachedColBalance/> <w:UseFELayout/> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\\\"Cambria Math\\\"/> <m:brkBin m:val=\\\"before\\\"/> <m:brkBinSub m:val=\\\"--\\\"/> <m:smallFrac m:val=\\\"off\\\"/> <m:dispDef/> <m:lMargin m:val=\\\"0\\\"/> <m:rMargin m:val=\\\"0\\\"/> <m:defJc m:val=\\\"centerGroup\\\"/> <m:wrapIndent m:val=\\\"1440\\\"/> <m:intLim m:val=\\\"subSup\\\"/> <m:naryLim m:val=\\\"undOvr\\\"/> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\\\"false\\\" DefUnhideWhenUsed=\\\"true\\\" DefSemiHidden=\\\"true\\\" DefQFormat=\\\"false\\\" DefPriority=\\\"99\\\" LatentStyleCount=\\\"267\\\"> <w:LsdException Locked=\\\"false\\\" Priority=\\\"0\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Normal\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"heading 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 7\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 8\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"9\\\" QFormat=\\\"true\\\" Name=\\\"heading 9\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 7\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 8\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" Name=\\\"toc 9\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"35\\\" QFormat=\\\"true\\\" Name=\\\"caption\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"10\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Title\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"1\\\" Name=\\\"Default Paragraph Font\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"11\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Subtitle\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"22\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Strong\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"20\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Emphasis\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"59\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Table Grid\\\"/> <w:LsdException Locked=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Placeholder Text\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"1\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"No Spacing\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Revision\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"34\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"List Paragraph\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"29\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Quote\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"30\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Intense Quote\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 1\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 2\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 3\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 4\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 5\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"60\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Shading Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"61\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light List Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"62\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Light Grid Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"63\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 1 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"64\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Shading 2 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"65\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 1 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"66\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium List 2 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"67\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 1 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"68\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 2 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"69\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Medium Grid 3 Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"70\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Dark List Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"71\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Shading Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"72\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful List Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"73\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" Name=\\\"Colorful Grid Accent 6\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"19\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Subtle Emphasis\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"21\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Intense Emphasis\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"31\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Subtle Reference\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"32\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Intense Reference\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"33\\\" SemiHidden=\\\"false\\\" UnhideWhenUsed=\\\"false\\\" QFormat=\\\"true\\\" Name=\\\"Book Title\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"37\\\" Name=\\\"Bibliography\\\"/> <w:LsdException Locked=\\\"false\\\" Priority=\\\"39\\\" QFormat=\\\"true\\\" Name=\\\"TOC Heading\\\"/> </w:LatentStyles> </xml><![endif]--> <!-- /* Font Definitions */ @font-face \t{font-family:\\\"Cambria Math\\\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:roman; \tmso-font-pitch:variable; \tmso-font-signature:-1610611985 1107304683 0 0 159 0;} @font-face \t{font-family:\\\"&#47569;&#51008; &#44256;&#46357;\\\"; \tpanose-1:2 11 5 3 2 0 0 2 0 4; \tmso-font-charset:129; \tmso-generic-font-family:modern; \tmso-font-pitch:variable; \tmso-font-signature:-1879047505 165117179 18 0 524289 0;} @font-face \t{font-family:\\\"@&#47569;&#51008; &#44256;&#46357;\\\"; \tpanose-1:2 11 5 3 2 0 0 2 0 4; \tmso-font-charset:129; \tmso-generic-font-family:modern; \tmso-font-pitch:variable; \tmso-font-signature:-1879047505 165117179 18 0 524289 0;} /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\\\"\\\"; \tmargin:0cm; \tmargin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:10.0pt; \tfont-family:\\\"Times New Roman\\\",\\\"serif\\\"; \tmso-fareast-font-family:\\\"&#47569;&#51008; &#44256;&#46357;\\\"; \tmso-ansi-language:EN-AU; \tmso-fareast-language:EN-US;} .MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-size:10.0pt; \tmso-ansi-font-size:10.0pt; \tmso-bidi-font-size:10.0pt; \tmso-fareast-font-family:\\\"&#47569;&#51008; &#44256;&#46357;\\\";} @page Section1 \t{size:612.0pt 792.0pt; \tmargin:3.0cm 72.0pt 72.0pt 72.0pt; \tmso-header-margin:36.0pt; \tmso-footer-margin:36.0pt; \tmso-paper-source:0;} div.Section1 \t{page:Section1;} /* List Definitions */ @list l0 \t{mso-list-id:260070017; \tmso-list-type:hybrid; \tmso-list-template-ids:1550744384 -1 -1 -1 -1 -1 -1 -1 -1 -1;} @list l0:level1 \t{mso-level-start-at:3; \tmso-level-number-format:alpha-upper; \tmso-level-text:\\\"(%1)\\\"; \tmso-level-tab-stop:36.0pt; \tmso-level-number-position:left; \ttext-indent:-18.0pt;} @list l1 \t{mso-list-id:1428692749; \tmso-list-type:hybrid; \tmso-list-template-ids:308210422 336134159 336134169 336134171 336134159 336134169 336134171 336134159 336134169 336134171;} @list l1:level1 \t{mso-level-tab-stop:none; \tmso-level-number-position:left; \ttext-indent:-18.0pt;} @list l2 \t{mso-list-id:1769153127; \tmso-list-type:hybrid; \tmso-list-template-ids:1256257460 1227274586 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;} @list l2:level1 \t{mso-level-number-format:alpha-upper; \tmso-level-text:\\\"(%1)\\\"; \tmso-level-tab-stop:36.0pt; \tmso-level-number-position:left; \ttext-indent:-18.0pt;} ol \t{margin-bottom:0cm;} ul \t{margin-bottom:0cm;} --> <!--[if gte mso 10]> <style> /* Style Definitions */ table.MsoNormalTable \t{mso-style-name:\\\"&#54364;&#51456; &#54364;\\\"; \tmso-tstyle-rowband-size:0; \tmso-tstyle-colband-size:0; \tmso-style-noshow:yes; \tmso-style-priority:99; \tmso-style-qformat:yes; \tmso-style-parent:\\\"\\\"; \tmso-padding-alt:0cm 5.4pt 0cm 5.4pt; \tmso-para-margin:0cm; \tmso-para-margin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:10.0pt; \tfont-family:\\\"Times New Roman\\\",\\\"serif\\\";} </style> <![endif]--> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Please, rank the following on the scale from 1 (worst) to 5 (best)</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">3</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Methodological originality<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">3</span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Biologic originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">3</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Completeness of discussion <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Appropriate references <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Organisation <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Clarity <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">4</span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Is the technical treatment plausible and free from technical errors?<span>&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span><span>&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">YES</span></span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Have you checked the equations<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">NO</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Are you aware of prior publication or presentation of this work<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">NO</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Is the paper too long<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">NO</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Recommendation:</span><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">(B)</span></span></p> <p style=\\\"margin-left: 36pt; text-align: justify; text-indent: -18pt; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(A)<span>&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Accept </span></p> <p style=\\\"margin-left: 18pt; text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>(B) Accept subject to minor revisions</span></p> <p style=\\\"margin-left: 36pt; text-align: justify; text-indent: -18pt; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(C)<span>&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Accept with major revisions</span></p> <p style=\\\"margin-left: 36pt; text-align: justify; text-indent: -18pt; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(D)<span>&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Reject</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span style=\\\"background: #d9d9d9 none repeat scroll 0% 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial\\\">Poster</span></p> <p class=\\\"MsoNormal\\\"><span>Comments to the manuscript:</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>Couple of mistakes:</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <ol style=\\\"margin-top: 0cm\\\"><li class=\\\"MsoNormal\\\" style=\\\"text-align: justify\\\"><span>On page 3, 5<sup>th</sup> paragraph, 4<sup>th</sup> line, know -&gt; known</span></li><li class=\\\"MsoNormal\\\" style=\\\"text-align: justify\\\"><span>On page 7, 2<sup>nd</sup> paragraph, 1<sup>st</sup> line, as well-&gt; as well as </span></li></ol> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>As authors have suggested, stress levels in the leaflets might also be desired for the repair process, in which case a FE modelling is a better choice. If model&rsquo;s robustness and speed is more desirable than the accuracy (which is a fair argument), one might consider explicit time scheme for FE method (Karol Miller, Total Lagrangian explicit dynamics finite element algorithm for computing soft tissue deformation, MICCAI 2007). It will be an interesting comparison between mass-spring approach and FE modelling on speed, and also modelling accuracy.</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>On page 7, paragraph 2, authors mention &ldquo;homogeneous/nonhomogeneous boundary conditions&rdquo;. Please clarify.</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>If the model is stable and does not take long time to run, then a more detailed sensitivity analysis such as a factorial analysis will be more adequate.</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>&nbsp;</span></p> ", "review_id": 1495}, {"date": "07-04-2008", "author": {"author_id": 875, "author_email": "v.rajagopal@auckland.ac.nz", "author_lastname": "Rajagopal", "author_firstname": "Vijayaraghavan"}, "content": " <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Please, rank the following on the scale from 1 (worst) to 5 (best)</span></strong></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Methodological originality<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Biologic originality <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>3<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Completeness of discussion <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>5</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Appropriate references <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>4</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Organisation <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>4</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>Clarity <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>4</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>&nbsp;</span><strong><span>Is the technical treatment plausible and free from technical errors?<span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span> </span></span></strong></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Have you checked the equations</span></strong><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>no.</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Are you aware of prior publication or presentation of this work</span></strong><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>no.</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Is the paper too long</span></strong><span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>no.</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><strong><span>Recommendation:</span></strong></p> <p style=\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\" class=\"MsoNormal\"><!--[if !supportLists]--><span><span>(A)<span style=\"font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal\">&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Accept </span></p> <p style=\"margin-left: 0.25in; text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>(B) Accept subject to minor revisions</span></p> <p style=\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\" class=\"MsoNormal\"><!--[if !supportLists]--><span><span>(C)<span style=\"font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal\">&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Accept with major revisions</span></p> <p style=\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\" class=\"MsoNormal\"><!--[if !supportLists]--><span><span>(D)<span style=\"font-family: &quot;Times New Roman&quot;; font-style: normal; font-variant: normal; font-weight: normal; font-size: 7pt; line-height: normal; font-size-adjust: none; font-stretch: normal\">&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span>Reject</span></p> <p style=\"text-align: justify; line-height: 150%\" class=\"MsoNormal\"><span>B, accept subject to minor revisions. </span></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>&nbsp;</span><strong><span>Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</span></strong><span> Presentation.</span></p> <p class=\"MsoNormal\"><strong><span>Comments to the manuscript:</span></strong></p> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>The paper is well written, providing a clear idea of the methods used to model mitral valve closure. The authors&rsquo; aim of providing quick computations of valve closure justifies the use of mass-spring models. </span></p><span>However, I am not able to understand the reasoning for why the authors desire low sensitivity of valve closure to leaflet properties. Doesn&rsquo;t the indication of large variance in these properties (from ref [14]) indicate that subject-specific material properties are necessary? Indeed, biological tissue properties are individual-specific and time-specific (properties change over time as well). Change in material properties affect mechanical stress and deformation. Therefore, more clarification is needed on this part. What range of material properties should we expect physiologically in normal and diseased hearts?</span> <p style=\"text-align: justify\" class=\"MsoNormal\"><span>Fig. 5 is a bit confusing. Do the authors refer to the top and bottom rows or the left most and right most columns? More clarification in the caption for Fig. 5 would suffice. </span></p> ", "review_id": 1499}], "publication_id": 564},
{"reviews": [{"date": "06-30-2008", "author": {"author_id": 832, "author_email": "grandj@mech.uwa.edu.au", "author_lastname": "Joldes", "author_firstname": "Grand roman"}, "content": "<p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><font face=\"Times New Roman\" size=\"3\">&nbsp;&nbsp; In this paper the authors propose the use of the Optimal Mass Transport theory for identifying the cortical structures by mapping a brain atlas to the MRI scan of a patient. </font></p><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\">&nbsp;</p><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><font size=\"3\"><font face=\"Times New Roman\">&nbsp;&nbsp; Most of the solution algorithm derivation and implementation described in this paper was presented in previous papers [1]. The authors contribute by proposing the use of a different direction for minimization and by enforcing the mass preserving property after each iteration step.</font></font></p><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><font size=\"3\"><font face=\"Times New Roman\"><span>&nbsp;&nbsp; </span></font></font></p><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><font face=\"Times New Roman\" size=\"3\">&nbsp;&nbsp; The method requires as a pre-requisite a segmentation of the patient MRI scan into the major tissue classes - it is not specified in the paper how this problem is solved. It also requires that the intensities of the two input images (atlas and MRI) be normalized and rescaled to make sure that both have the same mass (intensity). This will certainly influence the results especially if the intensity distribution differs considerably between the atlas and the MRI scan (scanning sequences or sensors are very different).</font></p><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\">&nbsp;</p><p style=\"margin: 0cm 0cm 0pt\" class=\"MsoNormal\"><font face=\"Times New Roman\" size=\"3\">&nbsp;&nbsp; The authors present the difference in white matter intensity between the patient MRI and the re-sampled atlas image as a proof of accuracy. Nevertheless, this only proves that the algorithm can morph one image into the other, not that the folds are accurately aligned (as shown in the presented results, some atlas labels are propagated to the wrong regions). The matching of anatomical landmarks would be more appropriate for quantifying the accuracy of the method.</font></p><font face=\"Times New Roman\" size=\"3\">&nbsp;</font><font face=\"Times New Roman\" size=\"3\">&nbsp;</font> <p style=\"margin: 0cm 0cm 0pt; text-indent: 0cm\" class=\"MsoNormal\"><font face=\"Times New Roman\" size=\"3\">References</font></p><font face=\"Times New Roman\" size=\"3\">&nbsp;</font> <p style=\"margin: 0cm 0cm 0pt; text-indent: 0cm\" class=\"MsoNormal\"><font face=\"Times New Roman\" size=\"3\">1. <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Haker, S., Zhu, L., Tannenbaum, A., Angenent, S., 2004, Optimal mass transport for registration and warping. International Journal of Computer Vision 60 (3), 225&ndash;240.</font></p><p>&nbsp;</p>", "review_id": 1482}], "publication_id": 565},
{"reviews": [{"date": "07-03-2008", "author": {"author_id": 894, "author_email": "heye.zhang@auckland.ac.nz", "author_lastname": "Zhang", "author_firstname": "Heye"}, "content": "Originality 4<br />Methodological originality 3<br />Biologic originality 4<br />Completeness of discussion 4<br />Appropriate references 4<br />Organisation 3<br />Clarity 3<br />Is the technical treatment plausible and free from technical errors?<br />Have you checked the equations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No<br />Are you aware of prior publication or presentation of this work No<br />Is the paper too long Yes<br />Recommendation:<br />&nbsp;&nbsp;&nbsp;&nbsp; (A) Accept<br />&nbsp;&nbsp;&nbsp;&nbsp; (B) Accept subject to minor revisions<br />&nbsp;&nbsp;&nbsp;&nbsp; (C) Accept with major revisions<br />&nbsp;&nbsp;&nbsp;&nbsp; (D) Reject<br />&nbsp;&nbsp;&nbsp;&nbsp; My recommendation: Accept<br />Should this paper be presented as poster or as podium presentation (this recommendation does not reflect<br />upon the relative quality of the paper)?<br />Oral<br />Comments to the manuscript:<br />The method, coupling of FEM and EFG, has been applied into mechanical application for a while. In this<br />paper, authors adopted this method into new biological application, brain tumor, and shown with nice<br />numerical validation. I can follow mathematical parts of EFG, but authors may need to add more details<br />into section 3.2, Analysis Solver. Because the format of Total Largrange equation is not easy to be<br />understood.<br />Since meshfree method is the key selling point of this paper, authors should discuss more details of EFG<br />implementation. EFG has been proved with enough stability and consisitency in mechanical application in<br />many papers. Penalty method has been proposed to handle essenstial conditions very well. But authors<br />claim that a solely mesh-free Element Free Galerkin (EFG) model will prove to be inefficient, suffering<br />from consistency and stability issues, as well as Dirichlet boundary difficulties (page 1). If it is in this<br />particular application, brain tumor, authors should use numerical experiments to support their claims. If it<br />has been proved in other papers, authors should add more details and put enough references over there.<br />Authors also claims that FEM on its own will be inaccurate and problematic for modelling the brain<br />deformation response to tumour growth, since the mesh surrounding the tumour is easily distorted,<br />consequently destroying elements. Yes, it is true. but authors should also metion that remesh in this<br />situatuon is very time-consuming even though FEM can handle large deformation after remehsing.<br />Section 3.1.2 Mixed-Mesh Reader, and Figure 3.1: Block diagram of the preprocessing phase (red) and<br />analysis solver (green) may not be able to help understand FEM and EFG so much. It is a little bit far away<br />from coupling of FEM and EFG. The details of implementation, such as how to do integeration for EFG,<br />how to chose the density of nodes in EFG and how to handle the interface of FEM and EFG may help a lot.<br />", "review_id": 1494}, {"date": "07-04-2008", "author": {"author_id": 875, "author_email": "v.rajagopal@auckland.ac.nz", "author_lastname": "Rajagopal", "author_firstname": "Vijayaraghavan"}, "content": " <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><strong><span>Please, rank the following on the scale from 1 (worst) to 5 (best)</span></strong></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Originality <span> </span>3</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Methodological originality<span> </span><span> </span>3</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Biologic originality <span> </span>3<span> </span></span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Completeness of discussion <span> </span>2</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Appropriate references <span> </span>4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Organisation <span> </span>4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>Clarity <span> </span><span> </span>4</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span> </span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span> </span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><strong><span>Is the technical treatment plausible and free from technical errors? </span></strong><span><span> </span><span> </span>yes</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><strong><span>Have you checked the equations<span> </span></span></strong></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><strong><span>Are you aware of prior publication or presentation of this work</span></strong><span><span> </span>no</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><strong><span>Is the paper too long</span></strong><span><span> </span>yes, 15 pages long, when max limit is 12.</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><strong><span>Recommendation:</span></strong></p> <p style=\\\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(A)<span> </span></span></span><!--[endif]--><span>Accept </span></p> <p style=\\\"margin-left: 0.25in; text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>(B) Accept subject to minor revisions</span></p> <p style=\\\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(C)<span> </span></span></span><!--[endif]--><span>Accept with major revisions</span></p> <p style=\\\"margin-left: 0.5in; text-align: justify; text-indent: -0.25in; line-height: 150%\\\" class=\\\"MsoNormal\\\"><!--[if !supportLists]--><span><span>(D)<span> </span></span></span><!--[endif]--><span>Reject</span></p> <p style=\\\"text-align: justify; line-height: 150%\\\" class=\\\"MsoNormal\\\"><span>B, accept with minor revisions.</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><strong><span>Should this paper be presented as poster or as podium presentation (this recommendation does not reflect upon the relative quality of the paper)?</span></strong><span> Poster</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span> </span></p> <p class=\\\"MsoNormal\\\"><strong><span>Comments to the manuscript:</span></strong></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>The paper presents an elegant technique to couple mesh-free and finite element mesh methods to solve finite elasticity on complex geometries. The paper is novel in tackling the difficulties with mesh methods using meshless techniques. </span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>1. The paper will be much stronger if the author also provides the analytic solution to the deformation of a cylinder. The results from FE, EFG and FE/EFG coupled simulations could then be compared to the analytic solution to provide a more robust validation. </span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>2. Variable notation in eqn 3.8 need to be explained. W(d)?</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span>3. The discussion should inform the accuracy of the modelling technique for inhomogeneous bodies. Is the cylinder model assumed to be homogeneous? What would the accuracy of the method be for inhomogeneous bodies?</span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span> </span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><strong><span>References</span></strong></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span> </span></p> <p style=\\\"text-align: justify\\\" class=\\\"MsoNormal\\\"><span> </span></p> ", "review_id": 1497}], "publication_id": 567},
{"reviews": [], "publication_id": 568},
{"reviews": [], "publication_id": 572},
{"reviews": [], "publication_id": 574},
{"reviews": [], "publication_id": 575},
{"reviews": [], "publication_id": 577},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents a semi-automatic live tumor segmentation technique. <br />In this method, the liver tumors are first segmented using a multi-resolution multi-class Bayesian classification <br />algorithm . Morphological operation and active contour method are then used to refine the segmentation.</p><p>Detailed comments:</p><p>1) This is a well-organized workshop paper. The presentation is clear.</p><p>2) From my point of view, the multi-resolution approach might cause difficulty in segmenting small liver tumors, given the large variability of lesion size. Could the authors briefly address this issue?&nbsp; </p><p>3) The liver tumors may appear as either hypo-intensity or hyper-intensity, compared to the surrounding liver tissue. <br />Is this taken into account in the 5-class intensity model?</p><p>4) Could the user manually identified point in the initialization be an arbitrary point in the liver, e.g. a point either in normal liver tissue or in the lesion?</p><p>5) In Table 2, the values of the five metrics are good enough to show the reproducibility of the proposed method.<br />The last column on the right should be deleted, because those scores are not generated by comparision with provided reference segmentation.</p>", "review_id": 1526}], "publication_id": 579},
{"reviews": [], "publication_id": 580},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents a level-set based semi-automatic live tumor segmentation technique. <br />The segmentation is initialized using a user-defined ROI. The level set is evolved according to a speed function computed using&nbsp;fuzzy pixel classification technique.</p><p><br />Detailed comments:</p><p>1) What makes liver tumor segmentation a challenging task is the large variation of lesion&#39;s shape, size and contrast in CT images. A tumor segmentation technique with potential of clinical application should be able to handle both homogeneous and round shaped lesions, as well as not well-defined ones.&nbsp; </p><p>2) In the last paragraph of &quot;Discussion&quot; section, the authors said that &quot;user intelligence was reduced when placing the two seeds&quot;. From my point of view, it would be helpful to test the reproducibility of the proposed technique on the training and testing data, before making such a conclusion.</p><p>3) What is the stop criterion of the level-set evolution?</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1523}], "publication_id": 581},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents an automatic live tumor segmentation technique. <br />This technique is composed of two steps.<br />First, the liver is segmented using a heuristic thresholding method. Second, the tumors&nbsp;are segmented using a multi-thresholding algorithm.</p><p><br />Detailed comments:</p><p>1) The authors should provide more details of the liver and liver tumor segmentation algorithms. From my point of view, this is the core part of the workshop paper, which has only been briefly described in the manuscript.</p><p>2) Fig. 3 is not referenced in the manuscript.</p><p>3) Could the authors speculate on the main reason that causes the over-segmentation in the results?</p><p>&nbsp;</p>", "review_id": 1521}], "publication_id": 582},
{"reviews": [], "publication_id": 583},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents a semi-automatic live tumor segmentation technique. <br />The segmentation is initialized with a user-drawn stroke across the lesion. The tumors are then segmented using adaptive thresholding followed with refinement by morphological operation. </p><p>Detailed comments:</p><p>1) The proposed technique requires a user-drawn stroke to initialize the segmentation, and some manual editing in refinement. In my opinion, this algorithm should belong to &quot;Interactive system&quot;.</p><p>2) It would be helpful if the authors could provide some information regarding the sensitivity of the proposed algorithm to the initial stroke, i.e., variation of segmentation against different positions of the initial stroke.</p><p>3) In Table 1, please use the provided tumor name, e.g., IMG05_L1.</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1522}], "publication_id": 584},
{"reviews": [], "publication_id": 585},
{"reviews": [], "publication_id": 586},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents a semi-automatic live tumor segmentation technique. <br />The segmentation is initialized with a user defined ROI. The tumors are then segmented using region growing followed with refinement by morphological operation. </p><p><br />Detailed comments:</p><p>1) The amount of user intervention needed in this method may be under-estimated, <br />because it requires user-defined ROI on each tumor bearing slice.<br />For processing large amount of data in routine clinical use, this could become a labor-intensive and time-consuming task . </p><p>2) it is not clear to me why the Knowledge-based constraints should be used to refine the segmentation.<br />What&#39;s the difference between the ROI and &quot;larger area&quot; mentioned in section 2.3?<br />Why can&#39;t the segmentation start with a &quot;larger area&quot; in the first run?<br />Could the authors briefly address this algorithm&#39;s sensitivity to initialization?</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1524}], "publication_id": 588},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>The authors presented a semi-automatic live tumor segmentation technique. In this method, the liver is first segmented using watershed algorithm, tumors are then segmented using a minimum cross-entropy multi-thresholding algorithm. The tumor segmentation is further refined with region growing and level-set based surface smoothing methods.</p><p>Detailed comments:</p><p>1) Overall, this is a nice workshop paper. The presentation is clear.</p><p>2) In the multi-thresholding tumor segmentation, the number of thresholds applied in multi-thresholding is 3, with the first and third thresholds set for hypodense and hyperdense tumors respectively. What is the second threshold for?</p><p>3) In segmentation refinement, why are the threshold limits not symmetric with respect to the mean value?</p><p>4) Could the user manually identified point in the initialization be an arbitrary point in the liver, e.g. a point&nbsp;in normal liver tissue or in the lesion?</p>", "review_id": 1525}], "publication_id": 589},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents a semi-automatic live tumor segmentation technique. <br />In this method, the tumor is first segmented in one slice using an SVM classifier. The contour is then propagated to other slices and refined using an updated SVM classifier to obtain&nbsp; segmentation of the whole lesion. </p><p>Detailed comments:</p><p>1) If the tumor has an asymmetric shape, I don&#39;t see a clear advantage to start the segmentation in the mid section of the lesion.</p><p>2) It is not clear to me how the segmentation procedure can be stopped during the propagation so that user can manually adjust the initial ROI. </p><p><br />3) While the proposed technique does not need manual editing of the segmented contour, it does require some user-intervention in initialization and in the middle of segmentation procedure. In my opinion, the proposed technique is an interactive segmentation technique.</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1520}], "publication_id": 590},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents a semi-automatic live tumor segmentation technique. <br />In this method, the tumor is segmented using 3D region growing and Bayesian classification. </p><p>Detailed comments:</p><p>1) Could the authors provide more detailed information about selection of seed points, i.e., how many seed points should be used for inhomogeneous lesions?</p><p>2) Since the selection of seed point is the only user-intervention required, it would be helpful to test the sensitivity/repeatability of the proposed technique against independent initialization.</p><p><br />3) How are the multiple Gaussian distributions combined into one?</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1519}], "publication_id": 591},
{"reviews": [], "publication_id": 592},
{"reviews": [], "publication_id": 593},
{"reviews": [], "publication_id": 594},
{"reviews": [], "publication_id": 595},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents an contrast enhancement technique for live tumor segmentation.</p><p><br />Detailed comments:</p><p>1) Contrast enhancement is&nbsp;a preprocessing step&nbsp;of liver tumor segmentation.<br />The authors should provide detailed description of the segmentation algroithm. <br />Otherwise, it is difficult to compare this segmentation techniques with others.</p>", "review_id": 1514}], "publication_id": 596},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>The authors present an automatic live tumor segmentation technique. <br />In this technique, candidate tumor sites are first identified and segmented by intensity thresholding and region growing. The segmented regions are then filtered using a set of hueristic criteria. The remaining segmentations are refined using competition-diffusion algorithm. Finally, segmented tumors with size below and above certain thresholds are eliminated.</p><p>Detailed comments:</p><p>1) The proposed tumor segmentation algorithm uses a lot of heuristic methods, as well as empirically determined parameters.<br />As a result, the algorithm could be very sensitive to the large variation&nbsp;of clinical liver tumor images, in terms of size, shape and contrast.</p><p>2) The number of false positive in the segmentation results would make clinical application of this technique difficult.</p><p>3) The edge of tumors may not be well-defined in the original CT images. The down-sampling used in the pre-processing stage will further blur the boundary, which could cause over-segmentation in intensity thresholding based segmentation methods.</p><p>&nbsp;</p>", "review_id": 1513}], "publication_id": 597},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents an interactive live tumor segmentation technique. The liver is first segmented using combined graph-cut and watershed algorithm, tumors are then segmented with a maximum a posteriori method. Manual editing is followed to refine the tumor segmentation.</p><p>Detailed comments:</p><p>1) Could the author briefly describe the average computation time of tumor segmentation and time for manual editing?<br />That would give readers some sense of the potential of clincial application of the proposed method.</p><p>2) For Table 4 in the manuscript, please use the same table as what we provided in the evaluation (tumor name,&nbsp; metric value, score, etc.) for the sake of consistency. The caption could be &quot;Results of comparison metrics and scores for all ten test tumors&quot;</p><p>3) As the authors state in the manuscript, &quot;the first step of our method is manual definition of a sub volume containing one or more tumors that need to be segmented.&quot; If manually defined ROI is required to initialize the tumor segmentation, what&#39;s the point of extraction of liver boundary in Section 3.3</p><p>&nbsp;</p>", "review_id": 1515}], "publication_id": 598},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents an automatic live tumor segmentation technique. <br />In this method, tumors are segmented using an AdaBoosting based algorithm. Morphological operation is followed to refine the segmentation.</p><p><br />Detailed comments:</p><p>1) Many empirically determined parameters are used to compute the 54 features in the proposed tumor segmentation algorithm. <br />This could make this technique sensitive to&nbsp;size and characteristics of training data. Could the authors briefly address this point?</p><p>2) While the focus of this contest is accuracy of tumor segmentation techniques, it would be helpful if the authors could provide some information regarding the false positives in the results, because it is an important indicator of potential of clinical application.</p><p>3) What&#39;s the difference between the segmentation algorithms for small and large lesions?<br />How do the authors determine small and large lesions?</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1516}], "publication_id": 599},
{"reviews": [], "publication_id": 600},
{"reviews": [], "publication_id": 602},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>The authors presented an automatic liver tumor segmentation technique.<br />In this method, the tumor is first segmented by thresholding and morphological operation, and then refined using fuzzy C-means clustering and level-set based surface smoothing.</p><p>Detailed comments:</p><p>1) A lot of empirically determined parameters are used in the &quot;rough segmentation&quot; stage, which could make the algorithm sensitive to data. Such effect may have been demonstrated in Tables 1-3 by the difference in performance on the training and testing datasets.</p><p>2) In Table 3, please include the evaluation table we provided as it is. You can split the results from training and testing datasets in Table 3 into two tables.</p><p>&nbsp;</p>", "review_id": 1518}], "publication_id": 603},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p>This paper describes an approach to the detection of MS lesions from brain MRI.</p><p>It utilizes a local feature estimation approach.</p><p>Interestingly, the paper finds improved results without the use of intensity inhomogeneity artifact compensation, due to edge artifacts created by the intensity inhomogeneity compensation algorithm.&nbsp;</p><p>&nbsp;The results are promising and with further work may be comparable to those of human raters.</p><p>&nbsp;</p><p>Typo:&nbsp;</p><p>methode should be method&nbsp;</p>", "review_id": 1534}, {"date": "07-28-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>The paper presents a MS lesion segmentation using a PCA based local feature vector classification incorporating a given voxel neighborhood. </p><p>The evaluations show that the method surprisingly performs better without intensity inhomogeneity correction. This may be an artifact of the employed bias correction methods. A tissue classification based bias correction (Well, Leemput, and many others) may help in this case. </p><p>The paper could use another revision and feels in part like a technical report. </p><p>Minor:</p><p>Page 5 top: &quot;affine fitted&quot; should be &quot;affinely fitted&quot;</p><p>Page 7 middle: &quot;non-rigid fit&quot; should be &quot;non-rigidly fit&quot; </p><p>Conclusion section: &quot;by by&quot; should be simply &quot;by&quot; </p><p>&nbsp;</p>", "review_id": 1538}], "publication_id": 604},
{"reviews": [{"date": "07-29-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>This methods extends the existing frameworks for topologically constrained tissue segmentation by Bazin to incorporate an MS lesion model. WM and lesions are grouped together for the topological constraint. Within this joint MS+WM region, each voxel is then classified either as WM or MS based on the computed tissue classification model (unlike WM, lesions have no prior weight in the classification).</p><p>The method is quite appealing with good results. Good discussion.</p><p>The paper is overall well written and no major revisions are needed.</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1541}, {"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p>This paper describes an algorithm for the segmentation of brain MRI of MS patients.</p><p>The primary contribution of this work is the introduction of a topological constraint, which ensures that the segmentation of patients is topologically equivalent to that of healthy subjects.</p><p>&nbsp;The evaluation of the method indicates it achieves good performance.</p><p>&nbsp;</p>", "review_id": 1531}], "publication_id": 605},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p><br /> This paper describes an algorithm for the segmentation of MS lesions that is fully automated.</p><p>The approach utilizes a trimmed likelihood estimator to avoid outliers influencing the calculation of the mixture model parameters.</p><p>The evaluation of the method indicates it performs well.</p><p>Typos:</p><p>apperaring - appearing</p><p>datasets where - datasets were&nbsp;</p>", "review_id": 1535}, {"date": "07-29-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>This paper presents the use of a robust EM classification method to segment MS lesions. The EM classifier needs a prior bias field correction and skull stripping, unlike other methods that incorporate these steps as part of the EM loop. First the normal brain tissue classes are determined via the robust EM, followed by an outlier detection for a rule based MS lesion segmentation. </p><p>Good results, but it is not clear what happened with cases UNC 07 and CHB 15 which have an empty image (no lesions). </p><p>Well written paper overall, no major revisions needed. </p>", "review_id": 1542}], "publication_id": 606},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 872, "author_email": "dengxiang05@gmail.com", "author_lastname": "Deng", "author_firstname": "Xiang"}, "content": "<p>This paper presents an automatic live tumor segmentation technique. <br />In this method,&nbsp;probalistic intensity models of the tumor and surrounding liver tissue are first estimated using a non-parametric technique. Second, the tumors are segmented using a 3D active contour model that can minimize the intensity variance inside and outside the object of interest.</p><p><br />Detailed comments:</p><p>1) The active surface model used in the segmentation seems to require some kind of initialization, e.g., manually defined&nbsp;initial contour. If that&#39;s the case, the method should be semi-automatic. Could the authors clarify this point?</p><p>2) The meaning of symbols in equation (1) in section 2.1 are not clearly defined, i.e., does &quot;measure of the region of the tumor&quot; mean the volume of the tumor? what does |Vol_{in}| stand for?</p><p>3) In &quot;Experimental results&quot; section, the statement &quot;the small relative difference between the intensity of the tumor and the healthy part this cause that any energy based segmentation of the normalized intensity values will not work&quot; is too strong.</p><p>4) In &quot;Experimental results&quot; section, I don&#39;t see a clear advatange of the proposed distribution estimation method from Figures 2 and 3. Could the authors show some quantitative comparison?</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1517}], "publication_id": 607},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p>This paper describes an algorithm for the segmentation of brain MRI images of MS patients.</p><p>The approach utilizes an auto-context model (ACM) to discover features that are characteristic. A novel choice is the use of probability estimates of image patches as a feature, which is then used to evolve the posterior probabilities.</p><p>&nbsp;Evaluation of performance indicates the method achieves results similar to those of the manual segmentations. </p><p>There is a typo in the word &#39;deliniation&#39; and the acronym ACM is not defined at its first use.</p><p>&nbsp;</p>", "review_id": 1530}, {"date": "07-28-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p><strong>Summary:</strong><br /> The authors present a MS lesions segmentation method using an efficient method combining appearance and context models. The model is generated in an auto-context modeling approach that iteratively refines the feature selection.<br /> </p><p>The method in general performs well, especially for the CHB dataset.</p><p>It is surprising though that the authors used two separate training datasets, as a segmentation from the CHB rater was available for the whole training data. The performance for the UNC case may actually be better when using the CHB rater, as the method seems to emulate that rater more appropriately and the final scores are averaged between the testing segmentations of the UNC and CHB rater. Also, there seems to have been a problem with UNC test 07 (empty image, no lesions detected), can you elaborate on the result in that case.</p><p><br /> A real discussion section is missing. It would great if you describe situations when the algorithm performs well (e.g. UNC test 03), or not that well (e.g. UNC test 10). Also no information about future directions of this research is given.<br /> <br /> </p>", "review_id": 1536}], "publication_id": 609},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p><br /> This paper describes an algorithm for the segmentation of MRI scans of MS patients.</p><p>The contribution utilizes features derived from signal intensity and coordinates in space. In order for the features to be commensurate, they are normalized to have zero mean and unit variance.&nbsp; Posterior probabilities are estimated through KNN density estimation.</p><p>&nbsp;The comparison of the algorithm with data from manual segmentation and other algorithms demonstrates the advantages of this approach.</p><p>&nbsp;</p><p>Minor problems:</p><p>tenser should be tensor</p><p>On page 4, was also compare should be was also compared.&nbsp;</p><p>&nbsp;On page 7, consequently should be consistently. </p>", "review_id": 1529}, {"date": "07-29-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>The paper presents a voxelwise KNN tissue classification for MS lesion detection.</p><p>Can you elaborate why only T1 and FLAIR was employed, when more MR scans were available? </p><p>Overall the results are quite good as they are similar to the CHB rater&#39;s performance (the rater used in the training), while they are still appropriate as compared to the UNC rater. </p><p>Also, the STAPLE segmentation incorporate all segmentation results used in this competition and the majority of the segmentations seem to oversegment the MS lesions. This explains why your results indicate an over segmentation as compared to the human raters and under segmentation as compared to the STAPLE computation. </p><p>Another revision, maybe by an english native speaker, would improve the quality of the submission. </p><p>Minor:&nbsp;</p><p>Abstract: &quot;It is based the K-...&quot; should be &quot;It is based on the K-...&quot;, &quot;that accurate&quot; should be &quot;that is accurate&quot; </p><p>Image Processing section: &quot;..performed before they were provided&quot; should be &quot;....performed as provided by the workshop organizers.&quot;</p><p>&nbsp;</p>", "review_id": 1539}], "publication_id": 610},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p><br /> This paper describes an approach using histogram analysis to explicitly construct a discretized feature space, and applies this to the segmentation of lesions in MRI of MS patients.</p><p>The paper provides an interesting analysis of the effectiveness of certain feature vectors for characterizing lesions, and is able to demonstrate that there is considerable overlap of these features between healthy tissue and lesions.</p><p>Minor problems: </p><p>The results section says &#39;good specificity, or true positive rate&#39; but here specificity should instead be sensitivity, later in the same sentence sensitivity should be replaced by specificity.</p><p>The authors apparently did not obtain the set of manual segmentations from the CHB rater which included segmentations of all CHB and all UNC cases. This data is available now. At the workshop and afterwards, segmentations by the UNC rater for all cases will also be available.</p><p>&nbsp;</p>", "review_id": 1527}, {"date": "07-29-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>Overall a well written paper with an interesting new method using an explicit intensity model of MS lesions with a vector image joint histogram.</p><p>The data quality section is a bit too negative, especially given that all methods use the same training and testing data. Also, I think that the issue of inter-rater variability is not really related to data quality here, as inter-rater variability is an inherent fact of MS lesion segmentation. This inter-rater variability is one of the main reasons towards automated methods. Furthermore, the methods are evaluated with respect to this inter-rater variability, i.e. if a method varies from one rater as much as another rater then it would get a score of 90.&nbsp;&nbsp; </p><p>Also, it seems that the authors were unaware of the updated training datasets that were available several weeks before the submission due date. The updated training datasets had a full set of segmentation from the CHB rater for all datasets. It may very well be that the method would perform better if this updated training would have been employed. </p><p>The authors chose a bias field correction algorithm that also normalizes the image intensity. Can you add a sentence why additional image normalization was necessary.</p><p>The method seems to penalize peri-ventricular lesions, as MS lesions within 2 voxels of CSF are rejected. Can you discuss the possibility of a bias against peri-ventricular lesions. </p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1540}], "publication_id": 611},
{"reviews": [{"date": "07-29-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>The paper employs a hidden markov chain based tissue model and a trimmed likelihood classifier within an EM loop to segment the MS lesions as outliers to the classification. </p><p>It is not clear whether the training datasets were used at all. Were they used for the estimation of the best parameter settings such as the trimming parameter h?&nbsp; </p><p>Nice paper with very good results, but could use an additional revision to improve the writing. Some sentences should be reformulated, as they are somewhat convoluted. </p> <div id=\\\"doc\\\"> </div> ", "review_id": 1544}, {"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p>This paper develops and applies a new approach to segment MRI images of MS patients.</p><p>Particularly interesting contributions are the use of a Hilbert-Peano curve to enable the use of a 1D Markov Chain model, reducing computational complexity compared to a Markov Random Field model, and the use of a trimmed likelihood estimator to reject outliers in the process of estimating a Gaussian mixture model likelihood function.</p><p>The authors note that in addition to the lesion class, CSF in particular, but also other tissue classes, may have outlier voxels.</p><p>Lesion size criteria and an atlas constraint were utilized to reduce misclassifications.</p><p>&nbsp;</p>", "review_id": 1528}], "publication_id": 612},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p>This paper describes an algorithm for the segmentation of lesions from brain MRI of MS patients.</p><p>The approach utilizes preprocessing followed by the estimation of a threshold for lesions in FLAIR images based on the signal intensity of the gray matter distribution.</p><p>The evaluation indicates the method performs well.</p><p>Minor problems:</p><p>I suggest to rewrite the sentence with the word unity to use a different word.</p><p>The table of Figure 6 adds up to 90 minutes of processing, but says 96 mins. &nbsp;</p>", "review_id": 1532}, {"date": "07-29-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>The paper presents a MS lesion segmentation method that focuses on the detection of hyper-intense T2-FLAIR regions. This detection is supported by an extensive set of preprocessing steps, including bias correction, skull stripping, intensity normalization, and EM loop based multi-channel tissue segmentation. The brain tissue segmentation is used to estimate the intensity parameters of the normal/healthy tissues. Based on the GM tissue parameter, a lesion segmentation is estimated and postprocessed with a set of rules. </p><p>It seems that in case of a severe MS case, the initial brain tissue segmentation would consist for WM to a larger degree of lesions. Thus, the parameters for the normal tissue (both WM and GM) would be off and the lesions would quite underestimated. Could you discuss this in your paper? </p><p>Overall nice paper with good results, a few minor revisions needed.</p><p>&nbsp;</p><p>&nbsp;</p>", "review_id": 1545}], "publication_id": 613},
{"reviews": [], "publication_id": 615},
{"reviews": [{"date": "07-25-2008", "author": {"author_id": 514, "author_email": "simon.warfield@childrens.harvard.edu", "author_lastname": "Warfield", "author_firstname": "Simon"}, "content": "<p>&nbsp;</p><p>This paper describes a fully automated algorithm for the segmentation of brain MRI of patients with MS lesions.</p><p>MS lesions are detected by identifying regions which are different in the patient scan from a brain atlas.</p><p>A robust estimator is utilized to prevent outliers from influencing the estimation of parameters of a Gaussian mixture model likelihood function.</p><p>&nbsp;The results indicate the method has high specificity but lower sensitivity, indicating a conservative lesion segmentation outcome. </p>", "review_id": 1533}, {"date": "07-28-2008", "author": {"author_id": 28, "author_email": "styner@cs.unc.edu", "author_lastname": "Styner", "author_firstname": "Martin"}, "content": "<p>This paper presents an MS lesion segmentation approach via outlier detection from an atlas based tissue classification. The classification procedure assign voxels to regions, which in turn are classified in tissue classes, MS lesions detected as outliers and corrected for intensity inhomogeneity within Expectation Maximization loop.</p><p>The results clearly indicate the conservative&nbsp; nature of the current approach, sensitivity is quite low, while specificty and false-positive rate are great. </p><p>It is not clear to what sense the training cases were used, as the approach seems to be based on an existing prior atlas. Was it used to fine-tune any parameters? </p><p>Overall well written paper. </p>", "review_id": 1537}], "publication_id": 616},
{"reviews": [{"date": "07-30-2008", "author": {"author_id": 168, "author_email": "torsten@synapse.sri.com", "author_lastname": "Rohlfing", "author_firstname": "Torsten"}, "content": "<p><strong>Summary:</strong><br /> This submission contains a GUI visualization tool for 3D and 4D images, including functions to visualize fusion, overlays, and deformation fields<br /> <br /> <strong>Open Science:</strong><br />Source code and demonstration data are included.<br /> <br /> <strong>Reproducibility:</strong><br /> Compiled from source and tested with my own data. Building is a breeze (on Linux FC9 with latest CVS versions of ITK and VTK). Testing worked well, too.<br /> <br /> <strong>Use of Open Source Software:</strong><br /> Software uses only open source toolkits.<br /> <br /> <strong>Open Source Contributions:</strong><br />Full source provided.<br /> <br /> <strong>Suggestions for future work:</strong><br /> Just a few issues I found:</p><p>* There seems to be an A/P flip in axial data (tried both Analyze and Nrrd files). A is bottom of viewer, and P is top, which is counter-intuitive.</p><p>* Nrrd should be supported as a file format (listed as a file type in the Open Deformation Field dialog) for deformation fields (certainly supported by ITK).</p><p>* Why can &quot;linked&quot; images not be overlaid and fused? It&#39;s a bit inconvenient to have to re-read an image to be able to do both linked cursors and overlay of the same second data set.</p><p>* Somehow many of the Qt widgets seem to be too small for their content (e.g., window/level entries, preset drop-down list). For the widgets just below the menu bar, the problem goes away when I maximize the application window, but the widgets in the &quot;Overlay&quot; tabfor example stay too small.</p><p>* It would be nice to have anatomical labels (&quot;A/P/L/R/I/S&quot;) displayed in the viewers for orientation. </p><p>* There does not seem to be a way to change the scale of the viewer images, while there is translate interaction using the middle mouse buttom. </p><p>* It would be useful to be able to turn the text overlay in the viewers on and off (for exporting images). </p><p> <strong>Additional Comments:</strong><br />This is certainly not as powerful a tool as others, e.g., 3DSlicer, but for what it does it is exactly right. The tool does a terrific job at what it does, without the bloating and feature overload of more complex packages. Great contribution!!<br /> <br /> </p>", "review_id": 1547}, {"date": "07-29-2008", "author": {"author_id": 4, "author_email": "luis.ibanez@kitware.com", "author_lastname": "Ibanez", "author_firstname": "Luis"}, "content": "<p>&nbsp;</p><p><strong>Summary:</strong></p><p>The authors describe a visualization tool suitable for 2D+t and 3D+t data. This is a very useful visualization tool for a task for which no other tools are currently available. The implementation is very well crafted and resulted in a tool that feels very fluid to the user. Great Work !</p><p>&nbsp;</p><p><strong>Open Science:</strong></p><p> The paper provides all the material required to replicate the work described by the authors.</p><p><strong>Reproducibility:</strong></p><p>I downloaded the source code and build it under Linux Debian with Gcc 4.1. It build out of the box without any modifications.</p><p>Downloaded the data provided by the authors as well and was able to load it into the VV tool and to exercise the functionalities described in the paper.</p><p>The paper and its complementary material is a perfect example of a reproducible paper. </p><p><br /> <strong>Use of Open Source Software:</strong><br /> </p><p>The authors used the Open Source packages : ITK, VTK and QT (note that Qt has a dual-license).</p><p>The source code of the tool described in the paper is also available as Open Source software under a modified BSD license. </p><p>The authors did a great job of reusing of functionalities provided by existing toolkits and focusing on developing new functionalities that no other tool includes today.</p><p> <br /> <strong>Open Source Contributions:</strong><br /> </p><p>The source code was provided and it was very easy to build.</p><p> <br /> <strong>Code Quality:</strong></p><p>The source code was readable. The coding style is not fully consistent. Therefore it may require some style fixing if added to Insight Applications. </p><p> <br /> <strong>Applicability to other problems:</strong></p><p> This viewer is an excellent tool and it will certainly be useful in many different fields. </p><p> <br /> <strong>Suggestions for future work:</strong></p><p> <br /> <strong>Additional Comments:</strong><br /> </p><p>This is a great paper, describing a great tool.</p><p>Congratulations for a job well done, </p><p>and thanks for sharing this good software with the community. </p><p>&nbsp;</p><p>------</p><p>Very Very Minor improvements: the CMakeLists.txt file must be updated for CMake 2.6. </p><p>Several warnings were reported when building in Linux,nothing too serious, but it would be nice to clean them up. </p>", "review_id": 1543}], "publication_id": 617},
{"reviews": [], "publication_id": 618},
{"reviews": [], "publication_id": 619},
{"reviews": [], "publication_id": 620},
{"reviews": [], "publication_id": 621},
{"reviews": [], "publication_id": 622},
{"reviews": [], "publication_id": 623},
{"reviews": [], "publication_id": 624},
{"reviews": [], "publication_id": 626},
{"reviews": [], "publication_id": 629},
{"reviews": [], "publication_id": 631},
{"reviews": [], "publication_id": 632},
{"reviews": [], "publication_id": 633},
{"reviews": [], "publication_id": 634},
{"reviews": [], "publication_id": 635},
{"reviews": [], "publication_id": 636},
{"reviews": [], "publication_id": 637},
{"reviews": [], "publication_id": 638},
{"reviews": [], "publication_id": 639},
{"reviews": [], "publication_id": 640},
{"reviews": [], "publication_id": 641},
{"reviews": [], "publication_id": 642},
{"reviews": [], "publication_id": 643},
{"reviews": [], "publication_id": 644},
{"reviews": [], "publication_id": 645},
{"reviews": [], "publication_id": 646},
{"reviews": [], "publication_id": 647},
{"reviews": [], "publication_id": 648},
{"reviews": [], "publication_id": 649},
{"reviews": [], "publication_id": 650},
{"reviews": [], "publication_id": 651},
{"reviews": [], "publication_id": 652},
{"reviews": [], "publication_id": 653},
{"reviews": [], "publication_id": 654},
{"reviews": [], "publication_id": 655},
{"reviews": [], "publication_id": 656},
{"reviews": [], "publication_id": 657},
{"reviews": [], "publication_id": 658},
{"reviews": [], "publication_id": 659},
{"reviews": [], "publication_id": 660},
{"reviews": [], "publication_id": 661},
{"reviews": [], "publication_id": 662},
{"reviews": [], "publication_id": 663},
{"reviews": [], "publication_id": 664},
{"reviews": [], "publication_id": 665},
{"reviews": [], "publication_id": 666},
{"reviews": [], "publication_id": 667},
{"reviews": [], "publication_id": 668},
{"reviews": [], "publication_id": 669},
{"reviews": [], "publication_id": 670},
{"reviews": [], "publication_id": 671},
{"reviews": [], "publication_id": 672},
{"reviews": [], "publication_id": 673},
{"reviews": [], "publication_id": 675},
{"reviews": [], "publication_id": 676},
{"reviews": [], "publication_id": 677},
{"reviews": [], "publication_id": 678},
{"reviews": [], "publication_id": 679},
{"reviews": [], "publication_id": 680},
{"reviews": [], "publication_id": 681},
{"reviews": [], "publication_id": 682},
{"reviews": [], "publication_id": 683},
{"reviews": [], "publication_id": 684},
{"reviews": [], "publication_id": 685},
{"reviews": [], "publication_id": 686},
{"reviews": [], "publication_id": 687},
{"reviews": [], "publication_id": 688},
{"reviews": [], "publication_id": 689},
{"reviews": [], "publication_id": 690},
{"reviews": [], "publication_id": 691},
{"reviews": [], "publication_id": 692},
{"reviews": [], "publication_id": 693},
{"reviews": [], "publication_id": 694},
{"reviews": [], "publication_id": 695},
{"reviews": [], "publication_id": 696},
{"reviews": [], "publication_id": 697},
{"reviews": [], "publication_id": 698},
{"reviews": [], "publication_id": 699},
{"reviews": [], "publication_id": 700},
{"reviews": [], "publication_id": 701},
{"reviews": [], "publication_id": 702},
{"reviews": [], "publication_id": 703},
{"reviews": [], "publication_id": 704},
{"reviews": [], "publication_id": 705},
{"reviews": [], "publication_id": 706},
{"reviews": [], "publication_id": 707},
{"reviews": [], "publication_id": 708},
{"reviews": [], "publication_id": 709},
{"reviews": [], "publication_id": 710},
{"reviews": [], "publication_id": 711},
{"reviews": [], "publication_id": 712},
{"reviews": [], "publication_id": 713},
{"reviews": [], "publication_id": 714},
{"reviews": [], "publication_id": 715},
{"reviews": [], "publication_id": 716},
{"reviews": [], "publication_id": 717},
{"reviews": [], "publication_id": 718},
{"reviews": [], "publication_id": 719},
{"reviews": [], "publication_id": 720},
{"reviews": [], "publication_id": 721},
{"reviews": [], "publication_id": 722},
{"reviews": [], "publication_id": 723},
{"reviews": [], "publication_id": 724},
{"reviews": [], "publication_id": 725},
{"reviews": [], "publication_id": 726},
{"reviews": [], "publication_id": 727},
{"reviews": [], "publication_id": 728},
{"reviews": [], "publication_id": 729},
{"reviews": [], "publication_id": 730},
{"reviews": [], "publication_id": 734},
{"reviews": [], "publication_id": 735},
{"reviews": [], "publication_id": 736},
{"reviews": [], "publication_id": 737},
{"reviews": [], "publication_id": 738},
{"reviews": [], "publication_id": 739},
{"reviews": [], "publication_id": 740},
{"reviews": [], "publication_id": 741},
{"reviews": [], "publication_id": 742},
{"reviews": [], "publication_id": 743},
{"reviews": [], "publication_id": 744},
{"reviews": [], "publication_id": 745},
{"reviews": [], "publication_id": 746},
{"reviews": [], "publication_id": 747},
{"reviews": [], "publication_id": 748},
{"reviews": [], "publication_id": 749},
{"reviews": [], "publication_id": 750},
{"reviews": [], "publication_id": 751},
{"reviews": [], "publication_id": 752},
{"reviews": [], "publication_id": 753},
{"reviews": [], "publication_id": 754},
{"reviews": [], "publication_id": 755},
{"reviews": [], "publication_id": 756},
{"reviews": [], "publication_id": 757},
{"reviews": [], "publication_id": 758},
{"reviews": [], "publication_id": 759},
{"reviews": [], "publication_id": 760},
{"reviews": [], "publication_id": 761},
{"reviews": [], "publication_id": 762},
{"reviews": [], "publication_id": 763},
{"reviews": [], "publication_id": 764},
{"reviews": [], "publication_id": 765},
{"reviews": [], "publication_id": 766},
{"reviews": [], "publication_id": 767},
{"reviews": [], "publication_id": 768},
{"reviews": [], "publication_id": 769},
{"reviews": [], "publication_id": 770},
{"reviews": [], "publication_id": 771},
{"reviews": [], "publication_id": 772},
{"reviews": [], "publication_id": 773},
{"reviews": [], "publication_id": 774},
{"reviews": [], "publication_id": 775},
{"reviews": [], "publication_id": 776},
{"reviews": [], "publication_id": 777},
{"reviews": [], "publication_id": 778},
{"reviews": [], "publication_id": 779},
{"reviews": [], "publication_id": 780},
{"reviews": [], "publication_id": 781},
{"reviews": [], "publication_id": 782},
{"reviews": [], "publication_id": 783},
{"reviews": [], "publication_id": 784},
{"reviews": [], "publication_id": 785},
{"reviews": [], "publication_id": 786},
{"reviews": [], "publication_id": 787},
{"reviews": [], "publication_id": 788},
{"reviews": [], "publication_id": 789},
{"reviews": [], "publication_id": 790},
{"reviews": [], "publication_id": 791},
{"reviews": [], "publication_id": 792},
{"reviews": [], "publication_id": 793},
{"reviews": [], "publication_id": 794},
{"reviews": [], "publication_id": 796},
{"reviews": [], "publication_id": 797},
{"reviews": [], "publication_id": 798},
{"reviews": [], "publication_id": 799},
{"reviews": [], "publication_id": 800},
{"reviews": [], "publication_id": 801},
{"reviews": [], "publication_id": 802},
{"reviews": [], "publication_id": 803},
{"reviews": [], "publication_id": 804},
{"reviews": [], "publication_id": 805},
{"reviews": [], "publication_id": 808},
{"reviews": [], "publication_id": 809},
{"reviews": [], "publication_id": 810},
{"reviews": [], "publication_id": 811},
{"reviews": [], "publication_id": 812},
{"reviews": [], "publication_id": 813},
{"reviews": [], "publication_id": 815},
{"reviews": [], "publication_id": 816},
{"reviews": [], "publication_id": 817},
{"reviews": [], "publication_id": 818},
{"reviews": [], "publication_id": 819},
{"reviews": [], "publication_id": 820},
{"reviews": [], "publication_id": 821},
{"reviews": [], "publication_id": 822},
{"reviews": [], "publication_id": 823},
{"reviews": [], "publication_id": 824},
{"reviews": [], "publication_id": 825},
{"reviews": [], "publication_id": 826},
{"reviews": [], "publication_id": 827},
{"reviews": [], "publication_id": 828},
{"reviews": [], "publication_id": 829},
{"reviews": [], "publication_id": 830},
{"reviews": [], "publication_id": 831},
{"reviews": [], "publication_id": 832},
{"reviews": [], "publication_id": 833},
{"reviews": [], "publication_id": 834},
{"reviews": [], "publication_id": 835},
{"reviews": [], "publication_id": 836},
{"reviews": [], "publication_id": 837},
{"reviews": [], "publication_id": 838},
{"reviews": [], "publication_id": 839},
{"reviews": [], "publication_id": 840},
{"reviews": [], "publication_id": 841},
{"reviews": [], "publication_id": 842},
{"reviews": [], "publication_id": 843},
{"reviews": [], "publication_id": 844},
{"reviews": [], "publication_id": 845},
{"reviews": [], "publication_id": 846},
{"reviews": [], "publication_id": 847},
{"reviews": [], "publication_id": 848},
{"reviews": [], "publication_id": 849},
{"reviews": [], "publication_id": 850},
{"reviews": [], "publication_id": 851},
{"reviews": [], "publication_id": 852},
{"reviews": [], "publication_id": 853},
{"reviews": [], "publication_id": 854},
{"reviews": [], "publication_id": 855},
{"reviews": [], "publication_id": 856},
{"reviews": [], "publication_id": 857},
{"reviews": [], "publication_id": 858},
{"reviews": [], "publication_id": 859},
{"reviews": [], "publication_id": 860},
{"reviews": [], "publication_id": 861},
{"reviews": [], "publication_id": 862},
{"reviews": [], "publication_id": 863},
{"reviews": [], "publication_id": 864},
{"reviews": [], "publication_id": 866},
{"reviews": [], "publication_id": 868},
{"reviews": [], "publication_id": 869},
{"reviews": [], "publication_id": 870},
{"reviews": [], "publication_id": 871},
{"reviews": [], "publication_id": 872},
{"reviews": [], "publication_id": 873},
{"reviews": [], "publication_id": 874},
{"reviews": [], "publication_id": 875},
{"reviews": [], "publication_id": 876},
{"reviews": [], "publication_id": 877},
{"reviews": [], "publication_id": 878},
{"reviews": [], "publication_id": 879},
{"reviews": [], "publication_id": 880},
{"reviews": [], "publication_id": 881},
{"reviews": [], "publication_id": 882},
{"reviews": [], "publication_id": 883},
{"reviews": [], "publication_id": 884},
{"reviews": [], "publication_id": 885},
{"reviews": [], "publication_id": 886},
{"reviews": [], "publication_id": 887},
{"reviews": [], "publication_id": 889},
{"reviews": [], "publication_id": 890},
{"reviews": [], "publication_id": 891},
{"reviews": [], "publication_id": 892},
{"reviews": [], "publication_id": 893},
{"reviews": [], "publication_id": 894},
{"reviews": [], "publication_id": 896},
{"reviews": [], "publication_id": 897},
{"reviews": [], "publication_id": 898},
{"reviews": [], "publication_id": 899},
{"reviews": [], "publication_id": 900},
{"reviews": [], "publication_id": 901},
{"reviews": [], "publication_id": 902},
{"reviews": [], "publication_id": 903},
{"reviews": [], "publication_id": 904},
{"reviews": [], "publication_id": 905},
{"reviews": [], "publication_id": 906},
{"reviews": [], "publication_id": 907},
{"reviews": [], "publication_id": 908},
{"reviews": [], "publication_id": 909},
{"reviews": [], "publication_id": 910},
{"reviews": [], "publication_id": 911},
{"reviews": [], "publication_id": 912},
{"reviews": [], "publication_id": 913},
{"reviews": [], "publication_id": 914},
{"reviews": [], "publication_id": 915},
{"reviews": [], "publication_id": 916},
{"reviews": [], "publication_id": 917},
{"reviews": [], "publication_id": 918},
{"reviews": [], "publication_id": 919},
{"reviews": [], "publication_id": 920},
{"reviews": [], "publication_id": 921},
{"reviews": [], "publication_id": 923},
{"reviews": [], "publication_id": 924},
{"reviews": [], "publication_id": 925},
{"reviews": [], "publication_id": 926},
{"reviews": [], "publication_id": 927},
{"reviews": [], "publication_id": 928},
{"reviews": [], "publication_id": 929},
{"reviews": [], "publication_id": 930},
{"reviews": [], "publication_id": 931},
{"reviews": [], "publication_id": 932},
{"reviews": [], "publication_id": 933},
{"reviews": [], "publication_id": 934},
{"reviews": [], "publication_id": 935},
{"reviews": [], "publication_id": 936},
{"reviews": [], "publication_id": 937},
{"reviews": [], "publication_id": 938},
{"reviews": [], "publication_id": 939},
{"reviews": [], "publication_id": 940},
{"reviews": [], "publication_id": 941},
{"reviews": [], "publication_id": 942},
{"reviews": [], "publication_id": 945},
{"reviews": [], "publication_id": 946},
{"reviews": [], "publication_id": 947},
{"reviews": [], "publication_id": 948},
{"reviews": [], "publication_id": 949},
{"reviews": [], "publication_id": 950},
{"reviews": [], "publication_id": 951},
{"reviews": [], "publication_id": 952},
{"reviews": [], "publication_id": 953},
{"reviews": [], "publication_id": 954},
{"reviews": [], "publication_id": 955},
{"reviews": [], "publication_id": 956},
{"reviews": [], "publication_id": 957},
{"reviews": [], "publication_id": 958},
{"reviews": [], "publication_id": 959},
{"reviews": [], "publication_id": 960},
{"reviews": [], "publication_id": 961},
{"reviews": [], "publication_id": 962},
{"reviews": [], "publication_id": 963},
{"reviews": [], "publication_id": 964},
{"reviews": [], "publication_id": 965},
{"reviews": [], "publication_id": 966},
{"reviews": [], "publication_id": 967},
{"reviews": [], "publication_id": 968},
{"reviews": [], "publication_id": 969},
{"reviews": [], "publication_id": 970},
{"reviews": [], "publication_id": 971},
{"reviews": [], "publication_id": 972},
{"reviews": [], "publication_id": 973},
{"reviews": [], "publication_id": 974},
{"reviews": [], "publication_id": 975},
{"reviews": [], "publication_id": 976},
{"reviews": [], "publication_id": 977},
{"reviews": [], "publication_id": 978},
{"reviews": [], "publication_id": 979},
{"reviews": [], "publication_id": 980},
{"reviews": [], "publication_id": 981},
{"reviews": [], "publication_id": 982},
{"reviews": [], "publication_id": 983},
{"reviews": [], "publication_id": 984},
{"reviews": [], "publication_id": 985},
{"reviews": [], "publication_id": 986},
{"reviews": [], "publication_id": 987},
{"reviews": [], "publication_id": 988},
{"reviews": [], "publication_id": 989},
{"reviews": [], "publication_id": 990},
{"reviews": [], "publication_id": 991},
{"reviews": [], "publication_id": 992}
]
